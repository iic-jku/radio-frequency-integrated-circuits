[
  {
    "objectID": "rfic.html#sec-intro-wireless",
    "href": "rfic.html#sec-intro-wireless",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "1.1 Wireless Transmission",
    "text": "1.1 Wireless Transmission\nIn wireless transmission, we usually want to transmit data via a transmitter (TX) and a connected antenna to a receiver (RX) using an electromagnetic (EM) wave. This arrangement is shown in Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: The block diagram of a simple wireless system.\n\n\n\n\n\nUnfortunately, wireless transmission is hard. The wireless channel, i.e., the usage of electromagnetic waves to transmit information from a transmitter to a receiver, while tremendously useful, unfortunately has quite a few undesired features:\n\nThe wireless channel is shared between all users.\nAs a consequence, the available bandwidth is shared; this means that bandwidth is a scarce resource.\nThe wireless channel has significant losses.\nThe channel is time variant, as usually the transmitter and/or the receiver move, and/or the environment changes.\n\nIn order to estimate the power \\(P_\\mathrm{R}\\) of the wireless transmission at the receiver we can use Friis’ transmission formula (Pozar 2011):\n\\[\nP_\\mathrm{R} = \\frac{P_\\mathrm{T}}{4 \\pi d^2} \\cdot A_\\mathrm{R} = P_\\mathrm{T} \\cdot \\frac{A_\\mathrm{R} \\cdot A_\\mathrm{T}}{d^2 \\lambda^2}\n\\tag{1}\\]\nHere, \\(A_\\mathrm{R}\\) (and \\(A_\\mathrm{T}\\)) is the effective area of the receive/transmit antenna, while \\(d\\) is the distance (line of sight) between the two antennas. The effective area of an antenna depends on the type and construction, but generally we can say that\n\\[\nA \\propto \\lambda^2\n\\]\nFor an isotropic antenna (a theoretical construct where the radiation is equal in all directions) \\(A = \\lambda^2 / (4 \\pi)\\), while for a \\(\\lambda/2\\)-dipole \\(A = 0.13 \\lambda^2\\). Of course, the speed of light \\(c\\) relates frequency \\(f\\) and wavelength \\(\\lambda\\) of an electromagnetic wave by\n\\[\nc = \\lambda f.\n\\]\nGenerally speaking, the size of an electromagnetic antenna is proportional to the wavelength of the EM wave use for transmission. For man devices, we seek antennas on the order of a few centimeters, and this is why frequencies in the hundreds of MHz to GHz are so popular. Table 1 lists a few typical applications and their frequency and wavelength.\n\n\n\nTable 1: Typical RF applications with their operating frequencies and corresponding wavelengths\n\n\n\n\n\nApplication\nFrequency\nWavelength\n\n\n\n\nFM Radio\n88–108 MHz\n2.8-3.4 m\n\n\nWiFi (lowband)\n2.4 GHz\n12.5 cm\n\n\nWiFi (highband)\n5 GHz\n6 cm\n\n\nBluetooth\n2.4 GHz\n12.5 cm\n\n\nCellular\n0.6–5 GHz\n6-50 cm\n\n\nGNSS\n1.575 GHz\n19 cm\n\n\n\n\n\n\nAs you can see in Table 1 many of these antennas would not fit into the used device form factors, i.e., often we have to use electrically small antennas.\n\n\n\n\n\n\nNote 1: Wavelength Calculation\n\n\n\nLet’s calculate the wavelength for a Bluetooth signal at 2.4 GHz. Given:\n\nFrequency \\(f = 2.4\\) GHz \\(= 2.4 \\times 10^9\\) Hz\n\nSpeed of light \\(c = 3 \\times 10^8\\) m/s\n\nUsing the relationship \\(c = \\lambda f\\), we can solve for wavelength:\n\\[\\lambda = \\frac{c}{f} = \\frac{3 \\times 10^8 \\text{ m/s}}{2.4 \\times 10^9 \\text{ Hz}} = 0.125 \\text{ m} = 12.5 \\text{ cm}\\]\nThis means that a quarter-wavelength monopole antenna for 2.4 GHz Bluetooth would be approximately 3.1 cm long, which easily fits into most mobile devices.\n\n\nIn order to get a feeling for the attenuation experienced in wireless communication, we now calculate the following exemplary transmission. We will use the unit of dBm with is often used in RF design and is defined as\n\\[\nP|_\\text{dBm} = 10 \\cdot \\log_{10} \\left( \\frac{P|_\\text{W}}{1\\,\\text{mW}} \\right)\n\\tag{2}\\]\n\n\n\n\n\n\nNote 2: Wireless Transmission\n\n\n\nWe use the following parameters:\n\nTransmit power \\(P_\\mathrm{T} = 1\\) W\nFrequency \\(f = 2.4\\) GHz\nCommunication distance \\(d = 10\\) km\nUsing \\(\\lambda/2\\) dipoles on both ends\n\nUsing Equation 1 we calculate\n\\[\nP_\\mathrm{R} = P_\\mathrm{T} \\cdot \\frac{0.13 \\lambda^2 \\cdot 0.13 \\lambda^2}{d^2 \\lambda^2} = P_\\mathrm{T} \\cdot 0.13^2 \\left( \\frac{\\lambda}{d} \\right)^2 =  2.64\\,\\text{pW} = -85.8\\,\\text{dBm}\n\\]\nWith the transmit power of 1 W = 30 dBm we have an attenuation of 116 dB! This is a very large number!\n\n\nAs dire as the situation of Note 2 already looks, this is not even all factors considered:\n\nThe given attenuation is for line-of-sight paths; often, the attenuation is significantly higher than this due to blockage by buildings, mountains, rain, or foliage.\nIn lack of a direct line-of-sight path, the EM wave is redirected by reflections, causing additional attenuation, and the potential destructive interference by multi-path reception.\n\nThe consequences of this are (among others):\n\nThe transmitter needs to generate enough transmit power to overcome the transmission loss; this has to be done often with high efficiency, as the transmit device is battery operated or limited by cooling.\nThe receiver has to be able to process weak signals, i.e., the noise level of the signal processing has to be very low.\nOften, the receive signal is very weak, while there are strong signals at other frequencies (i.e., other wireless transmitters are located close to the receiver). This means the receiver has to be able to process a weak signal while simultaneously tolerate large interfering signals (called blockers).\nSince the frequency spectrum is shared among many users and wireless applications, the transmit information has to be packed efficiently into a small bandwidth.\nVery often, wireless devices are battery-operated. This means transmit and receive functions have to be implemented using minimum power consumption.\n\nAs stated in the beginning, designing wireless systems is hard."
  },
  {
    "objectID": "rfic.html#sec-intro-standards",
    "href": "rfic.html#sec-intro-standards",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "1.2 Wireless Standards",
    "text": "1.2 Wireless Standards\nIn order to allow communication between different devices, different operators, and different manufacturers, wireless communication is standardized. There are many different standards, each with its own characteristics. Wireless standards define every aspect of the wireless communication, and be documents with hundreds or thousands of pages. Here, we mainly focus on the radio-frequency and analog aspects of wireless standards. Summarized in Table 2 are a few popular wireless standards with their main characteristics.\n\n\n\nTable 2: Comparison of wireless communication standards\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStandard\nGSM (2G)\nWCDMA (3G)\nLTE (4G)5G NR\nWiFi\nBluetooth\nGNSS\n\n\n\n\nFrequency range (MHz)\n850, 900, 1800, 1900\n850, 900, 1700, 1900, 2100\nMultiple bands 450…7100 (FR1), 24000…48000 (FR2)\n2400, 5000, 6000\n2400\n1500, 1200\n\n\nModulation\nGMSK, 8PSK (EDGE)\nQPSK (DL), BPSK (UL), 16QAM (HSPA), 64QAM (HSPA)\nQPSK, 16QAM, 64QAM (DL+UL) 256QAM (DL+UL)\nBPSK, QPSK, 16QAM, 64QAM, 256QAM, 1024QAM, 4096QM\nGFSK (m=0.28…0.35), \\(\\pi\\)/4-DQPSK, 8DPSK\nBPSK, QPSK\n\n\nTransmission/ multiple access\nTDMA, FDMA\nDS-CDMA\nOFDMA (DL+UL), SC-FDMA/DFT-s-OFDM (UL)\nOFDM, CSMA/CA\nFHSS\nCDMA\n\n\nDuplex\nFDD\nFDD\nFDD, TDD\nTDD\nTDD\nn/a\n\n\nChannel bandwidth\n200 kHz\n5 MHz\n1.4, 3, 5, 10, 15, 20, …, 100 MHz (FR1), 400 MHz (FR2)\n10, 20, 40, 80, 160, 320 MHz\n1 MHz\n16…24 MHz\n\n\nSymbol rate\n270.833 ksym/s\n3.84 Msym/s\n15/30/60 ksym/s\n312.5 ksym/s\n1 Msym/s\n50 sym/s\n\n\nPulse shaping\nGaussian (BT=0.3)\nRoot Raised Cosine (\\(\\alpha\\)=0.22)\nRectangular\nRectangular\nGaussian (BT=0.5)\nRectangular\n\n\nTransmit power\n1…2 W\n250 mW\n200 mW (FDD), 400 mW (TDD)\n100 mW\n1…100 mW\nn/a\n\n\nPAR (UL)\n0 dB (GMSK), 3 dB (8PSK)\n3…8 dB\n6…8 dB\nUp to 12 dB\n0 dB (GFSK), 3 dB (8DPSK)\nn/a\n\n\nMIMO\nno\nNot realized (DL 2x2)\nDL 4x4 (up to 8x8)\n2x2 (up to 8x8)\nno\nno\n\n\nChannel bond\nno\nUp to 4x5 MHz\nUp to 7x20/4x100 MHz\nUp to 80+80+80+80 MHz\nno\nno\n\n\n\n\n\n\nDuring this course, we will learn what these terms mean and how they impact the design of RF integrated circuits.\nAs you can see in Table 2, since LTE (4G) and 5G NR, many additional bands have been defined in the sub-6 GHz range (FR1) and also in the mm-wave range (FR2, 24.25 to 52.6 GHz). This means that modern wireless devices have to support many different frequency bands, which makes the design of RF frontends even more challenging. A good overview of the different frequency bands is given here for LTE and 5G NR."
  },
  {
    "objectID": "rfic.html#sec-linearity",
    "href": "rfic.html#sec-linearity",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.1 Linearity",
    "text": "2.1 Linearity\nAs we have already seen in Section 1.1 the transmitter has to process large signals without distorting them, while the receiver has to process small signals in the presence of large signals. Both situations mean we need metrics and models to quantify and discuss linearity properties.\nWe are going to use a very simple, time-invariant model to study linearity, based on a Taylor polynomial.\n\n\n\n\n\n\nImportantLinearity and Time Invariance in RF Systems\n\n\n\nWe use time invariance to simplify the mathematics. In practice, many circuits and systems will show time variant behavior which leads to quite a few very interesting and important phenomena!\n\n\nWe model a nonlinear circuit block with the following Taylor polynomial:\n\\[\ny(t) = \\alpha_0 + \\alpha_1 x(t) + \\alpha_2 x(t)^2 + \\alpha_3 x(t)^3 + \\ldots\n\\tag{3}\\]\nUsually, the blocks under study will have higher order nonlinear terms but we often stop at 3rd order to keep things simple. For practical work, higher order terms should be included if necessary.\nWhich \\(x(t)\\) should we use to study wireless systems? Often, the bandwidth \\(f_\\mathrm{BW}\\) of a transmit signal is much smaller than the center frequency \\(f_0\\), i.e., \\(f_\\mathrm{BW} \\ll f_0\\). In this case using a sinusoidal signal as a mode is both simple to handle and approximately correct.\n\n2.1.1 Single-Tone Linearity\nWe thus set (with \\(A\\) being the amplitude of the input signal and \\(\\omega = 2 \\pi f\\) the angular frequency)\n\\[\nx(t) = A \\cos(\\omega t)\n\\]\nand insert it into Equation 3. After some simple trigonometric manipulations we are at\n\\[\n\\begin{split}\ny(t) &=\n\\underbrace{ \\frac{1}{2} \\alpha_2 A^2 }_\\text{dc component}\n+\n\\underbrace{ \\left(\\alpha_1 A + \\frac{3}{4} \\alpha_3 A^3 \\right) \\cos(\\omega t) }_\\text{fundamental} \\\\\n&+\n\\underbrace{ \\frac{1}{2} \\alpha_2 A^2 \\cos(2 \\omega t) }_\\text{2nd harmonic}\n+\n\\underbrace{ \\frac{1}{4} \\alpha_3 A^3 \\cos(3 \\omega t) }_\\text{3rd harmonic}\n\\end{split}\n\\tag{4}\\]\nLooking at Equation 4 we can make a few interesting observations:\n\nEven-order nonlinearity (\\(\\alpha_2\\)) creates low-frequency components; it effectively adds frequency components related to the envelope \\(A\\). If \\(A\\) is a constant then this results in a dc term; if \\(A(t)\\) is time variant it will created a squared version of it at low frequencies.\nThe \\(\\alpha_1\\) term is the gain of the circuit block.\nOdd-order nonlinearity (\\(\\alpha_3\\)) can impact the gain of the fundamental term passing through the block. Depending on the sign of \\(\\alpha_3\\) this can lead to gain contraction or expansion.\nEven- and odd-order nonlinearities creates additional frequency components, so-called harmonics of the fundamental frequency. These harmonics are often unwanted, as they are far outside the wanted transmission frequency range, and need to be minimized, by either\n\nuse a lowpass filter to filter these harmonics, or\nincrease the linearity, i.e., make the \\(\\alpha_2\\), \\(\\alpha_3\\), etc., small enough.\n\n\nThe created harmonics are illustrated in Figure 2. Note that measuring harmonics to quantify the nonlinearity metrics like \\(\\alpha_2\\) and \\(\\alpha_3\\) is often not very accurate, as these harmonics are often filtered in bandwidth-limited systems.\n\n\n\n\n\n\n\n\nFigure 2: Single-tone test showing created harmonics at 2ω and 3ω.\n\n\n\n\n\nHow can we quantify the nonlinearity with a one-tone test? We can sweep the input signal \\(x(t)\\) in amplitude, and observe the output \\(y(t)\\). If the observed gain drops by 1 dB from the small-signal value we note the input power, and call this point the 1dB compression point (\\(P_\\mathrm{1dB}\\)). We should always add whether this 1dB compression point is input- or output-referred to avoid ambiguity. The diagram in Figure 3 shows this test (\\(\\alpha_1 = 100\\), \\(\\alpha_3 = -0.2\\)).\n\n\n\n\n\n\n\n\nFigure 3: 1dB compression point test showing input vs output power relationship and the definition of P1dB.\n\n\n\n\n\n\n\n\n\n\n\nImportantCompressive vs. Expansive Behavior\n\n\n\nNote that for compressive behaviour, \\(\\alpha_3\\) and \\(\\alpha_1\\) have different signs, while for expansive behaviour, they have the same sign.\nAt some point, every circuit block will show compressive behavior, as the maximum signal amplitude will be limited by power supply voltages, device breakdown voltages, etc.\n\n\n\n\n2.1.2 Multi-Tone Linearity\nWe now elevate our investigations and apply two sinusoids with different frequencies and different amplitudes and see which signals we get at the output of the nonlinear block. The two-tone test and resulting third-order intermodulation products (IM3) are illustrated in Figure 4.\n\\[\nx(t) = A_1 \\cos(\\omega_1 t) + A_2 \\cos(\\omega_2 t)\n\\]\nWe apply the above stimulus to our nonlinear model described by Equation 3 and again, after some trigonometric manipulations, arrive at:\n\\[\ny(t) = y'(t) + y''(t) + y'''(t)\n\\tag{5}\\]\nAs many different frequency components are created by this simple two-tone test (and nonlinearity only up to 3rd order) we split the result into different equations and look at the result separately.\nFirst, we start with the fundamental tones:\n\\[\n\\begin{split}\n    y'(t) &= \\left( \\underbrace{\\alpha_1 A_1 + \\frac{3}{4} \\alpha_3 A_1^3}_\\text{compression/expansion} + \\underbrace{\\frac{3}{2} \\alpha_3 A_1 A_2^2}_\\text{cross-modulation/desens} \\right) \\cos(\\omega_1 t) \\\\\n    &+ \\left( \\underbrace{\\alpha_1 A_2 + \\frac{3}{4} \\alpha_3 A_2^3}_\\text{compression/expansion} + \\underbrace{\\frac{3}{2} \\alpha_3 A_2 A_1^2}_\\text{cross-modulation/desens} \\right) \\cos(\\omega_2 t)\n\\end{split}\n\\tag{6}\\]\nAs shown in Equation 6, interesting things happen:\n\nWe (again) have the gain compression/expansion effect as already discussed in Section 2.1.1.\nIn addition, we have cross-modulation, i.e., the envelope of one tone (e.g., \\(A_2(t)\\) of the tone at \\(\\omega_2\\)) impacts the envelope of the other tone at \\(\\omega_1\\). This can lead to unwanted signal distortation, even if there is a large frequency separation between \\(\\omega_1\\) and \\(\\omega_2\\)!\nFurther, since the sign of \\(\\alpha_3\\) is usually opposite to \\(\\alpha_1\\), this can also lead to desensitization (“desens”). If, for example, \\(A_2 \\gg A_1\\), then there would be no compression due to the tone \\(\\omega_1\\) itself, however, the large tone at \\(\\omega_2\\) will lead to gain compression of the tone at \\(\\omega_1\\); this effect is called desense.\n\nWe now look at the next class of generated tones:\n\\[\n\\begin{split}\n    y''(t) &= \\frac{1}{2} \\alpha_2 A_1^2 + \\frac{1}{2} \\alpha_2 A_2^2 \\\\\n    &+ \\alpha_2 A_1 A_2 \\cos[ (\\omega_1 - \\omega_2) t] \\\\\n    &+ \\alpha_2 A_1 A_2 \\cos[ (\\omega_1 + \\omega_2) t]\n\\end{split}\n\\tag{7}\\]\nAs we can see in Equation 7 new tones are created (besides the low frequency components we already know from the single-tone test) at the sum and difference of \\(\\omega_1\\) and \\(\\omega_2\\). These new frequency components are called “intermodulation products of second order” (IM2). These tones are created by the even-order nonlinearity (\\(\\alpha_2\\)). These IM2 products are far away from the wanted tones, so are often not very problematic in amplifiers (but there can be exceptions!). However, they can be very problematic in frequency conversion blocks like mixers. We will come back to this point when discussing zero-IF receivers.\nWe now investigate the next couple of tones:\n\\[\n\\begin{split}\n    y'''(t) &= \\frac{3}{4} \\alpha_3 A_1^2 A_2 \\cos[(2 \\omega_1 + \\omega_2) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1^2 A_2 \\cos[(2 \\omega_1 - \\omega_2) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1 A_2^2 \\cos[(2 \\omega_2 + \\omega_1) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1 A_2^2 \\cos[(2 \\omega_2 - \\omega_1) t]\n\\end{split}\n\\tag{8}\\]\nThe tones shown in Equation 8 are called “intermodulation products of third order” (IM3), and are caused by the odd nonlinearities (like \\(\\alpha_3\\)). While the IM3 tones located at \\(2 \\omega_1 + \\omega_2\\) and \\(\\omega_1 + 2 \\omega_2\\) are similar to the sum IM2 tone and far away from \\(\\omega_1\\) and \\(\\omega_2\\), the other two tones are concerning.\nExpressing \\(\\Delta \\omega = \\omega_2 - \\omega_1\\) (and assuming \\(\\omega_1 &lt; \\omega_2\\)), the building law of \\(2 \\omega_1 - \\omega_2 = \\omega_1 - \\Delta \\omega\\) and \\(2 \\omega_2 - \\omega_1 = \\omega_2 + \\Delta \\omega\\) results in new tones right besides \\(\\omega_1\\) and \\(\\omega_2\\), with a frequency separation only defined by \\(\\Delta \\omega\\). This situation is illustrated in Figure 4.\n\n\n\n\n\n\n\n\nFigure 4: Two-tone test showing fundamental frequencies ω₁, ω₂ and third-order intermodulation products (IM3) at 2ω₁-ω₂ and 2ω₂-ω₁.\n\n\n\n\n\nThis close localization of the IM3 tones can also be utilized to characterize nonlinear performance. Using gain compression or harmonic generation (H3) it can be very difficult to extract nonlinearity of third order (\\(\\alpha_3\\)). However, using a two-tone test, the IM3 tones can be readily measured, even if the measured signal path shows a bandpass characteristic! As RF systems frequently employ bandpass filters to suppress out-of-band signals, this is a very important property of the two-tone test.\nThe resulting test is called a two-tone test yielding the third-order intercept point (IP3). This test is widely used in RF design to characterize the linearity of amplifiers, mixers, and complete transceiver systems. The power relationship between fundamental tones and IM3 products as a function of input power is shown in Figure 5.\n\n\n\n\n\n\n\n\nFigure 5: Two-tone IM3 test showing fundamental and IM3 product power vs. input power, with IP3 intercept point definition. Equal input power per tone is assumed.\n\n\n\n\n\nNote that, as shown in Figure 5, the IM3 products rise with a slope of 3 dB/dB, i.e., if the input power is increased by 1 dB, the IM3 products increase by 3 dB. The fundamental tones rise with a slope of 1 dB/dB (as long as we are in the linear region). The IP3 point is defined as the intersection of the extrapolated linear lines of fundamental and IM3 products. As both lines have different slopes, this intersection point is usually far outside the actual operating range of the circuit block under test!\nWhen calculating the IIP3 (input-referred IP3) we can use the following formula, assuming equal input power per tone. It is important to always check the slope of the IM3 products to ensure that we are indeed in the third-order region! If the input power per tone is \\(P_\\mathrm{in}\\) (in dBm) and the input-referred power of one IM3 tone is \\(P_\\mathrm{IM3}\\) (in dBm), then the input-referred IP3 is given by\n\\[\n\\text{IIP3} = P_\\mathrm{in} + \\frac{P_\\mathrm{in} - P_\\mathrm{IM3}}{2}\n\\tag{9}\\]\nFurther, for midly nonlinear systems (i.e., \\(\\alpha_3\\) is dominating), the IIP3 can be approximated from the 1dB compression point as\n\\[\n\\text{IIP3}|_\\mathrm{dBm} \\approx P_\\mathrm{1dB}|_\\mathrm{dBm} + 9.6\\,\\text{dB}.\n\\tag{10}\\]\nIf we have two blocks which are cascaded, and we know the gain and IIP3 of both blocks, we can calculate the overall IIP3 of the cascade with the following approximation. An exact calculation is very involved, as the nonlinearities of the first block (and the resulting tones) will be processed by the second block, creating even more tones; this process escalates very quickly. However, for practical purposes, the following approximation is often sufficient:\n\\[\n\\frac{1}{\\text{IIP3}_\\text{total}} \\approx \\frac{1}{\\text{IIP3}_1} + \\frac{G_1}{\\text{IIP3}_2} + \\frac{G_1 G_2}{\\text{IIP3}_3}\n\\tag{11}\\]\nHere \\(G_1\\) is the linear gain of the first block, and \\(\\text{IIP3}_1\\), \\(\\text{IIP3}_2\\) are the input-referred IP3 of the first and second block, respectively. Note that all powers have to be in linear units (i.e., Watts) when using Equation 11. An even more simplified version of Equation 11 can be used with all quantities given in dBm and dB, respectively:\n\\[\n\\text{IIP3}_\\text{total} \\approx \\min \\{  \\text{IIP3}_1, \\text{IIP3}_2 - G_1, \\text{IIP3}_3 - G_1 - G_2 \\}\n\\tag{12}\\]\nA typical RF system cascade with multiple blocks and their individual IIP3 contributions is shown in Figure 6.\n\n\n\n\n\n\n\n\nFigure 6: Block cascade for IIP3 calculation showing multiple stages with gains and individual IIP3 values.\n\n\n\n\n\n\n\n\n\n\n\nNote 3: Simple IIP3 Cascade Calculation\n\n\n\nLet’s calculate the overall IIP3 of two cascaded blocks. The first block is a low-noise amplifier with an IIP3 of -10 dBm and a gain of 20 dB. The second block is a mixer that has a gain of 10 dB and an IIP3 of 5 dBm. What is the overall IIP3?\nUsing Equation 12 we can quickly estimate:\n\\[\n\\text{IIP3}_\\text{total} \\approx \\min \\{ -10\\,\\text{dBm}, 5\\,\\text{dBm} - 20\\,\\text{dB} = -15\\,\\text{dBm} \\} = -15\\,\\text{dBm}\n\\]\nWe see that the overall IIP3 is limited by the linearity of the second block, as the first block amplifies all signals (including blockers) by 20 dB before they reach the second block."
  },
  {
    "objectID": "rfic.html#sec-noise",
    "href": "rfic.html#sec-noise",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.2 Noise",
    "text": "2.2 Noise\nJust as nonlinearity is a limiting factor for large signals, noise is the limiting factor for small signals. Noise is present in all electronic circuits and systems, and it is impossible to avoid it. However, we can try to minimize its impact on the system performance.\nNoise is usually characterized by its power spectral density (PSD) in units of Watts per Hertz (W/Hz). For example, thermal noise at room temperature has a PSD of approximately \\(k T = 4 \\times 10^{-21}\\) W/Hz, or –174 dBm/Hz (with the Boltzmann constant \\(k = 1.38 \\times 10^{-23}\\,\\text{J/K}\\)). This means that if we have a bandwidth of 1 MHz, the total thermal noise power would be:\n\\[\nP_\\mathrm{thermal} = \\text{PSD} \\cdot B = -174\\,\\text{dBm/Hz} + 10 \\log_{10} \\left( \\frac{1\\,\\text{MHz}}{1\\,\\text{Hz}} \\right) = -114\\,\\text{dBm}\n\\]\nThe PSD of noise can be flat vs. frequency (which is called “white noise”), or can decrease with frequency (e.g., “flicker noise” or “1/f noise”). Further, noise can be generated by resistors (thermal noise), semiconductors (shot noise, generation-recombination noise), etc. A detailed discussion of noise sources can be found in (Gray et al. 2009) or (Razavi 2017).\n\n2.2.1 Types of Noise Generation\nResistors generate thermal noise, which is white noise with a PSD of \\(4 k T R\\) (in V\\(^2\\)/Hz) when looking at the voltage across the resistor, or \\(4 k T / R\\) (in A\\(^2\\)/Hz) when looking at the current through the resistor. This noise is generated by the random thermal motion of charge carriers in the resistor.\n\n\n\n\n\n\nImportantThermal Noise\n\n\n\nNote that the simple approximation given above is only valid for reasonably high frequencies and typical temperatures, and is known as the Rayleigh-Jeans approximation of Planck’s blackbody radiation accounting for quantum effects and is given by (Pozar 2011)\n\\[\n\\text{PSD} = \\frac{h f}{e^{{h f}/{k T}} - 1}\n\\]\nwhere \\(h\\) is the Planck constant (\\(h = 6.626 \\times 10^{-34}\\) Js) and \\(f\\) is the frequency. The Rayleigh-Jeans approximation is valid for \\(f \\ll k T / h\\), which is approximately 6 THz at room temperature (290 K).\n\n\nMOSFETs generate several types of noise, the most important ones being the thermal noise of the channel and flicker noise.\nThe thermal noise of the channel can be modeled as a current noise source between drain and source with a PSD of \\(4 k T \\gamma g_{d0}\\) (in A\\(^2\\)/Hz), where \\(\\gamma\\) is a process-dependent parameter (usually between 2/3 and 2). The parameter \\(g_{d0}\\) is the small-signal output conductance of the MOSFET in triode, i.e., \\(g_{d0} = g_\\mathrm{ds}\\), or equal to \\(g_{d0} = g_\\mathrm{m}\\) when in saturation.\nIn saturation, it is often useful to express the thermal noise as a voltage noise source at the gate with a PSD of \\(4 k T \\gamma / g_\\mathrm{m}\\) (in V\\(^2\\)/Hz). We can see that we can lower this noise of the MOSFET by increasing the transconductance \\(g_\\mathrm{m}\\), which can be achieved by increasing the bias current.\nIn addition, at high frequencies, the MOSFET also has induced gate-current noise, which is correlated with the channel thermal noise. A detailed discussion of this noise source can be found in (Razavi 2017).\nFlicker noise is usually modeled as a voltage noise source at the gate with a PSD of \\(K_f / (C'_\\mathrm{ox}W L f)\\) (in V\\(^2\\)/Hz), where \\(K_f\\) is a process-dependent parameter, \\(C'_\\mathrm{ox}\\) is the oxide capacitance per unit area, \\(L\\) and \\(W\\) are the length and width of the MOSFET, and \\(f\\) is the frequency. Note that we can lower the flicker noise by increasing the area of the MOSFET (\\(W L\\)), however, this increases the parasitic capacitances associated with the MOSFET, and this often prohibitive for RF operation!\nIn bipolar junction transistors (BJTs), the most important noise source is the shot noise due to the diffusion current in the base-emitter junction. Its PSD can be modeled as a current noise source between collector and emitter with a PSD of \\(2 q I_\\mathrm{C}\\) (in A\\(^2\\)/Hz), where \\(q\\) is the elementary charge (\\(q = 1.6 \\times 10^{-19}\\) C) and \\(I_\\mathrm{C}\\) is the dc collector current.\n\n\n\n\n\n\nImportantEquivalance of Shot and Thermal Noise\n\n\n\nNote that it has been shown in (Sarpeshkar, Delbruck, and Mead 1993) that thermal noise and shot noise are actually equivalent, as both are generated by the random, thermally agitated motion of charge carriers!\n\n\nIdeal capacitors and inductors do not generate noise, however, real capacitors and inductors have parasitic resistances which generate thermal noise.\nIn RF systems additional noise sources can be present. One noteworthy example is the cosmic microwave background radiation, which can be modeled as a noise temperature of approximately 3 K. While this is negligible compared to thermal noise at room temperature (approximately 290 K), it can be significant in very low-noise systems, such as radio telescopes pointing to the sky. An other important noise source in RF systems is the atmospheric noise, which is generated by natural phenomena like lightning or in the ionosphere.\n\n\n2.2.2 Noise in Impedance-Matched Systems\nWe now want to calculate the maximum noise power that can be extracted from a noisy source. We assume the following situation as shown in Figure 7. Note that the voltage source \\(\\overline{V_\\mathrm{n,s}^2}\\) models the thermal noise of the source resistor \\(R_\\mathrm{s}\\) resulting in a Thevenin equivalent circuit.\n\n\n\n\n\n\n\n\nFigure 7: A noise-matched system with source and load impedances.\n\n\n\n\n\nWe know that the noise of the source resistor is given by \\(\\overline{V_\\mathrm{n,s}^2} = 4 k T R_\\mathrm{s}\\). We assume the load resistor \\(R_\\mathrm{load}\\) as noiseless and matched to the source resistor, i.e., \\(R_\\mathrm{load} = R_\\mathrm{s}\\) for maximum power transfer. The noise power spectral density delivered to the load resistor is then given by\n\\[\nP_\\mathrm{n,load} = \\frac{\\overline{V_\\mathrm{n,load}^2}}{R_\\mathrm{load}} = \\frac{\\overline{V_\\mathrm{n,d}^2}}{4 R_\\mathrm{s}} = k T\n\\tag{13}\\]\nThe calculation of Equation 13 confirms the initial statement that the maximum noise power spectral density that can be extracted from a noisy source is \\(k T\\) (in W/Hz). This result is independent of the actual value of the source resistance \\(R_\\mathrm{s}\\).\nWe can further generalize the thermal noise of any impedance as\n\\[\n\\overline{V_\\mathrm{n}^2} = 4 k T \\Re \\{ Z \\}\n\\tag{14}\\]\nas for example in the complex impedance \\(Z_\\mathrm{ant}\\) of an antenna.\n\n\n2.2.3 Noise Figure\nIn RF systems, we often want to quantify the noise performance of a circuit block or a complete system. The most widely used metric is the noise factor (F), which is defined as the ratio of the signal-to-noise ratio (SNR) at the input to the SNR at the output of a circuit block or system. If we express the noise factor in dB, we call it the noise figure (NF) (Pozar 2011). The noise factor is given by\n\\[\nF = \\frac{\\text{SNR}_\\mathrm{in}}{\\text{SNR}_\\mathrm{out}} = \\frac{(P_\\mathrm{s}/P_\\mathrm{n})_\\mathrm{in}}{(P_\\mathrm{s}/P_\\mathrm{n})_\\mathrm{out}}\n\\tag{15}\\]\nwhere \\(P_\\mathrm{s}\\) is the signal power and \\(P_\\mathrm{n}\\) is the noise power. The noise factor is always larger than or equal to 1 (or 0 dB), as no circuit can improve the SNR!\n\n\n\n\n\n\nImportantSNR Improvement\n\n\n\nNote that the SNR can be improved by filtering, as filtering reduces the noise power. If the noise bandwidth is larger than the signal bandwidth, then the SNR can be improved without affecting the signal. However, this is not considered in the noise factor, as the noise factor assumes that both signal and noise pass through the same bandwidth.\n\n\nLet us look at a simple model of a noise circuit block as shown in Figure 8. The input signal \\(S_\\mathrm{in}\\) is accompanied by noise \\(N_\\mathrm{in}\\). By definition it is assumed that the input noise power results from a matched resistor at \\(T_0 = 290\\,\\text{K}\\), so that \\(N_\\mathrm{in} = k T_0\\). The circuit block has a power gain \\(G\\) and adds its own noise \\(N_\\mathrm{dut}\\) to the output signal. For simplicity, we assume that the input and output of the circuit block are impedance matched to avoid reflections.\n\n\n\n\n\n\n\n\nFigure 8: A noise-matched system with source and load impedances and a noisy circuit block.\n\n\n\n\n\nThe output signal and noise powers are then given by\n\\[\nS_\\mathrm{out} = G S_\\mathrm{in}\n\\]\n\\[\nN_\\mathrm{out} = G N_\\mathrm{in} + N_\\mathrm{dut}\n\\] The resulting noise factor can then be calculated as\n\\[\nF = \\frac{{S_\\mathrm{in}}/{N_\\mathrm{in}}}{{S_\\mathrm{out}}/{N_\\mathrm{out}}} = \\frac{1}{G} \\frac{G N_\\mathrm{in} + N_\\mathrm{dut}}{N_\\mathrm{in}} = 1 + \\frac{N_\\mathrm{dut}}{G N_\\mathrm{in}},\n\\]\nin other words, the noise factor is 1 plus the ratio of the noise added by the device under test (DUT) to the amplified input noise.\nNote that a noiseless block (\\(N_\\mathrm{dut} = 0\\)) has a noise factor of \\(F=1\\). A passive block with loss factor \\(L\\) (and impedance matched at input and output) has a noise factor of \\(F=L\\) (in linear units), as it attenuates the signal and \\(N_\\mathrm{out} = N_\\mathrm{in} = k T\\) if everything is in thermal equilibrium.\n\n\n\n\n\n\n\n\nFigure 9: Block cascade for noise factor calculation showing multiple stages with gains and individual noise factors.\n\n\n\n\n\nIf we have a cascade of multiple blocks, as shown in Figure 9, we can calculate the overall noise factor with the Friis formula (Pozar 2011)\n\\[\nF_\\mathrm{total} = 1 + (F_1 - 1) + \\frac{F_2 - 1}{G_1} + \\frac{F_3 - 1}{G_1 G_2}\n\\tag{16}\\]\nwhere \\(F_i\\) and \\(G_i\\) are the noise factor and power gain of the \\(i\\)-th block, respectively. Note that all gains have to be in linear units (not dB) when using Equation 16. We can interpret Equation 16 as follows:\n\nThe overall noise factor \\(F_\\mathrm{total}\\) is always larger than or equal to the noise factor of the first block (\\(F_1\\)).\nThe noise factor of the first block is the most important one, as the noise factors of the following blocks are reduced by the gain of all preceding blocks. This is especially important in RF receivers, where the first block is usually a low-noise amplifier (LNA) with a very low noise figure (e.g., 1 dB or less) and a high gain (e.g., 10 dB or more). This ensures that the noise of the following blocks is negligible.\nThe noise factor of the last block is reduced by the gain of all preceding blocks, so it is usually not very important.\n\nHere we also see a trade-off between noise and linearity, as shown by Equation 11 and Equation 16. For low noise, we should try to maximize \\(G_1\\), however, this will affect linearity (IIP3) in a negative way. As in many other situation in RF design, we have to find a good compromise between conflicting requirements.\n\n\n2.2.4 Sensitivity\nIn RF receivers, we often want to know the minimum input signal power that can be detected with a certain SNR. This minimum input signal power is called the sensitivity of the receiver. The sensitivity can be calculated as\n\\[\nP_\\mathrm{in, min} = P_\\mathrm{n} \\cdot \\text{SNR}_\\mathrm{min} \\cdot F\n\\tag{17}\\]\nwhere \\(P_\\mathrm{n}\\) is the noise power at the input, \\(\\text{SNR}_\\mathrm{min}\\) is the minimum detectable SNR, and \\(F\\) is the noise factor of the receiver. The input noise power can be calculated as\n\\[\nP_\\mathrm{n} = k T B\n\\]\nwhere \\(k\\) is the Boltzmann constant, \\(T\\) is the temperature in Kelvin, and \\(B\\) is the bandwidth of the receiver. Expressing Equation 17 in dBm we get the following formula:\n\\[\nP_\\mathrm{in, min}|_\\mathrm{dBm} = -174\\,\\text{dBm/Hz} + \\text{NF} + 10 \\log_{10}(B/\\text{Hz}) + \\text{SNR}_\\mathrm{min}|_\\mathrm{dB}\n\\tag{18}\\]\nwhere -174 dBm/Hz is the thermal noise PSD at room temperature (290 K). We can see that the sensitivity improves with lower noise figure, smaller bandwidth, and lower minimum detectable SNR.\n\n\n\n\n\n\nNote 4: Sensitivity Calculation for WiFi\n\n\n\nLet’s calculate the sensitivity of a WiFi receiver operating at 5 GHz with a bandwidth of \\(B = 80\\,\\text{MHz}\\), a noise figure of \\(NF = 7\\,\\text{dB}\\), and a minimum detectable SNR of 25 dB. This high SNR means that a high-order modulation scheme (like 64-QAM) is used for high data rates.\nUsing Equation 18 we get: \\[\nP_\\mathrm{in, min} = -174\\,\\text{dBm/Hz} + 7\\,\\text{dB} + 10 \\log_{10} (80 \\times 10^6) + 25\\,\\text{dB} \\approx -63\\,\\text{dBm}\n\\]\nThis means that the minimum input signal power that can be detected by the WiFi receiver is approximately -63 dBm."
  },
  {
    "objectID": "rfic.html#direct-conversion-transceiver",
    "href": "rfic.html#direct-conversion-transceiver",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.1 Direct-Conversion Transceiver",
    "text": "3.1 Direct-Conversion Transceiver\nThe following typical functions have to be performed by a TRX:\n\nPulse-shaping filtering of the baseband signal (can be implemented analog or in most cases digital).\nModulating the baseband signal onto a carrier frequency (upconversion) in the TX or downconversion in the RX.\nContain the RF signal in a small bandwidth (TX), or single out the wanted signal in the RX.\nAdapt gain (and linearity) to the signal strength in the RX, and to the output power in the TX.\nGenerate the carrier frequency (local oscillator, LO) with low phase noise.\n\nThe dominant architecture for the TRX is the so-called direct-conversion (or Zero-IF) architecture, where the upconversion and downconversion is performed in a single step. This is in contrast to superheterodyne architectures, where the signal is first converted to an intermediate frequency (IF) before being converted to baseband. The direct-conversion architecture has the advantage of reduced complexity and cost, as it requires fewer components and less filtering. However, it also has some disadvantages, such as increased susceptibility to DC offsets and I/Q imbalance. A typical TRX block diagram is shown in Figure Figure 10.\n\n\n\n\n\n\n\n\nFigure 10: Block diagram of a typical transceiver (TRX) showing the main functional blocks of RX and TX. The modem provides the digital baseband processing and interfaces to the rest of the system.\n\n\n\n\n\nAs can be seen in Figure 10, this generic example can be adapted in various ways. Generally, the amplifier gains are adjustable to adapt to different signal levels. If various channel bandwidths are to be supported, the corner frequencies of the low-pass filters (LPF) can be adjusted, as well as (optionally) the sampling rate of the ADCs and DACs. The local oscillator (LO) frequency is generated by a phase-locked loop (PLL) synthesizer, which can be tuned to the desired carrier frequency. In case of frequency-division duplex (FDD) operation, two PLLs are used to generate the TX and RX LO frequencies, which are separated by the duplex distance. In time-division duplex (TDD) operation, a single PLL is sufficient, supplying the LO signal to both RX and TX.\nThe modem that is shown in Figure 10 is responsible for the digital baseband processing, including functions like channel coding/decoding, modulation/demodulation, equalization, and error correction. The modem is usually implemented as a digital System-on-Chip (SoC) consisting of (multiple) CPUS, DSPs, and fixed-function blocks for time-critical processing. For an in-depth discussion we recommend (Sklar and Harris 2020) or (Molisch 2022)."
  },
  {
    "objectID": "rfic.html#modulation-and-demodulation",
    "href": "rfic.html#modulation-and-demodulation",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.2 Modulation and Demodulation",
    "text": "3.2 Modulation and Demodulation\nModulation is the process of varying a carrier signal at frequency \\(f_\\mathrm{c}\\) in order to transmit information. The complex baseband signal (after converting the real-valued digital \\(s_\\mathrm{I}\\) and \\(s_\\mathrm{Q}\\) signals to analog and pulse-shaping filtering) is represented as\n\\[\ns_\\mathrm{BB}(t) = s_\\mathrm{I}(t) + j s_\\mathrm{Q}(t).\n\\]\nWe want to shift this signal to the carrier frequency \\(f_\\mathrm{c}\\), which can be done by multiplying with a complex exponential:\n\\[\ns_\\mathrm{RF,complex}(t) = s_\\mathrm{BB}(t) \\cdot e^{j \\omega_\\mathrm{c} t} = [s_\\mathrm{I}(t) + j s_\\mathrm{Q}(t)] \\cdot [\\cos(\\omega_\\mathrm{c} t) + j \\sin(\\omega_\\mathrm{c} t)].\n\\]\nThe real-valued RF signal is obtained by taking the real part of this expression:\n\\[\ns_\\mathrm{RF}(t) = \\Re \\{ s_\\mathrm{RF,complex}(t) \\} = s_\\mathrm{I}(t) \\cos(\\omega_\\mathrm{c} t) - s_\\mathrm{Q}(t) \\sin(\\omega_\\mathrm{c} t).\n\\tag{19}\\]\nThe process formulated in Equation 19 is done in the TX, as shown in Figure 11.\n\n\n\n\n\n\n\n\nFigure 11: TX modulator.\n\n\n\n\n\nThe RF signal generation according to Equation 19 is called quadrature modulation. This is the modulation used most often in modern communication systems, as it allows to transmit two independent signals (I and Q) in the same bandwidth. The I and Q signals are also called quadrature components, as they are 90° out of phase with each other.\nAlternatively, a modulation called polar modulation can be used, where the amplitude and phase of the carrier are varied according to the baseband signal. This is done by converting the I and Q signals to polar coordinates\n\\[\ns_\\mathrm{RF}(t) = \\Re \\{ A(t) \\cdot e^{j \\varphi(t)} \\cdot e^{j \\omega_\\mathrm{c} t} \\}\n\\]\nwith\n\\[\nA(t) = \\sqrt{s_\\mathrm{I}^2(t) + s_\\mathrm{Q}^2(t)}, \\quad \\varphi(t) = \\tan^{-1}\\left(\\frac{s_\\mathrm{I}(t)}{s_\\mathrm{Q}(t)}\\right).\n\\]\nAs the mathematical operations required for the cartesian to polar transformation are quite nonlinear, the \\(A(t)\\) and \\(\\phi(t)\\) signals are wideband. Some wireless standards allow efficient use of polar modulation, for example Bluetooth, where basically all TX are realized as polar modulators.\nIn the RX, the received RF signal is downconverted to baseband by a similar process, as shown in Figure 12.\n\n\n\n\n\n\n\n\nFigure 12: RX demodulator.\n\n\n\n\n\nFor demodulation we have to shift the RF signal down to baseband, which mathematically is done by multiplying with the complex conjugate of the carrier:\n\\[\ns_\\mathrm{BB,complex}(t) = s_\\mathrm{RF}(t) \\cdot e^{-j \\omega_\\mathrm{c} t} = s_\\mathrm{RF}(t) \\cdot [\\cos(\\omega_\\mathrm{c} t) - j \\sin(\\omega_\\mathrm{c} t)]\n\\tag{20}\\]"
  },
  {
    "objectID": "rfic.html#filtering",
    "href": "rfic.html#filtering",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.3 Filtering",
    "text": "3.3 Filtering\nFiltering is an essential function in both TX and RX. In the TX, filtering is used to limit the bandwidth of the transmitted signal to the allocated channel bandwidth, and to suppress out-of-band emissions. In the RX, filtering is used to select the wanted signal from a crowded spectrum, and to suppress unwanted signals (blockers) that can cause interference or desensitization of the RX. A typical example of filtering in the RX is shown in Figure 13, where a bandpass filter is used to attenuate strong unwanted blockers while only slightly attenuating the wanted signal.\n\n\n\n\n\n\n\n\nFigure 13: Filtering of wanted channel amid strong unwanted blockers. Exemplary shown in an RX scenario around 900 MHz. The strong blockers (top figure) are attenuated by an RF bandpass filter (bottom figure) with a bandwidth of 20 MHz, achieving more than 40 dB rejection of the blockers while only slightly attenuating the wanted signal.\n\n\n\n\n\nIn any filter there exists a fundamental trade-off between selectivity (steepness of the filter skirts), bandwidth, and insertion loss. A very selective filter with steep skirts and large BW will have a high insertion loss. Conversely, a filter with low insertion loss will have a gentle roll-off and may not sufficiently suppress unwanted signals. A useful metric to quantify the performance of a filter is the quality factor \\(Q\\), defined as\n\\[\nQ = \\frac{f_\\mathrm{c}}{\\Delta f}\n\\]\nwhere \\(f_\\mathrm{c}\\) is the center frequency and \\(\\Delta f\\) is the –3 dB bandwidth of the filter. A higher \\(Q\\) indicates a more selective filter.\nThe achievable \\(Q\\) depends on the filter technology used. For example, on-chip LC filters can achieve \\(Q\\) values of around 10-20, while off-chip SAW or BAW/FBAR filters can achieve \\(Q\\) values of several hundreds, and a crystal filter can achieve \\(Q\\) values of several thousands. The choice of filter technology depends on the application requirements, such as frequency range, bandwidth, insertion loss, and cost. Generally speaking, the required filtering to single out the wanted signal in the RX spectrum and decrease the power of strong blockers to a tolerable level is one of the most critical design choices, and is usually distributed at different locations in the RX chain:\n\nRF filters (between antenna and LNA) provide a first level of filtering, and are usually implemented as off-chip SAW or BAW/FBAR filters. They provide high \\(Q\\) and good selectivity, but have a fixed center frequency and bandwidth. They are used to pass the wanted band of interest, and to attenuate strong out-of-band blockers.\nIF filters (in case of a super-heterodyne receiver) provide additional filtering, and can be implemented as on-chip LC filters or off-chip SAW/BAW filters. They provide moderate \\(Q\\) and selectivity, and can be tuned to some extent.\nBB filters (after downconversion) provide the final level of filtering before entering the ADCs, and are usually implemented as on-chip active RC filters. They provide channel selection, and can be easily adjusted to different bandwidths.\nDigital filters (in the DSP block) provide the final level of filtering and signal processing, and can be implemented as FIR or IIR filters. They provide high flexibility and can be easily adapted to different standards and requirements. Digital filters show now variations, so they can be designed to be very selective.\n\nIt is important to note (because this dictates a lot of choices in RF design) that high-\\(Q\\) filters are usually fixed-frequency and fixed-bandwidth. Only baseband and digital filters can be easily adjusted to different bandwidths!\n\n\n\n\n\n\nImportantFilter Technologies\n\n\n\nBaseband filters (analog) are usually implemented as active \\(RC\\) filters on-chip. They are very flexible and can have adjustable bandwidth by either changing \\(R\\) and/or \\(C\\). For medium frequencies \\(g_\\mathrm{m}-C\\) filters can be used, which are also tunable by changing the transconductance \\(g_\\mathrm{m}\\) and/or \\(C\\). For even higher bandwidths, on-chip LC filters can be used, which have a limited \\(Q\\) of around 10-20.\nBaseband filters (digital) are implemented as FIR or IIR filters in the DSP block. They are very flexible and can be easily adapted to different standards and requirements. Digital filters show now variations, so they can be designed to be very selective.\nSurface acoustic wave (SAW) and bulk acoustic wave (BAW/FBAR) filters are off-chip components that can achieve high \\(Q\\) values of several hundreds. They have a fixed center frequency and bandwidth. Usually 1-2 such filters are required per supported band of interest.\nCrystal filters can achieve very high \\(Q\\) values of several thousands, but are usually bulky and expensive.\nLC filters can be either implemented off-chip (using discrete components) or on-chip. Off-chip LC filters can achieve higher \\(Q\\) values than on-chip LC filters, but are usually larger and more expensive. On-chip LC filters are limited in \\(Q\\) (around 10-20), but are very compact and can be integrated into the RFIC. Off-chip LC filters can achieve \\(Q\\) values of around 50-100, depending on the frequency and component quality.\nCeramic filters are another off-chip filter technology that can achieve moderate to high \\(Q\\) values (up to several hundreds). They are usually smaller and less expensive than SAW or BAW/FBAR filters, but also lower performance.\nWaveguide filters are used at very high frequencies (above 10 GHz) and can achieve very high \\(Q\\) values (up to several thousands). They are usually bulky and expensive, and are not commonly used in mobile applications, but rather in fixed installations like base stations or satellite communication.\n\n\nFundamentally, the choice of filter technology is a trade-off between performance, size, cost, and flexibility. In most cases, a combination of different filter technologies is used to achieve the desired performance."
  },
  {
    "objectID": "rfic.html#direct-conversion-architecture",
    "href": "rfic.html#direct-conversion-architecture",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.4 Direct-Conversion Architecture",
    "text": "3.4 Direct-Conversion Architecture\nThe transceiver architecture shown in Figure 10 is called direct-conversion or zero-IF architecture, as the downconversion in the RX and upconversion in the TX is done in a single step. This architecture several advantages:\n\nPer RX and TX a single LO is required (which can even be shared between RX and TX in TDD operation).\nThere are a minimum number of RF blocks, which good for cost and power consumption.\nThis architecture is very flexible and can be easily adapted to different standards and requirements, and shows generally very good performance if the disadvantages can be overcome by good design.\nThis architecture allows a high integration level, as basically all blocks can be implemented on-chip.\nDirect conversion is the de-facto standard architecture for cellular, WiFi, Bluetooth (with the exception of the TX), and GNSS.\n\nHowever, the direct-conversion architecture also has some disadvantages:\n\nLO-RF coupling can cause self-mixing and desensitization of the RX, as well as LO leakage in the TX. This is an issue because the LO frequency is the same as the RF frequency.\nEven-order distortion products (especially IIP2) cause sensitivity degradation due to strong amplitude-modulated blockers.\nLO pulling can occur in the TX (again, LO and RF are at the same frequency).\nIQ errors (gain and phase mismatch) of the \\(I\\) and \\(Q\\) paths can cause constellation distortion leading to increased error vector magnitude (EVM).\nDC offsets can occur due to self-mixing of LO leakage and even-order distortion products.\nFlicker noise (1/f noise) upconversion can cause increased phase noise close to the carrier, as well as increased RX noise figure.\n\nNowadays there exist good design techniques to mitigate these disadvantages. However, in some cases (for example very high linearity requirements, or very high frequencies) other architectures like low-IF or super-heterodyne may be preferred."
  },
  {
    "objectID": "rfic.html#duplexing",
    "href": "rfic.html#duplexing",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.5 Duplexing",
    "text": "3.5 Duplexing\nIn the block diagram of Figure 10, we have not yet considered how to share the antenna between RX and TX. Essentially, there are two main methods to achieve this: frequency-division duplex (FDD) and time-division duplex (TDD).\n\n3.5.1 Frequency-Division Duplex (FDD)\nIn FDD, the RX and TX operate at different frequencies, separated by a duplex distance. This allows simultaneous transmission and reception, which is beneficial for applications like voice communication where low latency is required. However, FDD requires two separate frequency bands, which can be a limitation in terms of spectrum availability. Additionally, FDD requires two PLLs to generate the RX and TX LO frequencies, which increases complexity and power consumption.\nThe RF RX and TX paths are connected to the antenna via a duplexer, which is a three-port device that allows signals to pass between the antenna and the RX or TX path, while isolating the RX and TX paths from each other. A typical FDD TRX block diagram is shown in Figure 14.\n\n\n\n\n\n\n\n\nFigure 14: Block diagram of an FDD RF front-end.\n\n\n\n\n\nAdvantages of FDD:\n\nRX and TX can operate simultaneously, which is beneficial for low-latency applications.\nThere is no need for fast switching between RX and TX, which simplifies the design.\nRelaxed synchronization requirements between RX and TX and different users.\n\nDisadvantages of FDD:\n\nDuplexers are costly components, which significant insertion loss depending on filtering requirements.\nRequires two separate frequency bands, which can be a limitation in terms of spectrum availability, and MIMO channel estimation.\nThe large TX causes severe desensitization of the RX, which requires high linearity and good filtering (50 dB to 60 dB).\n\n\n\n3.5.2 Time-Division Duplex (TDD)\nIn TDD, the RX and TX share the same frequency band but operate at different times. This allows for more efficient use of the available spectrum, as the same frequency can be used for both transmission and reception. TDD is particularly well-suited for applications with asymmetric traffic patterns, where the data rate in one direction is significantly higher than in the other. However, TDD requires precise timing control to avoid interference between RX and TX periods, which can increase complexity. In TDD, a single PLL can be used to generate the LO frequency for both RX and TX, which reduces complexity and power consumption. The RF RX and TX paths are connected to the antenna via a switch, which alternates between connecting the antenna to the RX path and the TX path. A typical TDD TRX block diagram is shown in Figure 15.\n\n\n\n\n\n\n\n\nFigure 15: Block diagram of a TDD RF front-end.\n\n\n\n\n\nAdvantages of TDD:\n\nMore efficient use of the available spectrum, as the same frequency can be used for both RX and TX.\nA single PLL can be used for both RX and TX, which reduces complexity and power consumption.\nNo duplexer is required (just a single band filter), which reduces cost and insertion loss.\nNo RX blocking by own TX, which relaxes linearity and filtering requirements.\nEasier to implement MIMO, as all antennas can operate in the same frequency band.\n\nDisadvantages of TDD:\n\nRX and TX cannot operate simultaneously, which can be a limitation for low-latency applications.\nRequires precise timing control to avoid interference between RX and TX periods, which can increase complexity.\nSynchronization between RX and TX and different users is required, which can be challenging in some scenarios.\n\n\n\n3.5.3 Comparison of FDD and TDD\nBelow is a summary of important wireless standards and their duplexing method as shown in Table 3:\n\n\n\nTable 3: Comparison of duplexing methods used by major wireless standards\n\n\n\n\n\n\n\n\n\n\nWireless Standard\nDuplexing Method\nComments\n\n\n\n\nGSM (2G)\nFDD & TDMA\nTX and RX operate at different frequencies (FDD) and different times (TDMA)\n\n\nUMTS (3G)\nFDD\nTraditional cellular standard using paired spectrum\n\n\nLTE (4G)\nFDD/TDD\nFDD is used mostly &lt;2.7 GHz, TDD is used &gt;2.3 GHz\n\n\n5G NR\nFDD/TDD\nFDD is used mostly &lt;2.7 GHz, TDD is used &gt;2.3 GHz\n\n\nWiFi (802.11)\nTDD\nUnlicensed spectrum operation\n\n\nBluetooth\nTDD\nShort-range personal area network\n\n\nZigbee\nTDD\nLow-power IoT applications\n\n\n\n\n\n\nAs you can see in Table 3, there is a tendency to use FDD for lower frequencies and large communication distances, while TDD is preferred for higher frequencies and smaller distances."
  },
  {
    "objectID": "rfic.html#specialty-architectures",
    "href": "rfic.html#specialty-architectures",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.6 Specialty Architectures",
    "text": "3.6 Specialty Architectures\nIn some cases, other architectures may be preferred over the direct-conversion architecture. During the evolution of wireless communication, many different architectures have been proposed and used. However, only a few of them are still relevant today. Some examples are shown next.\n\n3.6.1 Super-Heterodyne Architecture\nThe super-heterodyne architecture is a widely used approach in radio. It works by mixing the incoming/outgoing RF signal with an LO to produce an intermediate frequency (IF) signal. This IF signal is then amplified and processed, allowing for better selectivity and sensitivity compared to direct-conversion architectures. Super-heterodyne receivers/transmitters are known for their excellent performance in terms of image rejection and dynamic range, making them suitable for a variety of applications, including traditional analog TV and radio broadcasting. As simplified block diagram of a super-heterodyne transceiver is shown in Figure 16.\n\n\n\n\n\n\n\n\nFigure 16: Block diagram of a super-heterodyne transceiver (TRX) showing the main functional blocks of RX and TX.\n\n\n\n\n\nWhen you compare Figure 10 with Figure 16, you can immediately appreciate the increased complexity of the super-heterodyne architecture. It requires two PLLs to generate the RX and TX LO frequencies, as well as additional mixers and filters for the IF stage. This increases cost, power consumption, and size. However, the super-heterodyne architecture can provide better performance in terms of selectivity and sensitivity, especially in challenging RF environments with strong blockers, as it allows filtering at RF, IF, and baseband frequencies.\nOne important aspect of super-heterodyne receivers is the choice of the intermediate frequency (IF). The IF should be high enough to allow for effective filtering and image rejection, but low enough to avoid excessive complexity and power consumption. Common IF frequencies range from a few MHz to several hundred MHz, depending on the application and frequency band.\nAn important issue in super-heterodyne receivers is the image frequency. The image frequency is a spurious frequency that can interfere with the desired signal, and is located at \\(f_\\mathrm{image} = f_\\mathrm{RF} \\pm 2 f_\\mathrm{IF}\\) (the signs depends on the choice of high-side or low-side mixing). To suppress the image frequency, an image-reject filter is either placed before (RX) or after (TX) the mixer. The design of this filter is critical, as it must provide sufficient attenuation of the image frequency while maintaining low insertion loss for the desired signal.\nAn alternative to image filtering is the use of active image rejection techniques, such as the Hartley or Weaver architectures. These techniques use additional mixers and phase shifters to cancel out the image frequency, allowing for improved performance without the need for a dedicated image-reject filter.\n\n\n3.6.2 Low-IF Architecture\nTo avoid some of the issues of direct-conversion architectures (like dc offsets and flicker noise), a low-IF architecture can be used. In a low-IF architecture, the RX and TX signals are mixed to a low intermediate frequency (typically a few MHz to tens of MHz) instead of directly to baseband. This allows for easier filtering of DC offsets and flicker noise, while still maintaining the benefits of a single LO and reduced complexity compared to super-heterodyne architectures. A low-IF architecture is shown in Figure 17.\n\n\n\n\n\n\n\n\nFigure 17: Block diagram of a low-IF transceiver (TRX) showing the main functional blocks of RX and TX. Note the usage of complex analog and digital baseband filters. Otherwise, the structure is similar to a zero-IF TRX as shown in Figure 10.\n\n\n\n\n\nThe low-IF architecture is the defacto standard for Bluetooth receivers. Its advantage compared to direct-conversion vanishes for larger channel bandwidths, this is why it is not used for cellular or WiFi (GSM receivers might be an exception).\nOne noteworthy disadvantage of low-IF architectures is the required 2xBW compared to direct-conversion. This might cause increased power consumption in the analog baseband filters and ADCs/DACs. Additionally, the low-IF architecture still requires careful design to mitigate issues like IQ imbalance and LO leakage, although these issues are generally less severe than in direct-conversion architectures.\n\n\n3.6.3 Super Simple Architecture\nFor some applications with very low cost and low performance requirements, a super simple architecture can be used (think garage door opener). In this architecture, the RX and TX paths are stripped down to the bare minimum. A super simple receiver just uses a bandpass filter and an envelope detector, while a super simple transmitter uses an oscillator and power amplifier. These simplified architectures are shown in Figure 18.\n\n\n\n\n\n\n\n\nFigure 18: Block diagram of a super simple TX and RX.\n\n\n\n\n\nDespite the simple architecture, digital amplitude-shift-keying (ASK) or on-off-keying (OOK) can be used. If the receiver is able to discriminate between frequencies (e.g., by using two RF filters with an envelope detector each), also frequency-shift-keying (FSK) can be used."
  },
  {
    "objectID": "rfic.html#iq-imbalance",
    "href": "rfic.html#iq-imbalance",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.7 I/Q Imbalance",
    "text": "3.7 I/Q Imbalance\nIn direct-conversion and low-IF architectures, the I and Q paths are used to process the in-phase and quadrature components of the signal. Ideally, these paths should have identical gain and a 90° phase difference. However, in practice, there are always some mismatches between the I and Q paths, leading to I/Q imbalance. This imbalance can cause constellation distortion, leading to increased error vector magnitude (EVM) and degraded system performance.\nI/Q imbalance can be characterized by two parameters: gain mismatch (\\(\\Delta G\\)) and phase mismatch (\\(\\Delta \\varphi\\)). Gain mismatch refers to the difference in gain between the I and Q paths, while phase mismatch refers to the deviation from the ideal 90° phase difference. The impact of I/Q imbalance on system performance depends on the modulation scheme used, with higher-order modulations being more sensitive to these impairments.\nThere are two ways to quantify I/Q imbalance:\n\nImage rejection ratio (IRR): The IRR is a measure of how well the receiver can reject the image frequency caused by I/Q imbalance. It is defined as the ratio of the power of the desired signal to the power of the image (unwanted) signal, typically expressed in dB. A higher IRR indicates better performance, with values above 30 dB to 40 dB generally considered acceptable for most applications.\nError vector magnitude (EVM): The EVM is a measure of the difference between the ideal transmitted signal and the received signal, expressed as a percentage of the signal’s magnitude. It quantifies the overall distortion in the received signal, including the effects of I/Q imbalance. Lower EVM values indicate better performance, with typical requirements ranging from 1% to 10% depending on the modulation scheme and application.\n\nThe EVM (in rms) is defined as\n\\[\n\\text{EVM} = \\frac{\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} |s_\\mathrm{ideal}(i) - s_\\mathrm{meas}(i)|^2}}{\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} |s_\\mathrm{ideal}(i)|^2}}\n\\tag{21}\\]\nwhere \\(s_\\mathrm{ideal}(i)\\) is the ideal transmitted symbol, \\(s_\\mathrm{meas}(i)\\) is the measured received symbol, and \\(N\\) is the number of symbols. EVM is expressed either in percent or in dB using\n\\[\n\\text{EVM}|_\\mathrm{dB} = 20 \\cdot \\log_{10}(\\text{EVM}).\n\\]\nIn order to make the I/Q mismatch sufficiently small, among the possible techniques are:\n\nCareful layout and matching of the components in the I and Q paths to minimize gain and phase mismatches. This usually involves good layout techniques. Further, the LO I/Q generation should be done with high accuracy.\nCalibration techniques can be used to measure and compensate for I/Q imbalance. This can be done either in the analog domain (e.g., using variable gain amplifiers and phase shifters) or in the digital domain (e.g., using digital signal processing algorithms). Digital compensation is usually preferred, as it is more flexible and can adapt to changing conditions. A CORDIC can be readily used for this purpose."
  },
  {
    "objectID": "rfic.html#sec-lna-resistive-matching",
    "href": "rfic.html#sec-lna-resistive-matching",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "4.1 Resistively Matched Common-Source LNA",
    "text": "4.1 Resistively Matched Common-Source LNA\nThe key question is now how to design an LNA with low noise figure and an input impedance matched to 50 Ω? In order to appreciate this design challenge, we will first try a naive approach, using a common-source amplifier with resistive termination, as shown in Figure 20.\n\n\n\n\n\n\n\n\nFigure 20: A simple LNA with resistive input matching and a tank circuit as a load (biasing details are omitted). The LNA is driven by a 50 Ω source.\n\n\n\n\n\nIf we assume the gate capacitance of \\(M_1\\) negligible, we can achieve good input impedance matching by choosing \\(R_\\mathrm{s} = R_\\mathrm{p} = 50\\,\\Omega\\). The voltage gain of this simple common-source LNA is given by \\(A_\\mathrm{v} = -g_\\mathrm{m}R_\\mathrm{D}\\), neglecting capacitances and \\(g_\\mathrm{ds}\\) of \\(M_1\\) (we assume that the load tank is tuned to the desired frequency with \\(\\omega_0 = 1 / \\sqrt{L C}\\)).\nHow can we calculate the noise figure of this simple LNA? We formulate\n\\[\nF = \\frac{\\text{total noise at output}}{\\text{noise at output due to source only}}.\n\\tag{22}\\]\nWe derive a small-signal equivalent circuit of Figure 20, which is shown in Figure 21, to calculate the total noise at the output of the LNA.\n\n\n\n\n\n\n\n\nFigure 21: Equivalent circuit of resistively matched common-source LNA.\n\n\n\n\n\nWithe the help of Figure 21, we can calculate the total output noise power spectral density as\n\\[\n\\overline{V_\\mathrm{n,out,1}^2} = A_\\mathrm{v}^2 \\cdot 4 k T (R_\\mathrm{s} \\parallel R_\\mathrm{p}) = (g_\\mathrm{m}R_\\mathrm{D})^2 \\cdot 4 k T (R_\\mathrm{s} \\parallel R_\\mathrm{p})\n\\]\nand\n\\[\n\\overline{I_\\mathrm{n,out}^2} = 4 k T \\gamma g_\\mathrm{m}+ \\frac{4 k T}{R_\\mathrm{D}}\n\\] \\[\n\\overline{V_\\mathrm{n,out,2}^2} = R_\\mathrm{D}^2 \\cdot \\overline{I_\\mathrm{n,out}^2} = 4 k T \\gamma g_\\mathrm{m}R_\\mathrm{D}^2 + 4 k T R_\\mathrm{D}\n\\]\nso that in total\n\\[\n\\overline{V_\\mathrm{n,out}^2} = \\overline{V_\\mathrm{n,out,1}^2} + \\overline{V_\\mathrm{n,out,2}^2} = 4 k T \\left[ (g_\\mathrm{m}R_\\mathrm{D})^2 (R_\\mathrm{s} \\parallel R_\\mathrm{p}) + \\gamma g_\\mathrm{m}R_\\mathrm{D}^2 + R_\\mathrm{D} \\right].\n\\tag{23}\\]\nWe now need to find the output noise coming from the source only. For this we can use the equivalent circuit in Figure 22, to formulate the output noise due to the source only.\n\n\n\n\n\n\n\n\nFigure 22: Eqivalent circuit to calculate the output noise from the input.\n\n\n\n\n\nWe find that\n\\[\n\\overline{V_\\mathrm{n,out,s}^2} = A_\\mathrm{v}^2 \\cdot 4 k T R_\\mathrm{s} \\cdot \\left(\\frac{R_\\mathrm{p}}{R_\\mathrm{s} + R_\\mathrm{p}}{} \\right)^2.\n\\tag{24}\\]\nFinally, we can use Equation 23 and Equation 24 with Equation 22 to calculate the noise figure of the simple resistively matched common-source LNA as\n\\[\nF = \\frac{\\overline{V_\\mathrm{n,out}^2}}{\\overline{V_\\mathrm{n,out,s}^2}} = 1 + \\frac{R_\\mathrm{s}}{R_\\mathrm{p}} + \\frac{\\gamma R_\\mathrm{s}}{g_\\mathrm{m}(R_\\mathrm{s} \\parallel R_\\mathrm{p})^2} + \\frac{R_\\mathrm{s}}{g_\\mathrm{m}^2 (R_\\mathrm{s} \\parallel R_\\mathrm{p})^2 R_\\mathrm{D}}.\n\\tag{25}\\]\n\n\n\n\n\n\nNoteCommon-source LNA with Resistive Matching\n\n\n\nAs an exercise to calculate circuits with noise, re-confirm and derive yourself the result of Equation 25.\n\n\nHow can we interpret Equation 25? We see that we can minimize the noise factor by making \\(g_\\mathrm{m}\\) large. Then we have a noise factor of\n\\[\nF = 1 + \\frac{R_\\mathrm{s}}{R_\\mathrm{p}} = 2\n\\]\nso we see that we are limited to a minimum noise figure of 3 dB, even if we spend the bias current to make \\(g_\\mathrm{m}\\) very large. We can go below 3 dB noise figure only if we choose \\(R_\\mathrm{p} &gt; R_\\mathrm{s}\\), however, this means that the input is no longer matched to 50 Ω, which is usually not acceptable. Hence, this simple resistively matched common-source LNA is not a good choice for a low-noise amplifier, with one exception: For very wideband amplifiers, where a NF of larger then 3 dB is acceptable, this configuration might be a good choice.\nWe see that we are stuck at high noise figures if we realize the real part of the input impedance with a resistor. This leaves us with the question on how to realize a real part of the input impedance then? We will answer this question in the next section."
  },
  {
    "objectID": "rfic.html#sec-lna-common-gate",
    "href": "rfic.html#sec-lna-common-gate",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "4.2 Common-Gate LNA",
    "text": "4.2 Common-Gate LNA\nWe remember from our analog circuit design lecture that the common-gate configuration has an input impedance of \\(1/g_\\mathrm{m}\\), neglecting parasitic capacitances. Hence, if we choose \\(g_\\mathrm{m}= 1/50\\,\\Omega = 20\\,\\text{mS}\\), we can achieve input matching to 50 Ω without using a resistor at the input. This is the key idea of the common-gate LNA, which is shown in Figure 23.\n\n\n\n\n\n\n\n\nFigure 23: Circuit diagram of a common-gate LNA.\n\n\n\n\n\nBy inspecting Figure 23 and the practice from Section 4.1, we can directly write down the output noise voltage as (with \\(1/g_\\mathrm{m}= R_\\mathrm{s}\\))\n\\[\n\\overline{V_\\mathrm{n,out}^2} = k T \\left[ (g_\\mathrm{m}R_\\mathrm{D})^2 R_\\mathrm{s} + \\gamma g_\\mathrm{m}R_\\mathrm{D}^2 + 4 R_\\mathrm{D} \\right] = k T \\left( \\frac{R_\\mathrm{D}^2}{R_\\mathrm{s}} + \\gamma \\frac{R_\\mathrm{D}^2}{R_\\mathrm{s}} + 4 R_\\mathrm{D} \\right).\n\\tag{26}\\]\nThe output noise due to the source only is given by\n\\[\n\\overline{V_\\mathrm{n,out,s}^2} = \\frac{R_\\mathrm{D}^2}{R_\\mathrm{s}}.\n\\tag{27}\\]\nFinally, we can use Equation 26 and Equation 27 with Equation 22 to calculate the noise figure of the common-gate LNA as\n\\[\nF = 1 + \\gamma + \\frac{4 R_\\mathrm{s}}{R_\\mathrm{D}}  \\xrightarrow{R_\\mathrm{D} \\gg R_\\mathrm{s}} F = 1 + \\gamma .\n\\tag{28}\\]\nWith a classical long-channel \\(\\gamma = 2/3\\), we can achieve a minimum noise figure of 2.2 dB, which is already better than the resistively matched common-source LNA. However, with modern short-channel devices, \\(\\gamma\\) is often larger than 1, so that the minimum noise figure of the common-gate LNA is often larger than 3 dB (Razavi 2011)."
  },
  {
    "objectID": "rfic.html#sec-lna-inductive-degeneration",
    "href": "rfic.html#sec-lna-inductive-degeneration",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "4.3 Inductively-Degenerated Common-Source LNA",
    "text": "4.3 Inductively-Degenerated Common-Source LNA\nAs we have seen in Section 4.2, using circuit techniques can realize a real part of an input impedance without the associated thermal noise of a resistor. We now try something different, in the hope that it will result in an even lower noise figure. We construct an LNA based on a common-source MOSFET amplifier, but we add an impedance \\(Z_\\mathrm{deg}\\) into the source line. This arrangement is shown in Figure 24.\n\n\n\n\n\n\n\n\nFigure 24: A common-source MOSFET stage with degeneration impedance.\n\n\n\n\n\nWe now extract the small-signal equivalent circuit of Figure 24, which is shown in Figure 25, to calculate the input impedance.\n\n\n\n\n\n\n\n\nFigure 25: Equivalent small-signal circuit of the input stage around \\(M_1\\).\n\n\n\n\n\nWe find that\n\\[\nv_\\mathrm{x} = v_\\mathrm{gs} + Z_\\mathrm{deg} (i_\\mathrm{x} + g_\\mathrm{m}v_\\mathrm{gs}), \\quad v_\\mathrm{gs} = \\frac{i_\\mathrm{x}}{s C_\\mathrm{gs}}\n\\]\nso that we can write the input impedance as\n\\[\nZ_\\mathrm{in} = \\frac{v_\\mathrm{x}}{i_\\mathrm{x}} = \\frac{1}{s C_\\mathrm{gs}} + Z_\\mathrm{deg} + \\frac{g_\\mathrm{m}Z_\\mathrm{deg}}{s C_\\mathrm{gs}}.\n\\tag{29}\\]\nThe final term in Equation 29 is the interesting one: By choosing \\(Z_\\mathrm{deg}\\) to be inductive (which we can do by either use an on-chip or off-chip inductor), we can realize a real part of the input impedance. If we choose \\(Z_\\mathrm{deg} = s L\\), we find that\n\\[\nZ_\\mathrm{in} = \\frac{1}{s C_\\mathrm{gs}} + s L + \\frac{g_\\mathrm{m}L}{C_\\mathrm{gs}}.\n\\]\nBy proper choice of \\(L\\) and \\(C_\\mathrm{gs}\\), we can achieve input matching to 50 Ω at the desired frequency \\(\\omega_0\\). We find that the real part of the input impedance is given by\n\\[\n\\Re \\{ Z_\\mathrm{in} \\} = \\frac{g_\\mathrm{m}L}{C_\\mathrm{gs}}\n\\]\nWithout proof (refer to (Razavi 2011) or (Darabi 2020) for a derivation) we find for the noise factor of this input stage (with some simplification) as\n\\[\nF = 1 + \\frac{\\gamma R_\\mathrm{s} \\omega_0^2 C_\\mathrm{gs}^2}{g_\\mathrm{m}}.\n\\tag{30}\\]\nFinally we have an LNA input stage configuration which allows us to achieve a noise figure below 3 dB, even with \\(\\gamma &gt; 1\\), by proper choice of \\(g_\\mathrm{m}\\). Making \\(g_\\mathrm{m}\\) large (by spending more bias current) results in (first order) arbitrarily low noise figure. The inductively-degenerated common-source LNA is a widely used LNA input stage configuration in modern RFICs. A somewhat detailed schematic is shown in Figure 26.\n\n\n\n\n\n\n\n\nFigure 26: An (almost complete) common-source MOSFET stage with degeneration impedance and cascode.\n\n\n\n\n\nThe inductor \\(L_\\mathrm{match}\\) is used to match the input impedance to 50 Ω at the desired frequency, \\(L_\\mathrm{deg}\\) is used to realize the real part of the input impedance, \\(R_\\mathrm{bias}\\) is used to set the bias current of \\(M_1\\), \\(M_2\\) is a cascode transistor which increases the output impedance and thus the gain of the stage (plus it improves the reverse isolation), and \\(R_\\mathrm{D}\\), \\(L_\\mathrm{D}\\), and \\(C_\\mathrm{D}\\) form a load tank which provides high gain at the desired frequency. A dc block is used at the input so that the bias point of \\(M_1\\) is not corrupted by the input signal source. The bias voltage \\(V_\\mathrm{bias2}\\) sets the operating point of the cascode transistor \\(M_2\\).\nWhat is missing in Figure 26 is any form of frequency tuning of the load to the frequency of interest, and the support of different gain modes. Apart from these details this LNA circuit is a good starting point for a practical LNA design."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "",
    "text": "Radio-Frequency Integrated Circuits\n\n\n\nQuarto Publish\n\n\n(c) 2025 Harald Pretl and co-authors, Department for Integrated Circuits (ICD), Johannes Kepler University, Linz (JKU)\nThis is the material for a graduate-level radio-frequency integrated circuit course, held at JKU under course number 336.023 (“VO Integrierte Hochfrequenz-Schaltungstechnik”). Follow this link to access the material.\nAll course material is made publicly available and shared under the Apache-2.0 license.\nWe happily accept pull requests to fix typos or add content! If you want to discuss something that is not clear, please open an issue!"
  }
]