[
  {
    "objectID": "rfic.html#sec-intro-wireless",
    "href": "rfic.html#sec-intro-wireless",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "1.1 Wireless Transmission",
    "text": "1.1 Wireless Transmission\nIn wireless transmission, we usually want to transmit data via a transmitter (TX) and a connected antenna to a receiver (RX) using an electromagnetic (EM) wave. This arrangement is shown in Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: The block diagram of a simple wireless system.\n\n\n\n\n\nUnfortunately, wireless transmission is hard. The wireless channel, i.e., the usage of electromagnetic waves to transmit information from a transmitter to a receiver, while tremendously useful, unfortunately has quite a few undesired features:\n\nThe wireless channel is shared between all users.\nAs a consequence, the available bandwidth is shared; this means that bandwidth is a scarce resource.\nThe wireless channel has significant losses.\nThe channel is time variant, as usually the transmitter and/or the receiver move, and/or the environment changes.\n\nIn order to estimate the power \\(P_\\mathrm{R}\\) of the wireless transmission at the receiver we can use Friis’ transmission formula (Pozar 2011):\n\\[\nP_\\mathrm{R} = \\frac{P_\\mathrm{T}}{4 \\pi d^2} \\cdot A_\\mathrm{R} = P_\\mathrm{T} \\cdot \\frac{A_\\mathrm{R} \\cdot A_\\mathrm{T}}{d^2 \\lambda^2}\n\\tag{1}\\]\nHere, \\(A_\\mathrm{R}\\) (and \\(A_\\mathrm{T}\\)) is the effective area of the receive/transmit antenna, while \\(d\\) is the distance (line of sight) between the two antennas. The effective area of an antenna depends on the type and construction, but generally we can say that\n\\[\nA \\propto \\lambda^2\n\\]\nFor an isotropic antenna (a theoretical construct where the radiation is equal in all directions) \\(A = \\lambda^2 / (4 \\pi)\\), while for a \\(\\lambda/2\\)-dipole \\(A = 0.13 \\lambda^2\\). Of course, the speed of light \\(c\\) relates frequency \\(f\\) and wavelength \\(\\lambda\\) of an electromagnetic wave by\n\\[\nc = \\lambda f.\n\\]\nGenerally speaking, the size of an electromagnetic antenna is proportional to the wavelength of the EM wave use for transmission. For man devices, we seek antennas on the order of a few centimeters, and this is why frequencies in the hundreds of MHz to GHz are so popular. Table 1 lists a few typical applications and their frequency and wavelength.\n\n\n\nTable 1: Typical RF applications with their operating frequencies and corresponding wavelengths\n\n\n\n\n\nApplication\nFrequency\nWavelength\n\n\n\n\nFM Radio\n88–108 MHz\n2.8-3.4 m\n\n\nWiFi (lowband)\n2.4 GHz\n12.5 cm\n\n\nWiFi (highband)\n5 GHz\n6 cm\n\n\nBluetooth\n2.4 GHz\n12.5 cm\n\n\nCellular\n0.6–5 GHz\n6-50 cm\n\n\nGNSS\n1.575 GHz\n19 cm\n\n\n\n\n\n\nAs you can see in Table 1 many of these antennas would not fit into the used device form factors, i.e., often we have to use electrically small antennas.\n\n\n\n\n\n\nNote 1: Wavelength Calculation\n\n\n\nLet’s calculate the wavelength for a Bluetooth signal at 2.4 GHz. Given:\n\nFrequency \\(f = 2.4\\) GHz \\(= 2.4 \\times 10^9\\) Hz\n\nSpeed of light \\(c = 3 \\times 10^8\\) m/s\n\nUsing the relationship \\(c = \\lambda f\\), we can solve for wavelength:\n\\[\\lambda = \\frac{c}{f} = \\frac{3 \\times 10^8 \\text{ m/s}}{2.4 \\times 10^9 \\text{ Hz}} = 0.125 \\text{ m} = 12.5 \\text{ cm}\\]\nThis means that a quarter-wavelength monopole antenna for 2.4 GHz Bluetooth would be approximately 3.1 cm long, which easily fits into most mobile devices.\n\n\nIn order to get a feeling for the attenuation experienced in wireless communication, we now calculate the following exemplary transmission. We will use the unit of dBm with is often used in RF design and is defined as\n\\[\nP|_\\text{dBm} = 10 \\cdot \\log_{10} \\left( \\frac{P|_\\text{W}}{1\\,\\text{mW}} \\right)\n\\tag{2}\\]\n\n\n\n\n\n\nNote 2: Wireless Transmission\n\n\n\nWe use the following parameters:\n\nTransmit power \\(P_\\mathrm{T} = 1\\) W\nFrequency \\(f = 2.4\\) GHz\nCommunication distance \\(d = 10\\) km\nUsing \\(\\lambda/2\\) dipoles on both ends\n\nUsing Equation 1 we calculate\n\\[\nP_\\mathrm{R} = P_\\mathrm{T} \\cdot \\frac{0.13 \\lambda^2 \\cdot 0.13 \\lambda^2}{d^2 \\lambda^2} = P_\\mathrm{T} \\cdot 0.13^2 \\left( \\frac{\\lambda}{d} \\right)^2 =  2.64\\,\\text{pW} = -85.8\\,\\text{dBm}\n\\]\nWith the transmit power of 1 W = 30 dBm we have an attenuation of 116 dB! This is a very large number!\n\n\nAs dire as the situation of Note 2 already looks, this is not even all factors considered:\n\nThe given attenuation is for line-of-sight paths; often, the attenuation is significantly higher than this due to blockage by buildings, mountains, rain, or foliage.\nIn lack of a direct line-of-sight path, the EM wave is redirected by reflections, causing additional attenuation, and the potential destructive interference by multi-path reception.\n\nThe consequences of this are (among others):\n\nThe transmitter needs to generate enough transmit power to overcome the transmission loss; this has to be done often with high efficiency, as the transmit device is battery operated or limited by cooling.\nThe receiver has to be able to process weak signals, i.e., the noise level of the signal processing has to be very low.\nOften, the receive signal is very weak, while there are strong signals at other frequencies (i.e., other wireless transmitters are located close to the receiver). This means the receiver has to be able to process a weak signal while simultaneously tolerate large interfering signals (called blockers).\nSince the frequency spectrum is shared among many users and wireless applications, the transmit information has to be packed efficiently into a small bandwidth.\nVery often, wireless devices are battery-operated. This means transmit and receive functions have to be implemented using minimum power consumption.\n\nAs stated in the beginning, designing wireless systems is hard."
  },
  {
    "objectID": "rfic.html#sec-linearity",
    "href": "rfic.html#sec-linearity",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.1 Linearity",
    "text": "2.1 Linearity\nAs we have already seen in Section 1.1 the transmitter has to process large signals without distorting them, while the receiver has to process small signals in the presence of large signals. Both situations mean we need metrics and models to quantify and discuss linearity properties.\nWe are going to use a very simple, time-invariant model to study linearity, based on a Taylor polynomial.\n\n\n\n\n\n\nImportantLinearity and Time Invariance in RF Systems\n\n\n\nWe use time invariance to simplify the mathematics. In practice, many circuits and systems will show time variant behavior which leads to quite a few very interesting and important phenomena!\n\n\nWe model a nonlinear circuit block with the following Taylor polynomial:\n\\[\ny(t) = \\alpha_0 + \\alpha_1 x(t) + \\alpha_2 x(t)^2 + \\alpha_3 x(t)^3 + \\ldots\n\\tag{3}\\]\nUsually, the blocks under study will have higher order nonlinear terms but we often stop at 3rd order to keep things simple. For practical work, higher order terms should be included if necessary.\nWhich \\(x(t)\\) should we use to study wireless systems? Often, the bandwidth \\(f_\\mathrm{BW}\\) of a transmit signal is much smaller than the center frequency \\(f_0\\), i.e., \\(f_\\mathrm{BW} \\ll f_0\\). In this case using a sinusoidal signal as a mode is both simple to handle and approximately correct.\n\n2.1.1 Single-Tone Linearity\nWe thus set (with \\(A\\) being the amplitude of the input signal and \\(\\omega = 2 \\pi f\\) the angular frequency)\n\\[\nx(t) = A \\cos(\\omega t)\n\\]\nand insert it into Equation 3. After some simple trigonometric manipulations we are at\n\\[\n\\begin{split}\ny(t) &=\n\\underbrace{ \\frac{1}{2} \\alpha_2 A^2 }_\\text{dc component}\n+\n\\underbrace{ \\left(\\alpha_1 A + \\frac{3}{4} \\alpha_3 A^3 \\right) \\cos(\\omega t) }_\\text{fundamental} \\\\\n&+\n\\underbrace{ \\frac{1}{2} \\alpha_2 A^2 \\cos(2 \\omega t) }_\\text{2nd harmonic}\n+\n\\underbrace{ \\frac{1}{4} \\alpha_3 A^3 \\cos(3 \\omega t) }_\\text{3rd harmonic}\n\\end{split}\n\\tag{4}\\]\nLooking at Equation 4 we can make a few interesting observations:\n\nEven-order nonlinearity (\\(\\alpha_2\\)) creates low-frequency components; it effectively adds frequency components related to the envelope \\(A\\). If \\(A\\) is a constant then this results in a dc term; if \\(A(t)\\) is time variant it will created a squared version of it at low frequencies.\nThe \\(\\alpha_1\\) term is the gain of the circuit block.\nOdd-order nonlinearity (\\(\\alpha_3\\)) can impact the gain of the fundamental term passing through the block. Depending on the sign of \\(\\alpha_3\\) this can lead to gain contraction or expansion.\nEven- and odd-order nonlinearities creates additional frequency components, so-called harmonics of the fundamental frequency. These harmonics are often unwanted, as they are far outside the wanted transmission frequency range, and need to be minimized, by either\n\nuse a lowpass filter to filter these harmonics, or\nincrease the linearity, i.e., make the \\(\\alpha_2\\), \\(\\alpha_3\\), etc., small enough.\n\n\nThe created harmonics are illustrated in Figure 2. Note that measuring harmonics to quantify the nonlinearity metrics like \\(\\alpha_2\\) and \\(\\alpha_3\\) is often not very accurate, as these harmonics are often filtered in bandwidth-limited systems.\n\n\n\n\n\n\n\n\nFigure 2: Single-tone test showing created harmonics at 2ω and 3ω.\n\n\n\n\n\nHow can we quantify the nonlinearity with a one-tone test? We can sweep the input signal \\(x(t)\\) in amplitude, and observe the output \\(y(t)\\). If the observed gain drops by 1 dB from the small-signal value we note the input power, and call this point the 1dB compression point (\\(P_\\mathrm{1dB}\\)). We should always add whether this 1dB compression point is input- or output-referred to avoid ambiguity. The diagram in Figure 3 shows this test (\\(\\alpha_1 = 100\\), \\(\\alpha_3 = -0.2\\)).\n\n\n\n\n\n\n\n\nFigure 3: 1dB compression point test showing input vs output power relationship and the definition of P1dB.\n\n\n\n\n\n\n\n\n\n\n\nImportantCompressive vs. Expansive Behavior\n\n\n\nNote that for compressive behaviour, \\(\\alpha_3\\) and \\(\\alpha_1\\) have different signs, while for expansive behaviour, they have the same sign.\nAt some point, every circuit block will show compressive behavior, as the maximum signal amplitude will be limited by power supply voltages, device breakdown voltages, etc.\n\n\n\n\n2.1.2 Multi-Tone Linearity\nWe now elevate our investigations and apply two sinusoids with different frequencies and different amplitudes and see which signals we get at the output of the nonlinear block. The two-tone test and resulting third-order intermodulation products (IM3) are illustrated in Figure 4.\n\\[\nx(t) = A_1 \\cos(\\omega_1 t) + A_2 \\cos(\\omega_2 t)\n\\]\nWe apply the above stimulus to our nonlinear model described by Equation 3 and again, after some trigonometric manipulations, arrive at:\n\\[\ny(t) = y'(t) + y''(t) + y'''(t)\n\\tag{5}\\]\nAs many different frequency components are created by this simple two-tone test (and nonlinearity only up to 3rd order) we split the result into different equations and look at the result separately.\nFirst, we start with the fundamental tones:\n\\[\n\\begin{split}\n    y'(t) &= \\left( \\underbrace{\\alpha_1 A_1 + \\frac{3}{4} \\alpha_3 A_1^3}_\\text{compression/expansion} + \\underbrace{\\frac{3}{2} \\alpha_3 A_1 A_2^2}_\\text{cross-modulation/desens} \\right) \\cos(\\omega_1 t) \\\\\n    &+ \\left( \\underbrace{\\alpha_1 A_2 + \\frac{3}{4} \\alpha_3 A_2^3}_\\text{compression/expansion} + \\underbrace{\\frac{3}{2} \\alpha_3 A_2 A_1^2}_\\text{cross-modulation/desens} \\right) \\cos(\\omega_2 t)\n\\end{split}\n\\tag{6}\\]\nAs shown in Equation 6, interesting things happen:\n\nWe (again) have the gain compression/expansion effect as already discussed in Section 2.1.1.\nIn addition, we have cross-modulation, i.e., the envelope of one tone (e.g., \\(A_2(t)\\) of the tone at \\(\\omega_2\\)) impacts the envelope of the other tone at \\(\\omega_1\\). This can lead to unwanted signal distortation, even if there is a large frequency separation between \\(\\omega_1\\) and \\(\\omega_2\\)!\nFurther, since the sign of \\(\\alpha_3\\) is usually opposite to \\(\\alpha_1\\), this can also lead to desensitization (“desens”). If, for example, \\(A_2 \\gg A_1\\), then there would be no compression due to the tone \\(\\omega_1\\) itself, however, the large tone at \\(\\omega_2\\) will lead to gain compression of the tone at \\(\\omega_1\\); this effect is called desense.\n\nWe now look at the next class of generated tones:\n\\[\n\\begin{split}\n    y''(t) &= \\frac{1}{2} \\alpha_2 A_1^2 + \\frac{1}{2} \\alpha_2 A_2^2 \\\\\n    &+ \\alpha_2 A_1 A_2 \\cos[ (\\omega_1 - \\omega_2) t] \\\\\n    &+ \\alpha_2 A_1 A_2 \\cos[ (\\omega_1 + \\omega_2) t]\n\\end{split}\n\\tag{7}\\]\nAs we can see in Equation 7 new tones are created (besides the low frequency components we already know from the single-tone test) at the sum and difference of \\(\\omega_1\\) and \\(\\omega_2\\). These new frequency components are called “intermodulation products of second order” (IM2). These tones are created by the even-order nonlinearity (\\(\\alpha_2\\)). These IM2 products are far away from the wanted tones, so are often not very problematic in amplifiers (but there can be exceptions!). However, they can be very problematic in frequency conversion blocks like mixers. We will come back to this point when discussing zero-IF receivers.\nWe now investigate the next couple of tones:\n\\[\n\\begin{split}\n    y'''(t) &= \\frac{3}{4} \\alpha_3 A_1^2 A_2 \\cos[(2 \\omega_1 + \\omega_2) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1^2 A_2 \\cos[(2 \\omega_1 - \\omega_2) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1 A_2^2 \\cos[(2 \\omega_2 + \\omega_1) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1 A_2^2 \\cos[(2 \\omega_2 - \\omega_1) t]\n\\end{split}\n\\tag{8}\\]\nThe tones shown in Equation 8 are called “intermodulation products of third order” (IM3), and are caused by the odd nonlinearities (like \\(\\alpha_3\\)). While the IM3 tones located at \\(2 \\omega_1 + \\omega_2\\) and \\(\\omega_1 + 2 \\omega_2\\) are similar to the sum IM2 tone and far away from \\(\\omega_1\\) and \\(\\omega_2\\), the other two tones are concerning.\nExpressing \\(\\Delta \\omega = \\omega_2 - \\omega_1\\) (and assuming \\(\\omega_1 &lt; \\omega_2\\)), the building law of \\(2 \\omega_1 - \\omega_2 = \\omega_1 - \\Delta \\omega\\) and \\(2 \\omega_2 - \\omega_1 = \\omega_2 + \\Delta \\omega\\) results in new tones right besides \\(\\omega_1\\) and \\(\\omega_2\\), with a frequency separation only defined by \\(\\Delta \\omega\\). This situation is illustrated in Figure 4.\n\n\n\n\n\n\n\n\nFigure 4: Two-tone test showing fundamental frequencies ω₁, ω₂ and third-order intermodulation products (IM3) at 2ω₁-ω₂ and 2ω₂-ω₁.\n\n\n\n\n\nThis close localization of the IM3 tones can also be utilized to characterize nonlinear performance. Using gain compression or harmonic generation (H3) it can be very difficult to extract nonlinearity of third order (\\(\\alpha_3\\)). However, using a two-tone test, the IM3 tones can be readily measured, even if the measured signal path shows a bandpass characteristic! As RF systems frequently employ bandpass filters to suppress out-of-band signals, this is a very important property of the two-tone test.\nThe resulting test is called a two-tone test yielding the third-order intercept point (IP3). This test is widely used in RF design to characterize the linearity of amplifiers, mixers, and complete transceiver systems. The power relationship between fundamental tones and IM3 products as a function of input power is shown in Figure 5.\n\n\n\n\n\n\n\n\nFigure 5: Two-tone IM3 test showing fundamental and IM3 product power vs. input power, with IP3 intercept point definition. Equal input power per tone is assumed.\n\n\n\n\n\nNote that, as shown in Figure 5, the IM3 products rise with a slope of 3 dB/dB, i.e., if the input power is increased by 1 dB, the IM3 products increase by 3 dB. The fundamental tones rise with a slope of 1 dB/dB (as long as we are in the linear region). The IP3 point is defined as the intersection of the extrapolated linear lines of fundamental and IM3 products. As both lines have different slopes, this intersection point is usually far outside the actual operating range of the circuit block under test!\nWhen calculating the IIP3 (input-referred IP3) we can use the following formula, assuming equal input power per tone. It is important to always check the slope of the IM3 products to ensure that we are indeed in the third-order region! If the input power per tone is \\(P_\\mathrm{in}\\) (in dBm) and the input-referred power of one IM3 tone is \\(P_\\mathrm{IM3}\\) (in dBm), then the input-referred IP3 is given by\n\\[\n\\text{IIP3} = P_\\mathrm{in} + \\frac{P_\\mathrm{in} - P_\\mathrm{IM3}}{2}\n\\tag{9}\\]\nFurther, for midly nonlinear systems (i.e., \\(\\alpha_3\\) is dominating), the IIP3 can be approximated from the 1dB compression point as\n\\[\n\\text{IIP3}|_\\mathrm{dBm} \\approx P_\\mathrm{1dB}|_\\mathrm{dBm} + 9.6\\,\\text{dB}.\n\\tag{10}\\]\nIf we have two blocks which are cascaded, and we know the gain and IIP3 of both blocks, we can calculate the overall IIP3 of the cascade with the following approximation. An exact calculation is very involved, as the nonlinearities of the first block (and the resulting tones) will be processed by the second block, creating even more tones; this process escalates very quickly. However, for practical purposes, the following approximation is often sufficient:\n\\[\n\\frac{1}{\\text{IIP3}_\\text{total}} \\approx \\frac{1}{\\text{IIP3}_1} + \\frac{G_1}{\\text{IIP3}_2} + \\frac{G_1 G_2}{\\text{IIP3}_3}\n\\tag{11}\\]\nHere \\(G_1\\) is the linear gain of the first block, and \\(\\text{IIP3}_1\\), \\(\\text{IIP3}_2\\) are the input-referred IP3 of the first and second block, respectively. Note that all powers have to be in linear units (i.e., Watts) when using Equation 11. An even more simplified version of Equation 11 can be used with all quantities given in dBm and dB, respectively:\n\\[\n\\text{IIP3}_\\text{total} \\approx \\min \\{  \\text{IIP3}_1, \\text{IIP3}_2 - G_1, \\text{IIP3}_3 - G_1 - G_2 \\}\n\\tag{12}\\]\nA typical RF system cascade with multiple blocks and their individual IIP3 contributions is shown in Figure 6.\n\n\n\n\n\n\n\n\nFigure 6: Block cascade for IIP3 calculation showing multiple stages with gains and individual IIP3 values.\n\n\n\n\n\n\n\n\n\n\n\nNote 3: Simple IIP3 Cascade Calculation\n\n\n\nLet’s calculate the overall IIP3 of two cascaded blocks. The first block is a low-noise amplifier with an IIP3 of -10 dBm and a gain of 20 dB. The second block is a mixer that has a gain of 10 dB and an IIP3 of 5 dBm. What is the overall IIP3?\nUsing Equation 12 we can quickly estimate:\n\\[\n\\text{IIP3}_\\text{total} \\approx \\min \\{ -10\\,\\text{dBm}, 5\\,\\text{dBm} - 20\\,\\text{dB} = -15\\,\\text{dBm} \\} = -15\\,\\text{dBm}\n\\]\nWe see that the overall IIP3 is limited by the linearity of the second block, as the first block amplifies all signals (including blockers) by 20 dB before they reach the second block."
  },
  {
    "objectID": "rfic.html#sec-noise",
    "href": "rfic.html#sec-noise",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.2 Noise",
    "text": "2.2 Noise\nJust as nonlinearity is a limiting factor for large signals, noise is the limiting factor for small signals. Noise is present in all electronic circuits and systems, and it is impossible to avoid it. However, we can try to minimize its impact on the system performance.\nNoise is usually characterized by its power spectral density (PSD) in units of Watts per Hertz (W/Hz). For example, thermal noise at room temperature has a PSD of approximately \\(k T = 4 \\times 10^{-21}\\) W/Hz, or –174 dBm/Hz (with the Boltzmann constant \\(k = 1.38 \\times 10^{-23}\\,\\text{J/K}\\)). This means that if we have a bandwidth of 1 MHz, the total thermal noise power would be:\n\\[\nP_\\mathrm{thermal} = \\text{PSD} \\cdot B = -174\\,\\text{dBm/Hz} + 10 \\log_{10} \\left( \\frac{1\\,\\text{MHz}}{1\\,\\text{Hz}} \\right) = -114\\,\\text{dBm}\n\\]\nThe PSD of noise can be flat vs. frequency (which is called “white noise”), or can decrease with frequency (e.g., “flicker noise” or “1/f noise”). Further, noise can be generated by resistors (thermal noise), semiconductors (shot noise, generation-recombination noise), etc. A detailed discussion of noise sources can be found in (Gray et al. 2009) or (Razavi 2017).\n\n2.2.1 Types of Noise Generation\nResistors generate thermal noise, which is white noise with a PSD of \\(4 k T R\\) (in V\\(^2\\)/Hz) when looking at the voltage across the resistor, or \\(4 k T / R\\) (in A\\(^2\\)/Hz) when looking at the current through the resistor. This noise is generated by the random thermal motion of charge carriers in the resistor.\n\n\n\n\n\n\nImportantThermal Noise\n\n\n\nNote that the simple approximation given above is only valid for reasonably high frequencies and typical temperatures, and is known as the Rayleigh-Jeans approximation of Planck’s blackbody radiation accounting for quantum effects and is given by (Pozar 2011)\n\\[\n\\text{PSD} = \\frac{h f}{e^{{h f}/{k T}} - 1}\n\\]\nwhere \\(h\\) is the Planck constant (\\(h = 6.626 \\times 10^{-34}\\) Js) and \\(f\\) is the frequency. The Rayleigh-Jeans approximation is valid for \\(f \\ll k T / h\\), which is approximately 6 THz at room temperature (290 K).\n\n\nMOSFETs generate several types of noise, the most important ones being the thermal noise of the channel and flicker noise.\nThe thermal noise of the channel can be modeled as a current noise source between drain and source with a PSD of \\(4 k T \\gamma g_{d0}\\) (in A\\(^2\\)/Hz), where \\(\\gamma\\) is a process-dependent parameter (usually between 2/3 and 2). The parameter \\(g_{d0}\\) is the small-signal output conductance of the MOSFET in triode, i.e., \\(g_{d0} = g_\\mathrm{ds}\\), or equal to \\(g_{d0} = g_\\mathrm{m}\\) when in saturation.\nIn saturation, it is often useful to express the thermal noise as a voltage noise source at the gate with a PSD of \\(4 k T \\gamma / g_\\mathrm{m}\\) (in V\\(^2\\)/Hz). We can see that we can lower this noise of the MOSFET by increasing the transconductance \\(g_\\mathrm{m}\\), which can be achieved by increasing the bias current.\nIn addition, at high frequencies, the MOSFET also has induced gate-current noise, which is correlated with the channel thermal noise. A detailed discussion of this noise source can be found in (Razavi 2017).\nFlicker noise is usually modeled as a voltage noise source at the gate with a PSD of \\(K_f / (C'_\\mathrm{ox}W L f)\\) (in V\\(^2\\)/Hz), where \\(K_f\\) is a process-dependent parameter, \\(C'_\\mathrm{ox}\\) is the oxide capacitance per unit area, \\(L\\) and \\(W\\) are the length and width of the MOSFET, and \\(f\\) is the frequency. Note that we can lower the flicker noise by increasing the area of the MOSFET (\\(W L\\)), however, this increases the parasitic capacitances associated with the MOSFET, and this often prohibitive for RF operation!\nIn bipolar junction transistors (BJTs), the most important noise source is the shot noise due to the diffusion current in the base-emitter junction. Its PSD can be modeled as a current noise source between collector and emitter with a PSD of \\(2 q I_\\mathrm{C}\\) (in A\\(^2\\)/Hz), where \\(q\\) is the elementary charge (\\(q = 1.6 \\times 10^{-19}\\) C) and \\(I_\\mathrm{C}\\) is the dc collector current.\n\n\n\n\n\n\nImportantEquivalance of Shot and Thermal Noise\n\n\n\nNote that it has been shown in (Sarpeshkar, Delbruck, and Mead 1993) that thermal noise and shot noise are actually equivalent, as both are generated by the random, thermally agitated motion of charge carriers!\n\n\nIdeal capacitors and inductors do not generate noise, however, real capacitors and inductors have parasitic resistances which generate thermal noise.\nIn RF systems additional noise sources can be present. One noteworthy example is the cosmic microwave background radiation, which can be modeled as a noise temperature of approximately 3 K. While this is negligible compared to thermal noise at room temperature (approximately 290 K), it can be significant in very low-noise systems, such as radio telescopes pointing to the sky. An other important noise source in RF systems is the atmospheric noise, which is generated by natural phenomena like lightning or in the ionosphere.\n\n\n2.2.2 Noise in Impedance-Matched Systems\nWe now want to calculate the maximum noise power that can be extracted from a noisy source. We assume the following situation as shown in Figure 7. Note that the voltage source \\(\\overline{V_\\mathrm{n,s}^2}\\) models the thermal noise of the source resistor \\(R_\\mathrm{s}\\) resulting in a Thevenin equivalent circuit.\n\n\n\n\n\n\n\n\nFigure 7: A noise-matched system with source and load impedances.\n\n\n\n\n\nWe know that the noise of the source resistor is given by \\(\\overline{V_\\mathrm{n,s}^2} = 4 k T R_\\mathrm{s}\\). We assume the load resistor \\(R_\\mathrm{load}\\) as noiseless and matched to the source resistor, i.e., \\(R_\\mathrm{load} = R_\\mathrm{s}\\) for maximum power transfer. The noise power spectral density delivered to the load resistor is then given by\n\\[\nP_\\mathrm{n,load} = \\frac{\\overline{V_\\mathrm{n,load}^2}}{R_\\mathrm{load}} = \\frac{\\overline{V_\\mathrm{n,d}^2}}{4 R_\\mathrm{s}} = k T\n\\tag{13}\\]\nThe calculation of Equation 13 confirms the initial statement that the maximum noise power spectral density that can be extracted from a noisy source is \\(k T\\) (in W/Hz). This result is independent of the actual value of the source resistance \\(R_\\mathrm{s}\\).\nWe can further generalize the thermal noise of any impedance as\n\\[\n\\overline{V_\\mathrm{n}^2} = 4 k T \\Re \\{ Z \\}\n\\tag{14}\\]\nas for example in the complex impedance \\(Z_\\mathrm{ant}\\) of an antenna.\n\n\n2.2.3 Noise Figure\nIn RF systems, we often want to quantify the noise performance of a circuit block or a complete system. The most widely used metric is the noise factor (F), which is defined as the ratio of the signal-to-noise ratio (SNR) at the input to the SNR at the output of a circuit block or system. If we express the noise factor in dB, we call it the noise figure (NF) (Pozar 2011). The noise factor is given by\n\\[\nF = \\frac{\\text{SNR}_\\mathrm{in}}{\\text{SNR}_\\mathrm{out}} = \\frac{(P_\\mathrm{s}/P_\\mathrm{n})_\\mathrm{in}}{(P_\\mathrm{s}/P_\\mathrm{n})_\\mathrm{out}}\n\\tag{15}\\]\nwhere \\(P_\\mathrm{s}\\) is the signal power and \\(P_\\mathrm{n}\\) is the noise power. The noise factor is always larger than or equal to 1 (or 0 dB), as no circuit can improve the SNR!\n\n\n\n\n\n\nImportantSNR Improvement\n\n\n\nNote that the SNR can be improved by filtering, as filtering reduces the noise power. If the noise bandwidth is larger than the signal bandwidth, then the SNR can be improved without affecting the signal. However, this is not considered in the noise factor, as the noise factor assumes that both signal and noise pass through the same bandwidth.\n\n\nLet us look at a simple model of a noise circuit block as shown in Figure 8. The input signal \\(S_\\mathrm{in}\\) is accompanied by noise \\(N_\\mathrm{in}\\). By definition it is assumed that the input noise power results from a matched resistor at \\(T_0 = 290\\,\\text{K}\\), so that \\(N_\\mathrm{in} = k T_0\\). The circuit block has a power gain \\(G\\) and adds its own noise \\(N_\\mathrm{dut}\\) to the output signal. For simplicity, we assume that the input and output of the circuit block are impedance matched to avoid reflections.\n\n\n\n\n\n\n\n\nFigure 8: A noise-matched system with source and load impedances and a noisy circuit block.\n\n\n\n\n\nThe output signal and noise powers are then given by\n\\[\nS_\\mathrm{out} = G S_\\mathrm{in}\n\\]\n\\[\nN_\\mathrm{out} = G N_\\mathrm{in} + N_\\mathrm{dut}\n\\] The resulting noise factor can then be calculated as\n\\[\nF = \\frac{{S_\\mathrm{in}}/{N_\\mathrm{in}}}{{S_\\mathrm{out}}/{N_\\mathrm{out}}} = \\frac{1}{G} \\frac{G N_\\mathrm{in} + N_\\mathrm{dut}}{N_\\mathrm{in}} = 1 + \\frac{N_\\mathrm{dut}}{G N_\\mathrm{in}},\n\\]\nin other words, the noise factor is 1 plus the ratio of the noise added by the device under test (DUT) to the amplified input noise.\nNote that a noiseless block (\\(N_\\mathrm{dut} = 0\\)) has a noise factor of \\(F=1\\). A passive block with loss factor \\(L\\) (and impedance matched at input and output) has a noise factor of \\(F=L\\) (in linear units), as it attenuates the signal and \\(N_\\mathrm{out} = N_\\mathrm{in} = k T\\) if everything is in thermal equilibrium.\n\n\n\n\n\n\n\n\nFigure 9: Block cascade for noise factor calculation showing multiple stages with gains and individual noise factors.\n\n\n\n\n\nIf we have a cascade of multiple blocks, as shown in Figure 9, we can calculate the overall noise factor with the Friis formula (Pozar 2011)\n\\[\nF_\\mathrm{total} = 1 + (F_1 - 1) + \\frac{F_2 - 1}{G_1} + \\frac{F_3 - 1}{G_1 G_2}\n\\tag{16}\\]\nwhere \\(F_i\\) and \\(G_i\\) are the noise factor and power gain of the \\(i\\)-th block, respectively. Note that all gains have to be in linear units (not dB) when using Equation 16. We can interpret Equation 16 as follows:\n\nThe overall noise factor \\(F_\\mathrm{total}\\) is always larger than or equal to the noise factor of the first block (\\(F_1\\)).\nThe noise factor of the first block is the most important one, as the noise factors of the following blocks are reduced by the gain of all preceding blocks. This is especially important in RF receivers, where the first block is usually a low-noise amplifier (LNA) with a very low noise figure (e.g., 1 dB or less) and a high gain (e.g., 10 dB or more). This ensures that the noise of the following blocks is negligible.\nThe noise factor of the last block is reduced by the gain of all preceding blocks, so it is usually not very important.\n\nHere we also see a trade-off between noise and linearity, as shown by Equation 11 and Equation 16. For low noise, we should try to maximize \\(G_1\\), however, this will affect linearity (IIP3) in a negative way. As in many other situation in RF design, we have to find a good compromise between conflicting requirements.\n\n\n2.2.4 Sensitivity\nIn RF receivers, we often want to know the minimum input signal power that can be detected with a certain SNR. This minimum input signal power is called the sensitivity of the receiver. The sensitivity can be calculated as\n\\[\nP_\\mathrm{in, min} = P_\\mathrm{n} \\cdot \\text{SNR}_\\mathrm{min} \\cdot F\n\\tag{17}\\]\nwhere \\(P_\\mathrm{n}\\) is the noise power at the input, \\(\\text{SNR}_\\mathrm{min}\\) is the minimum detectable SNR, and \\(F\\) is the noise factor of the receiver. The input noise power can be calculated as\n\\[\nP_\\mathrm{n} = k T B\n\\]\nwhere \\(k\\) is the Boltzmann constant, \\(T\\) is the temperature in Kelvin, and \\(B\\) is the bandwidth of the receiver. Expressing Equation 17 in dBm we get the following formula:\n\\[\nP_\\mathrm{in, min}|_\\mathrm{dBm} = -174\\,\\text{dBm/Hz} + \\text{NF} + 10 \\log_{10}(B/\\text{Hz}) + \\text{SNR}_\\mathrm{min}|_\\mathrm{dB}\n\\tag{18}\\]\nwhere -174 dBm/Hz is the thermal noise PSD at room temperature (290 K). We can see that the sensitivity improves with lower noise figure, smaller bandwidth, and lower minimum detectable SNR.\n\n\n\n\n\n\nNote 4: Sensitivity Calculation for WiFi\n\n\n\nLet’s calculate the sensitivity of a WiFi receiver operating at 5 GHz with a bandwidth of \\(B = 80\\,\\text{MHz}\\), a noise figure of \\(NF = 7\\,\\text{dB}\\), and a minimum detectable SNR of 25 dB. This high SNR means that a high-order modulation scheme (like 64-QAM) is used for high data rates.\nUsing Equation 18 we get: \\[\nP_\\mathrm{in, min} = -174\\,\\text{dBm/Hz} + 7\\,\\text{dB} + 10 \\log_{10} (80 \\times 10^6) + 25\\,\\text{dB} \\approx -63\\,\\text{dBm}\n\\]\nThis means that the minimum input signal power that can be detected by the WiFi receiver is approximately -63 dBm."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "",
    "text": "Radio-Frequency Integrated Circuits\n\n\n\nQuarto Publish\n\n\n(c) 2025 Harald Pretl and co-authors, Department for Integrated Circuits (ICD), Johannes Kepler University, Linz (JKU)\nThis is the material for a graduate-level radio-frequency integrated circuit course, held at JKU under course number 336.023 (“VO Integrierte Hochfrequenz-Schaltungstechnik”). Follow this link to access the material.\nAll course material is made publicly available and shared under the Apache-2.0 license.\nWe happily accept pull requests to fix typos or add content! If you want to discuss something that is not clear, please open an issue!"
  }
]