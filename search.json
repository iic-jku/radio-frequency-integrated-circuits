[
  {
    "objectID": "rfic.html#sec-intro-wireless",
    "href": "rfic.html#sec-intro-wireless",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "1.1 Wireless Transmission",
    "text": "1.1 Wireless Transmission\nIn wireless transmission, we usually want to transmit data via a transmitter (TX) and a connected antenna to a receiver (RX) using an electromagnetic (EM) wave. This arrangement is shown in Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: The block diagram of a simple wireless system.\n\n\n\n\n\nUnfortunately, wireless transmission is hard. The wireless channel, i.e., the usage of electromagnetic waves to transmit information from a transmitter to a receiver, while tremendously useful, unfortunately has quite a few undesired features:\n\nThe wireless channel is shared between all users.\nAs a consequence, the available bandwidth is shared; this means that bandwidth is a scarce resource.\nThe wireless channel has significant losses.\nThe channel is time variant, as usually the transmitter and/or the receiver move, and/or the environment changes.\n\nIn order to estimate the power \\(P_\\mathrm{R}\\) of the wireless transmission at the receiver we can use Friis’ transmission formula (Pozar 2011):\n\\[\nP_\\mathrm{R} = \\frac{P_\\mathrm{T}}{4 \\pi d^2} \\cdot A_\\mathrm{R} = P_\\mathrm{T} \\cdot \\frac{A_\\mathrm{R} \\cdot A_\\mathrm{T}}{d^2 \\lambda^2}\n\\tag{1}\\]\nHere, \\(A_\\mathrm{R}\\) (and \\(A_\\mathrm{T}\\)) is the effective area of the receive/transmit antenna, while \\(d\\) is the distance (line of sight) between the two antennas. The effective area of an antenna depends on the type and construction, but generally we can say that\n\\[\nA \\propto \\lambda^2\n\\]\nFor an isotropic antenna (a theoretical construct where the radiation is equal in all directions) \\(A = \\lambda^2 / (4 \\pi)\\), while for a \\(\\lambda/2\\)-dipole \\(A = 0.13 \\lambda^2\\). Of course, the speed of light \\(c\\) relates frequency \\(f\\) and wavelength \\(\\lambda\\) of an electromagnetic wave by\n\\[\nc = \\lambda f.\n\\]\nGenerally speaking, the size of an electromagnetic antenna is proportional to the wavelength of the EM wave used for transmission. For many devices, we seek antennas on the order of a few centimeters, and this is why frequencies in the hundreds of MHz to GHz are so popular. Table 1 lists a few typical applications and their frequency and wavelength.\n\n\n\nTable 1: Typical RF applications with their operating frequencies and corresponding wavelengths\n\n\n\n\n\nApplication\nFrequency\nWavelength\n\n\n\n\nFM Radio\n88–108 MHz\n2.8-3.4 m\n\n\nWiFi (lowband)\n2.4 GHz\n12.5 cm\n\n\nWiFi (highband)\n5 GHz\n6 cm\n\n\nBluetooth\n2.4 GHz\n12.5 cm\n\n\nCellular\n0.6–5 GHz\n6-50 cm\n\n\nGNSS\n1.575 GHz\n19 cm\n\n\n\n\n\n\nAs you can see in Table 1 many of these antennas would not fit into the used device form factors, i.e., often we have to use electrically small antennas.\n\n\n\n\n\n\nNote 1: Wavelength Calculation\n\n\n\nLet’s calculate the wavelength for a Bluetooth signal at 2.4 GHz. Given:\n\nFrequency \\(f = 2.4\\) GHz \\(= 2.4 \\times 10^9\\) Hz\n\nSpeed of light \\(c = 3 \\times 10^8\\) m/s\n\nUsing the relationship \\(c = \\lambda f\\), we can solve for wavelength:\n\\[\\lambda = \\frac{c}{f} = \\frac{3 \\times 10^8 \\text{ m/s}}{2.4 \\times 10^9 \\text{ Hz}} = 0.125 \\text{ m} = 12.5 \\text{ cm}\\]\nThis means that a quarter-wavelength monopole antenna for 2.4 GHz Bluetooth would be approximately 3.1 cm long, which easily fits into most mobile devices.\n\n\nIn order to get a feeling for the attenuation experienced in wireless communication, we now calculate the following exemplary transmission. We will use the unit of dBm which is often used in RF design and is defined as\n\\[\nP|_\\text{dBm} = 10 \\cdot \\log_{10} \\left( \\frac{P|_\\text{W}}{1\\,\\text{mW}} \\right)\n\\tag{2}\\]\n\n\n\n\n\n\nNote 2: Wireless Transmission\n\n\n\nWe use the following parameters:\n\nTransmit power \\(P_\\mathrm{T} = 1\\) W\nFrequency \\(f = 2.4\\) GHz\nCommunication distance \\(d = 10\\) km\nUsing \\(\\lambda/2\\) dipoles on both ends\n\nUsing Equation 1 we calculate\n\\[\nP_\\mathrm{R} = P_\\mathrm{T} \\cdot \\frac{0.13 \\lambda^2 \\cdot 0.13 \\lambda^2}{d^2 \\lambda^2} = P_\\mathrm{T} \\cdot 0.13^2 \\left( \\frac{\\lambda}{d} \\right)^2 =  2.64\\,\\text{pW} = -85.8\\,\\text{dBm}\n\\]\nWith the transmit power of 1 W = 30 dBm we have an attenuation of 116 dB! This is a very large number!\n\n\nThe loss we calculated in Note 2 is called the free-space path loss (FSPL). It is the minimum loss we can expect in a wireless communication system. In reality, the situation is often even worse. The free-space path loss \\(\\text{FSPL}\\) (in dB) can be calculated as\n\\[\n\\text{FSPL} = 20 \\cdot \\log_{10}(d / \\text{m}) + 20 \\cdot \\log_{10}(f / \\text{Hz}) + 20 \\cdot \\log_{10} \\left( \\frac{4\\pi}{c} \\text{m/s} \\right).\n\\tag{3}\\]\nEquation 3 can be readily derived from Equation 1 and Equation 2 assuming isotropic antennas at transmitter and receiver. Using Equation 3 we can easily calculate the FSPL for different distances and frequencies. The results are shown in Figure 2. It should be noted that the FSPL increases by 20 dB per decade of distance and 20 dB per decade of frequency, making higher frequencies and longer distances very challenging.\n\n\n\n\n\n\n\n\nFigure 2: Free space path loss vs. distance for different frequencies (1 GHz, 10 GHz, and 100 GHz).\n\n\n\n\n\nAs dire as the situation of Figure 2 already looks, this is not even all factors considered:\n\nThe given attenuation is for line-of-sight paths; often, the attenuation is significantly higher than this due to blockage by buildings, mountains, rain, or foliage.\nIn the absence of a direct line-of-sight path, the EM wave is redirected by reflections, causing additional attenuation, and potential destructive interference by multi-path reception.\n\nThe consequences of this are (among others):\n\nThe transmitter needs to generate enough transmit power to overcome the transmission loss; this has to be done often with high efficiency, as the transmit device is battery operated or limited by cooling.\nThe receiver has to be able to process weak signals, i.e., the noise level of the signal processing has to be very low.\nOften, the receive signal is very weak, while there are strong signals at other frequencies (i.e., other wireless transmitters are located close to the receiver). This means the receiver has to be able to process a weak signal while simultaneously tolerating large interfering signals (called blockers).\nSince the frequency spectrum is shared among many users and wireless applications, the transmit information has to be packed efficiently into a small bandwidth.\nVery often, wireless devices are battery-operated. This means transmit and receive functions have to be implemented using minimum power consumption.\n\nAs stated in the beginning, designing wireless systems is hard."
  },
  {
    "objectID": "rfic.html#sec-intro-standards",
    "href": "rfic.html#sec-intro-standards",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "1.2 Wireless Standards",
    "text": "1.2 Wireless Standards\nIn order to allow communication between different devices, different operators, and different manufacturers, wireless communication is standardized. There are many different standards, each with its own characteristics. Wireless standards define every aspect of wireless communication, and can be documents with hundreds or thousands of pages. Here, we mainly focus on the radio-frequency and analog aspects of wireless standards. Summarized in Table 2 are a few popular wireless standards with their main characteristics.\n\n\n\nTable 2: Comparison of wireless communication standards\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStandard\nGSM (2G)\nWCDMA (3G)\nLTE (4G)5G NR\nWiFi\nBluetooth\nGNSS\n\n\n\n\nFrequency range (MHz)\n850, 900, 1800, 1900\n850, 900, 1700, 1900, 2100\nMultiple bands 450…7100 (FR1), 24000…48000 (FR2)\n2400, 5000, 6000\n2400\n1500, 1200\n\n\nModulation\nGMSK, 8PSK (EDGE)\nQPSK (DL), BPSK (UL), 16QAM (HSPA), 64QAM (HSPA)\nQPSK, 16QAM, 64QAM (DL+UL) 256QAM (DL+UL)\nBPSK, QPSK, 16QAM, 64QAM, 256QAM, 1024QAM, 4096QAM\nGFSK (m=0.28…0.35), \\(\\pi\\)/4-DQPSK, 8DPSK\nBPSK, QPSK\n\n\nTransmission/ multiple access\nTDMA, FDMA\nDS-CDMA\nOFDMA (DL+UL), SC-FDMA/DFT-s-OFDM (UL)\nOFDM, CSMA/CA\nFHSS\nCDMA\n\n\nDuplex\nFDD\nFDD\nFDD, TDD\nTDD\nTDD\nn/a\n\n\nChannel bandwidth\n200 kHz\n5 MHz\n1.4, 3, 5, 10, 15, 20, …, 100 MHz (FR1), 400 MHz (FR2)\n10, 20, 40, 80, 160, 320 MHz\n1 MHz\n16…24 MHz\n\n\nSymbol rate\n270.833 ksym/s\n3.84 Msym/s\n15/30/60 ksym/s\n312.5 ksym/s\n1 Msym/s\n50 sym/s\n\n\nPulse shaping\nGaussian (BT=0.3)\nRoot Raised Cosine (\\(\\alpha\\)=0.22)\nRectangular\nRectangular\nGaussian (BT=0.5)\nRectangular\n\n\nTransmit power\n1…2 W\n250 mW\n200 mW (FDD), 400 mW (TDD)\n100 mW\n1…100 mW\nn/a\n\n\nPAR (UL)\n0 dB (GMSK), 3 dB (8PSK)\n3…8 dB\n6…8 dB\nUp to 12 dB\n0 dB (GFSK), 3 dB (8DPSK)\nn/a\n\n\nMIMO\nno\nNot realized (DL 2x2)\nDL 4x4 (up to 8x8)\n2x2 (up to 8x8)\nno\nno\n\n\nChannel bond\nno\nUp to 4x5 MHz\nUp to 7x20/4x100 MHz\nUp to 80+80+80+80 MHz\nno\nno\n\n\n\n\n\n\nDuring this course, we will learn what these terms mean and how they impact the design of RF integrated circuits.\nAs you can see in Table 2, since LTE (4G) and 5G NR, many additional bands have been defined in the sub-6 GHz range (FR1) and also in the mm-wave range (FR2, 24.25 to 52.6 GHz). This means that modern wireless devices have to support many different frequency bands, which makes the design of RF frontends even more challenging. A good overview of the different frequency bands is given here for LTE and 5G NR.\nRFIC design is a multidisciplinary field, requiring knowledge from various engineering domains, as shown in Figure 3. This makes RFIC design challenging, but also very interesting!\n\n\n\n\n\n\n\n\nFigure 3: RF design as a multidisciplinary field requiring knowledge from various engineering domains (adapted from (Razavi 2011)).\n\n\n\n\n\nFurther, RFIC design requires careful consideration of many different aspects, as shown in Figure 4. Many parameters are often tightly coupled, requiring careful trade-offs during the design process.\n\n\n\n\n\n\n\n\nFigure 4: RFIC require careful design considerations and trade-offs (adapted from (Razavi 2011))."
  },
  {
    "objectID": "rfic.html#sec-channel-capacity",
    "href": "rfic.html#sec-channel-capacity",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.1 Channel Capacity",
    "text": "2.1 Channel Capacity\nIn Section 1 we have already discussed the fact that we need to pack information into a minimum bandwidth, as the available spectrum is limited. To appreciate the limits of information transfer, we need to understand how much information can be transmitted over a given bandwidth. This limit is given by the Shannon-Hartley theorem, which gives the maximum data rate \\(C\\) (in bit/s) that can be transmitted over a communication channel with bandwidth \\(B\\) (in Hz) and signal-to-noise ratio \\(\\text{SNR}\\) (with linear units):\n\\[\nC = B \\cdot \\log_2(1 + \\text{SNR})\n\\tag{4}\\]\nThis formula gives us a theoretical upper limit on the data rate that can be achieved with a given bandwidth and SNR under optimal conditions. It is important to note that this limit is only achievable with ideal coding and modulation schemes, which are not practical in real-world systems. However, it provides a useful benchmark for evaluating the performance of communication systems.\n\n\n\n\n\n\nNote 3: Channel Capacity Example\n\n\n\nLet us calculate the channel capacity for a system with a bandwidth of 2 MHz and an SNR of 7 dB (the BW and minimum SNR of Bluetooth LE for 1 Mbps). First, we need to convert the SNR from dB to linear units:\n\\[\n\\text{SNR} = 10^{{7}/{10}} \\approx 5\n\\]\nNow we can use Equation 4 to calculate the channel capacity:\n\\[\nC = B \\cdot \\log_2(1 + \\text{SNR}) = 2\\,\\text{MHz} \\cdot \\log_2(1 + 5) = 2\\,\\text{MHz} \\cdot 2.585 \\approx 5.2\\,\\text{Mbps}\n\\]\nThis sounds reasonable, as the user data rate for Bluetooth LE is 1 Mbps for the given SNR, which allows for quite some overhead for coding and protocols."
  },
  {
    "objectID": "rfic.html#sec-linearity",
    "href": "rfic.html#sec-linearity",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.2 Linearity",
    "text": "2.2 Linearity\nAs we have already seen in Section 1.1 the transmitter has to process large signals without distorting them, while the receiver has to process small signals in the presence of large signals. Both situations mean we need metrics and models to quantify and discuss linearity properties.\nWe are going to use a very simple, time-invariant model to study linearity, based on a Taylor polynomial.\n\n\n\n\n\n\nImportantLinearity and Time Invariance in RF Systems\n\n\n\nWe use time invariance to simplify the mathematics. In practice, many circuits and systems will show time variant behavior which leads to quite a few very interesting and important phenomena! A time-invariant nonlinear system is also called a “memoryless” system, as the output at time \\(t\\) only depends on the input at time \\(t\\).\nIn contrast, a system with memory (i.e., time-variant) will have an output at time \\(t\\) which depends on the input at time \\(t\\) and also on past inputs (e.g., at times \\(t - \\Delta T\\), \\(t - 2 \\Delta T\\), etc.). Examples of systems with memory are filters, which have a frequency-dependent response, or power amplifiers with thermal memory effects.\n\n\nWe model a nonlinear circuit block with the following Taylor polynomial:\n\\[\ny(t) = \\alpha_0 + \\alpha_1 x(t) + \\alpha_2 x(t)^2 + \\alpha_3 x(t)^3 + \\ldots\n\\tag{5}\\]\nUsually, the blocks under study will have higher order nonlinear terms but we often stop at 3rd order to keep things simple. For practical work, higher order terms should be included if necessary.\nWhich \\(x(t)\\) should we use to study wireless systems? Often, the bandwidth \\(f_\\mathrm{BW}\\) of a transmit signal is much smaller than the center frequency \\(f_0\\), i.e., \\(f_\\mathrm{BW} \\ll f_0\\). In this case using a sinusoidal signal as a model is both simple to handle and approximately correct.\n\n2.2.1 Single-Tone Linearity\nWe thus set (with \\(A\\) being the amplitude of the input signal and \\(\\omega = 2 \\pi f\\) the angular frequency)\n\\[\nx(t) = A \\cos(\\omega t)\n\\]\nand insert it into Equation 5. After some simple trigonometric manipulations we are at\n\\[\n\\begin{split}\ny(t) &=\n\\underbrace{ \\frac{1}{2} \\alpha_2 A^2 }_\\text{dc component}\n+\n\\underbrace{ \\left(\\alpha_1 A + \\frac{3}{4} \\alpha_3 A^3 \\right) \\cos(\\omega t) }_\\text{fundamental} \\\\\n&+\n\\underbrace{ \\frac{1}{2} \\alpha_2 A^2 \\cos(2 \\omega t) }_\\text{2nd harmonic}\n+\n\\underbrace{ \\frac{1}{4} \\alpha_3 A^3 \\cos(3 \\omega t) }_\\text{3rd harmonic}\n\\end{split}\n\\tag{6}\\]\nLooking at Equation 6 we can make a few interesting observations:\n\nEven-order nonlinearity (\\(\\alpha_2\\)) creates low-frequency components; it effectively adds frequency components related to the envelope \\(A\\). If \\(A\\) is a constant then this results in a dc term; if \\(A(t)\\) is time variant it will create a squared version of it at low frequencies.\nThe \\(\\alpha_1\\) term is the gain of the circuit block.\nOdd-order nonlinearity (\\(\\alpha_3\\)) can impact the gain of the fundamental term passing through the block. Depending on the sign of \\(\\alpha_3\\) this can lead to gain contraction or expansion.\nEven- and odd-order nonlinearities create additional frequency components, so-called harmonics of the fundamental frequency. These harmonics are often unwanted, as they are far outside the wanted transmission frequency range, and need to be minimized, by either\n\nuse a lowpass filter to filter these harmonics, or\nincrease the linearity, i.e., make the \\(\\alpha_2\\), \\(\\alpha_3\\), etc., small enough.\n\n\nThe created harmonics are illustrated in Figure 5. Note that measuring harmonics to quantify the nonlinearity metrics like \\(\\alpha_2\\) and \\(\\alpha_3\\) is often not very accurate, as these harmonics are often filtered in bandwidth-limited systems.\n\n\n\n\n\n\n\n\nFigure 5: Single-tone test showing created harmonics at 2ω and 3ω.\n\n\n\n\n\nHow can we quantify the nonlinearity with a one-tone test? We can sweep the input signal \\(x(t)\\) in amplitude, and observe the output \\(y(t)\\). If the observed gain drops by 1 dB from the small-signal value we note the input power, and call this point the 1dB compression point (\\(P_\\mathrm{1dB}\\)). We should always add whether this 1dB compression point is input- or output-referred to avoid ambiguity. The diagram in Figure 6 shows this test (\\(\\alpha_1 = 100\\), \\(\\alpha_3 = -0.2\\)).\n\n\n\n\n\n\n\n\nFigure 6: 1dB compression point test showing input vs output power relationship and the definition of P1dB.\n\n\n\n\n\n\n\n\n\n\n\nImportantCompressive vs. Expansive Behavior\n\n\n\nNote that for compressive behaviour, \\(\\alpha_3\\) and \\(\\alpha_1\\) have different signs, while for expansive behaviour, they have the same sign.\nAt some point, every circuit block will show compressive behavior, as the maximum signal amplitude will be limited by power supply voltages, device breakdown voltages, etc.\n\n\n\n\n2.2.2 Multi-Tone Linearity\nWe now elevate our investigations and apply two sinusoids with different frequencies and different amplitudes and see which signals we get at the output of the nonlinear block. The two-tone test and resulting third-order intermodulation products (IM3) are illustrated in Figure 7.\n\\[\nx(t) = A_1 \\cos(\\omega_1 t) + A_2 \\cos(\\omega_2 t)\n\\]\nWe apply the above stimulus to our nonlinear model described by Equation 5 and again, after some trigonometric manipulations, arrive at:\n\\[\ny(t) = y'(t) + y''(t) + y'''(t)\n\\tag{7}\\]\nAs many different frequency components are created by this simple two-tone test (and nonlinearity only up to 3rd order) we split the result into different equations and look at the result separately.\nFirst, we start with the fundamental tones:\n\\[\n\\begin{split}\n    y'(t) &= \\left( \\underbrace{\\alpha_1 A_1 + \\frac{3}{4} \\alpha_3 A_1^3}_\\text{compression/expansion} + \\underbrace{\\frac{3}{2} \\alpha_3 A_1 A_2^2}_\\text{cross-modulation/desens} \\right) \\cos(\\omega_1 t) \\\\\n    &+ \\left( \\underbrace{\\alpha_1 A_2 + \\frac{3}{4} \\alpha_3 A_2^3}_\\text{compression/expansion} + \\underbrace{\\frac{3}{2} \\alpha_3 A_2 A_1^2}_\\text{cross-modulation/desens} \\right) \\cos(\\omega_2 t)\n\\end{split}\n\\tag{8}\\]\nAs shown in Equation 8, interesting things happen:\n\nWe (again) have the gain compression/expansion effect as already discussed in Section 2.2.1.\nIn addition, we have cross-modulation, i.e., the envelope of one tone (e.g., \\(A_2(t)\\) of the tone at \\(\\omega_2\\)) impacts the envelope of the other tone at \\(\\omega_1\\). This can lead to unwanted signal distortion, even if there is a large frequency separation between \\(\\omega_1\\) and \\(\\omega_2\\)!\nFurther, since the sign of \\(\\alpha_3\\) is usually opposite to \\(\\alpha_1\\), this can also lead to desensitization (“desens”). If, for example, \\(A_2 \\gg A_1\\), then there would be no compression due to the tone \\(\\omega_1\\) itself, however, the large tone at \\(\\omega_2\\) will lead to gain compression of the tone at \\(\\omega_1\\); this effect is called desense.\n\nWe now look at the next class of generated tones:\n\\[\n\\begin{split}\n    y''(t) &= \\frac{1}{2} \\alpha_2 A_1^2 + \\frac{1}{2} \\alpha_2 A_2^2 \\\\\n    &+ \\alpha_2 A_1 A_2 \\cos[ (\\omega_1 - \\omega_2) t] \\\\\n    &+ \\alpha_2 A_1 A_2 \\cos[ (\\omega_1 + \\omega_2) t]\n\\end{split}\n\\tag{9}\\]\nAs we can see in Equation 9 new tones are created (besides the low frequency components we already know from the single-tone test) at the sum and difference of \\(\\omega_1\\) and \\(\\omega_2\\). These new frequency components are called “intermodulation products of second order” (IM2). These tones are created by the even-order nonlinearity (\\(\\alpha_2\\)). These IM2 products are far away from the wanted tones, so are often not very problematic in amplifiers (but there can be exceptions!). However, they can be very problematic in frequency conversion blocks like mixers. We will come back to this point when discussing zero-IF receivers.\nWe now investigate the next couple of tones:\n\\[\n\\begin{split}\n    y'''(t) &= \\frac{3}{4} \\alpha_3 A_1^2 A_2 \\cos[(2 \\omega_1 + \\omega_2) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1^2 A_2 \\cos[(2 \\omega_1 - \\omega_2) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1 A_2^2 \\cos[(2 \\omega_2 + \\omega_1) t] \\\\\n    &+ \\frac{3}{4} \\alpha_3 A_1 A_2^2 \\cos[(2 \\omega_2 - \\omega_1) t]\n\\end{split}\n\\tag{10}\\]\nThe tones shown in Equation 10 are called “intermodulation products of third order” (IM3), and are caused by the odd nonlinearities (like \\(\\alpha_3\\)). While the IM3 tones located at \\(2 \\omega_1 + \\omega_2\\) and \\(\\omega_1 + 2 \\omega_2\\) are similar to the sum IM2 tone and far away from \\(\\omega_1\\) and \\(\\omega_2\\), the other two tones are concerning.\nExpressing \\(\\Delta \\omega = \\omega_2 - \\omega_1\\) (and assuming \\(\\omega_1 &lt; \\omega_2\\)), the building law of \\(2 \\omega_1 - \\omega_2 = \\omega_1 - \\Delta \\omega\\) and \\(2 \\omega_2 - \\omega_1 = \\omega_2 + \\Delta \\omega\\) results in new tones right besides \\(\\omega_1\\) and \\(\\omega_2\\), with a frequency separation only defined by \\(\\Delta \\omega\\). This situation is illustrated in Figure 7.\n\n\n\n\n\n\n\n\nFigure 7: Two-tone test showing fundamental frequencies ω₁, ω₂ and third-order intermodulation products (IM3) at 2ω₁-ω₂ and 2ω₂-ω₁.\n\n\n\n\n\nThis close localization of the IM3 tones can also be utilized to characterize nonlinear performance. Using gain compression or harmonic generation (H3) it can be very difficult to extract nonlinearity of third order (\\(\\alpha_3\\)). However, using a two-tone test, the IM3 tones can be readily measured, even if the measured signal path shows a bandpass characteristic! As RF systems frequently employ bandpass filters to suppress out-of-band signals, this is a very important property of the two-tone test.\nThe resulting test is called a two-tone test yielding the third-order intercept point (IP3). This test is widely used in RF design to characterize the linearity of amplifiers, mixers, and complete transceiver systems. The power relationship between fundamental tones and IM3 products as a function of input power is shown in Figure 8.\n\n\n\n\n\n\n\n\nFigure 8: Two-tone IM3 test showing fundamental and IM3 product power vs. input power, with IP3 intercept point definition. Equal input power per tone is assumed.\n\n\n\n\n\nNote that, as shown in Figure 8, the IM3 products rise with a slope of 3 dB/dB, i.e., if the input power is increased by 1 dB, the IM3 products increase by 3 dB. The fundamental tones rise with a slope of 1 dB/dB (as long as we are in the linear region). The IP3 point is defined as the intersection of the extrapolated linear lines of fundamental and IM3 products. As both lines have different slopes, this intersection point is usually far outside the actual operating range of the circuit block under test!\nWhen calculating the IIP3 (input-referred IP3) we can use the following formula, assuming equal input power per tone. It is important to always check the slope of the IM3 products to ensure that we are indeed in the third-order region! If the input power per tone is \\(P_\\mathrm{in}\\) (in dBm) and the input-referred power of one IM3 tone is \\(P_\\mathrm{IM3}\\) (in dBm), then the input-referred IP3 is given by\n\\[\n\\text{IIP3} = P_\\mathrm{in} + \\frac{P_\\mathrm{in} - P_\\mathrm{IM3}}{2}\n\\tag{11}\\]\nFurther, for midly nonlinear systems (i.e., \\(\\alpha_3\\) is dominating), the IIP3 can be approximated from the 1dB compression point as\n\\[\n\\text{IIP3}|_\\mathrm{dBm} \\approx P_\\mathrm{1dB}|_\\mathrm{dBm} + 9.6\\,\\text{dB}.\n\\tag{12}\\]\nIf we have two blocks which are cascaded, and we know the gain and IIP3 of both blocks, we can calculate the overall IIP3 of the cascade with the following approximation. An exact calculation is very involved, as the nonlinearities of the first block (and the resulting tones) will be processed by the second block, creating even more tones; this process escalates very quickly. However, for practical purposes, the following approximation is often sufficient:\n\\[\n\\frac{1}{\\text{IIP3}_\\text{total}} \\approx \\frac{1}{\\text{IIP3}_1} + \\frac{G_1}{\\text{IIP3}_2} + \\frac{G_1 G_2}{\\text{IIP3}_3}\n\\tag{13}\\]\nHere \\(G_1\\) is the linear gain of the first block, and \\(\\text{IIP3}_1\\), \\(\\text{IIP3}_2\\) are the input-referred IP3 of the first and second block, respectively. Note that all powers have to be in linear units (i.e., Watts) when using Equation 13. An even more simplified version of Equation 13 can be used with all quantities given in dBm and dB, respectively:\n\\[\n\\text{IIP3}_\\text{total} \\approx \\min \\{  \\text{IIP3}_1, \\text{IIP3}_2 - G_1, \\text{IIP3}_3 - G_1 - G_2 \\}\n\\tag{14}\\]\nA typical RF system cascade with multiple blocks and their individual IIP3 contributions is shown in Figure 9.\n\n\n\n\n\n\n\n\nFigure 9: Block cascade for IIP3 calculation showing multiple stages with gains and individual IIP3 values.\n\n\n\n\n\n\n\n\n\n\n\nNote 4: Simple IIP3 Cascade Calculation\n\n\n\nLet’s calculate the overall IIP3 of two cascaded blocks. The first block is a low-noise amplifier with an IIP3 of -10 dBm and a gain of 20 dB. The second block is a mixer that has a gain of 10 dB and an IIP3 of 5 dBm. What is the overall IIP3?\nUsing Equation 14 we can quickly estimate:\n\\[\n\\text{IIP3}_\\text{total} \\approx \\min \\{ -10\\,\\text{dBm}, 5\\,\\text{dBm} - 20\\,\\text{dB} = -15\\,\\text{dBm} \\} = -15\\,\\text{dBm}\n\\]\nWe see that the overall IIP3 is limited by the linearity of the second block, as the first block amplifies all signals (including blockers) by 20 dB before they reach the second block."
  },
  {
    "objectID": "rfic.html#sec-noise",
    "href": "rfic.html#sec-noise",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.3 Noise",
    "text": "2.3 Noise\nJust as nonlinearity is a limiting factor for large signals, noise is the limiting factor for small signals. Noise is present in all electronic circuits and systems, and it is impossible to avoid it. However, we can try to minimize its impact on system performance.\nNoise is usually characterized by its power spectral density (PSD) in units of Watts per Hertz (W/Hz). For example, thermal noise at room temperature has a PSD of approximately \\(k T = 4 \\times 10^{-21}\\) W/Hz, or –174 dBm/Hz (with the Boltzmann constant \\(k = 1.38 \\times 10^{-23}\\,\\text{J/K}\\)). This means that if we have a bandwidth of 1 MHz, the total thermal noise power would be:\n\\[\nP_\\mathrm{thermal} = \\text{PSD} \\cdot B = -174\\,\\text{dBm/Hz} + 10 \\log_{10} \\left( \\frac{1\\,\\text{MHz}}{1\\,\\text{Hz}} \\right) = -114\\,\\text{dBm}\n\\]\nThe PSD of noise can be flat vs. frequency (which is called “white noise”), or can decrease with frequency (e.g., “flicker noise” or “1/f noise”). Further, noise can be generated by resistors (thermal noise), semiconductors (shot noise, generation-recombination noise), etc. A detailed discussion of noise sources can be found in (Gray et al. 2009) or (Razavi 2017).\n\n2.3.1 Types of Noise Generation\nResistors generate thermal noise, which is white noise with a PSD of \\(4 k T R\\) (in V\\(^2\\)/Hz) when looking at the voltage across the resistor, or \\(4 k T / R\\) (in A\\(^2\\)/Hz) when looking at the current through the resistor. This noise is generated by the random thermal motion of charge carriers in the resistor.\n\n\n\n\n\n\nImportantThermal Noise\n\n\n\nNote that the simple approximation given above is only valid for reasonably high frequencies and typical temperatures, and is known as the Rayleigh-Jeans approximation of Planck’s blackbody radiation accounting for quantum effects and is given by (Pozar 2011)\n\\[\n\\text{PSD} = \\frac{4 R h f}{e^{{h f}/{k T}} - 1}\n\\]\nwhere \\(h\\) is the Planck constant (\\(h = 6.626 \\times 10^{-34}\\) Js) and \\(f\\) is the frequency. The Rayleigh-Jeans approximation is valid for \\(f \\ll k T / h\\), which is approximately 6 THz at room temperature (290 K).\nWe can integrate the above PSD over the full frequency range and show the rms noise voltage of a resistor \\(R\\) is bounded to\n\\[\n\\overline{v_\\mathrm{n}^2} = \\int_0^\\infty \\frac{4 R h f}{e^{{h f}/{k T}} - 1} df = \\frac{2 (\\pi k T)^2}{3 h} \\cdot R\n\\]\nwhich equates to approximately 13 mVrms noise voltage for a 1 k\\(\\Omega\\) resistor at room temperature (which is impossible to measure in practice, as there will be some form of bandwidth limitation in any real measurement setup).\n\n\nMOSFETs generate several types of noise, the most important ones being the thermal noise of the channel and flicker noise.\nThe thermal noise of the channel can be modeled as a current noise source between drain and source with a PSD of \\(\\overline{I_\\mathrm{n}^2} = 4 k T \\gamma g_{d0}\\) (in A\\(^2\\)/Hz), where \\(\\gamma\\) is a process-dependent parameter (usually between 2/3 and 2). The parameter \\(g_{d0}\\) is the small-signal output conductance of the MOSFET in triode, i.e., \\(g_{d0} = g_\\mathrm{ds}\\), or equal to \\(g_{d0} = g_\\mathrm{m}\\) when in saturation.\nIn saturation, it is often useful to express the thermal noise as a voltage noise source at the gate with a PSD of \\(\\overline{V_\\mathrm{n}^2} = 4 k T \\gamma / g_\\mathrm{m}\\) (in V\\(^2\\)/Hz). We can see that we can lower this noise of the MOSFET by increasing the transconductance \\(g_\\mathrm{m}\\), which can be achieved by increasing the bias current.\nIn addition, at high frequencies, the MOSFET also has induced gate-current noise, which is correlated with the channel thermal noise. A detailed discussion of this noise source can be found in (Razavi 2017).\nFlicker noise is usually modeled as a voltage noise source at the gate with a PSD of \\(K_f / (C'_\\mathrm{ox}W L f)\\) (in V\\(^2\\)/Hz), where \\(K_f\\) is a process-dependent parameter, \\(C'_\\mathrm{ox}\\) is the oxide capacitance per unit area, \\(L\\) and \\(W\\) are the length and width of the MOSFET, and \\(f\\) is the frequency. Note that we can lower the flicker noise by increasing the area of the MOSFET (\\(W L\\)), however, this increases the parasitic capacitances associated with the MOSFET, and this often prohibitive for RF operation!\nIn bipolar junction transistors (BJTs), the most important noise source is the shot noise due to the diffusion current in the base-emitter junction. Its PSD can be modeled as a current noise source between collector and emitter with a PSD of \\(2 q I_\\mathrm{C}\\) (in A\\(^2\\)/Hz), where \\(q\\) is the elementary charge (\\(q = 1.6 \\times 10^{-19}\\) C) and \\(I_\\mathrm{C}\\) is the DC collector current.\n\n\n\n\n\n\nImportantEquivalence of Shot and Thermal Noise\n\n\n\nNote that it has been shown in (Sarpeshkar, Delbruck, and Mead 1993) that thermal noise and shot noise are actually equivalent, as both are generated by the random, thermally agitated motion of charge carriers!\n\n\nIdeal capacitors and inductors do not generate noise, however, real capacitors and inductors have parasitic resistances which generate thermal noise.\nIn RF systems additional noise sources can be present. One noteworthy example is the cosmic microwave background radiation, which can be modeled as a noise temperature of approximately 3 K. While this is negligible compared to thermal noise at room temperature (approximately 290 K), it can be significant in very low-noise systems, such as radio telescopes pointing to the sky. Another important noise source in RF systems is the atmospheric noise, which is generated by natural phenomena like lightning or in the ionosphere.\n\n\n\n\n\n\nNoteA Note on Circuit Noise Calculations\n\n\n\nWhen doing circuit noise calculations, it is instructive to keep the following points in mind:\n\nFor circuit calculations involving noise sources it is convenient to replace the power spectral density by equivalent sinusoidal generators in small bandwidths.\nThe noise power spectral density in a small bandwidth \\(\\Delta f\\) is given by \\(\\overline{V_\\mathrm{n}^2} = \\overline{v_\\mathrm{n}^2} / \\Delta f\\) and \\(\\overline{I_\\mathrm{n}^2} = \\overline{i_\\mathrm{n}^2} / \\Delta f\\).\nThe quantities \\(\\overline{V_\\mathrm{n}^2}\\) and \\(\\overline{I_\\mathrm{n}^2}\\) can be considered the mean-square value of sinusoidal generators. Using these values, network noise calculations reduce to familiar sinusoidal circuit-analysis calculations using \\(V_\\mathrm{n}\\) and \\(I_\\mathrm{n}\\).\nMultiple independent noise sources can be calculated individually at the output, and the total noise in bandwidth \\(\\Delta f\\) is calculated as a mean-square value by adding the individual mean-square contributions from each sinusoid.\n\n\n\n\n\n2.3.2 Noise in Impedance-Matched Systems\nWe now want to calculate the maximum noise power that can be extracted from a noisy source. We assume the following situation as shown in Figure 10. Note that the voltage source \\(\\overline{V_\\mathrm{n,s}^2}\\) models the thermal noise of the source resistor \\(R_\\mathrm{s}\\) resulting in a Thevenin equivalent circuit.\n\n\n\n\n\n\n\n\nFigure 10: A noise-matched system with source and load impedances.\n\n\n\n\n\nWe know that the noise of the source resistor is given by \\(\\overline{V_\\mathrm{n,s}^2} = 4 k T R_\\mathrm{s}\\). We assume the load resistor \\(R_\\mathrm{load}\\) as noiseless and matched to the source resistor, i.e., \\(R_\\mathrm{load} = R_\\mathrm{s}\\) for maximum power transfer. The noise power spectral density delivered to the load resistor is then given by\n\\[\nP_\\mathrm{n,load} = \\frac{\\overline{V_\\mathrm{n,load}^2}}{R_\\mathrm{load}} = \\frac{\\overline{V_\\mathrm{n,d}^2}}{4 R_\\mathrm{s}} = k T\n\\tag{15}\\]\nThe calculation of Equation 15 confirms the initial statement that the maximum noise power spectral density that can be extracted from a noisy source is \\(k T\\) (in W/Hz). This result is independent of the actual value of the source resistance \\(R_\\mathrm{s}\\).\nWe can further generalize the thermal noise of any impedance as\n\\[\n\\overline{V_\\mathrm{n}^2} = 4 k T \\Re \\{ Z \\}\n\\tag{16}\\]\nas for example in the complex impedance \\(Z_\\mathrm{ant}\\) of an antenna. Since an antenna is a reciprocal device, if we measure its radiation impedance \\(Z_\\mathrm{rad}\\) (for example with a vector network analyzer), we can calculate its thermal noise with Equation 16 to \\(\\overline{V_\\mathrm{n}^2} = 4 k T \\Re \\{ Z_\\mathrm{rad} \\}\\).\n\n\n2.3.3 Noise Figure\nIn RF systems, we often want to quantify the noise performance of a circuit block or a complete system. The most widely used metric is the noise factor (F), which is defined as the ratio of the signal-to-noise ratio (SNR) at the input to the SNR at the output of a circuit block or system. If we express the noise factor in dB, we call it the noise figure (NF) (Pozar 2011). The noise factor is given by\n\\[\nF = \\frac{\\text{SNR}_\\mathrm{in}}{\\text{SNR}_\\mathrm{out}} = \\frac{(P_\\mathrm{s}/P_\\mathrm{n})_\\mathrm{in}}{(P_\\mathrm{s}/P_\\mathrm{n})_\\mathrm{out}}\n\\tag{17}\\]\nwhere \\(P_\\mathrm{s}\\) is the signal power and \\(P_\\mathrm{n}\\) is the noise power. The noise factor is always larger than or equal to 1 (or 0 dB), as no circuit can improve the SNR!\n\n\n\n\n\n\nImportantSNR Improvement\n\n\n\nNote that the SNR can be improved by filtering, as filtering reduces the noise power. If the noise bandwidth is larger than the signal bandwidth, then the SNR can be improved without affecting the signal. However, this is not considered in the noise factor, as the noise factor assumes that both signal and noise pass through the same bandwidth.\n\n\nLet us look at a simple model of a noise circuit block as shown in Figure 11. The input signal \\(S_\\mathrm{in}\\) is accompanied by noise \\(N_\\mathrm{in}\\). By definition it is assumed that the input noise power results from a matched resistor at \\(T_0 = 290\\,\\text{K}\\), so that \\(N_\\mathrm{in} = k T_0\\). The circuit block has a power gain \\(G\\) and adds its own noise \\(N_\\mathrm{dut}\\) to the output signal. For simplicity, we assume that the input and output of the circuit block are impedance matched to avoid reflections.\n\n\n\n\n\n\n\n\nFigure 11: A noise-matched system with source and load impedances and a noisy circuit block.\n\n\n\n\n\nThe output signal and noise powers are then given by\n\\[\nS_\\mathrm{out} = G S_\\mathrm{in}\n\\]\n\\[\nN_\\mathrm{out} = G N_\\mathrm{in} + N_\\mathrm{dut}\n\\] The resulting noise factor can then be calculated as\n\\[\nF = \\frac{{S_\\mathrm{in}}/{N_\\mathrm{in}}}{{S_\\mathrm{out}}/{N_\\mathrm{out}}} = \\frac{1}{G} \\frac{G N_\\mathrm{in} + N_\\mathrm{dut}}{N_\\mathrm{in}} = 1 + \\frac{N_\\mathrm{dut}}{G N_\\mathrm{in}},\n\\]\nin other words, the noise factor is 1 plus the ratio of the noise added by the device under test (DUT) to the amplified input noise.\nNote that a noiseless block (\\(N_\\mathrm{dut} = 0\\)) has a noise factor of \\(F=1\\). A passive block with loss factor \\(L\\) (and impedance matched at input and output) has a noise factor of \\(F=L\\) (in linear units), as it attenuates the signal and \\(N_\\mathrm{out} = N_\\mathrm{in} = k T\\) if everything is in thermal equilibrium.\n\n\n\n\n\n\n\n\nFigure 12: Block cascade for noise factor calculation showing multiple stages with gains and individual noise factors.\n\n\n\n\n\nIf we have a cascade of multiple blocks, as shown in Figure 12, we can calculate the overall noise factor with the Friis formula (Pozar 2011)\n\\[\nF_\\mathrm{total} = 1 + (F_1 - 1) + \\frac{F_2 - 1}{G_1} + \\frac{F_3 - 1}{G_1 G_2}\n\\tag{18}\\]\nwhere \\(F_i\\) and \\(G_i\\) are the noise factor and power gain of the \\(i\\)-th block, respectively. Note that all gains have to be in linear units (not dB) when using Equation 18. We can interpret Equation 18 as follows:\n\nThe overall noise factor \\(F_\\mathrm{total}\\) is always larger than or equal to the noise factor of the first block (\\(F_1\\)).\nThe noise factor of the first block is the most important one, as the noise factors of the following blocks are reduced by the gain of all preceding blocks. This is especially important in RF receivers, where the first block is usually a low-noise amplifier (LNA) with a very low noise figure (e.g., 1 dB or less) and a high gain (e.g., 10 dB or more). This ensures that the noise of the following blocks is negligible.\nThe noise factor of the last block is reduced by the gain of all preceding blocks, so it is usually not very important.\n\nHere we also see a trade-off between noise and linearity, as shown by Equation 13 and Equation 18. For low noise, we should try to maximize \\(G_1\\), however, this will affect linearity (IIP3) in a negative way. As in many other situation in RF design, we have to find a good compromise between conflicting requirements.\n\n\n2.3.4 Sensitivity\nIn RF receivers, we often want to know the minimum input signal power that can be detected with a certain SNR. This minimum input signal power is called the sensitivity of the receiver. The sensitivity can be calculated as\n\\[\nP_\\mathrm{in, min} = P_\\mathrm{n} \\cdot \\text{SNR}_\\mathrm{min} \\cdot F\n\\tag{19}\\]\nwhere \\(P_\\mathrm{n}\\) is the noise power at the input, \\(\\text{SNR}_\\mathrm{min}\\) is the minimum detectable SNR, and \\(F\\) is the noise factor of the receiver. The input noise power can be calculated as\n\\[\nP_\\mathrm{n} = k T B\n\\]\nwhere \\(k\\) is the Boltzmann constant, \\(T\\) is the temperature in Kelvin, and \\(B\\) is the bandwidth of the receiver. Expressing Equation 19 in dBm we get the following formula:\n\\[\nP_\\mathrm{in, min}|_\\mathrm{dBm} = -174\\,\\text{dBm/Hz} + \\text{NF} + 10 \\log_{10}(B/\\text{Hz}) + \\text{SNR}_\\mathrm{min}|_\\mathrm{dB}\n\\tag{20}\\]\nwhere -174 dBm/Hz is the thermal noise PSD at room temperature (290 K). We can see that the sensitivity improves with lower noise figure, smaller bandwidth, and lower minimum detectable SNR.\n\n\n\n\n\n\nNote 5: Sensitivity Calculation for WiFi\n\n\n\nLet’s calculate the sensitivity of a WiFi receiver operating at 5 GHz with a bandwidth of \\(B = 80\\,\\text{MHz}\\), a noise figure of \\(NF = 7\\,\\text{dB}\\), and a minimum detectable SNR of 25 dB. This high SNR means that a high-order modulation scheme (like 64-QAM) is used for high data rates.\nUsing Equation 20 we get: \\[\nP_\\mathrm{in, min} = -174\\,\\text{dBm/Hz} + 7\\,\\text{dB} + 10 \\log_{10} (80 \\times 10^6) + 25\\,\\text{dB} \\approx -63\\,\\text{dBm}\n\\]\nThis means that the minimum input signal power that can be detected by the WiFi receiver is approximately -63 dBm."
  },
  {
    "objectID": "rfic.html#sec-fundamentals-modulation",
    "href": "rfic.html#sec-fundamentals-modulation",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.4 Modulation",
    "text": "2.4 Modulation\nIn order to transmit information via an EM wave, we need to modulate the EM wave with the information signal. Looking at a simple sinusoidal carrier wave\n\\[\ns(t) = A \\cos(\\omega_0 t + \\varphi)\n\\]\nwe see that we can change one or more of the following parameters to encode information:\n\nAmplitude \\(A(t)\\) (amplitude modulation, AM; the digital form is called amplitude-shift keying, ASK)\nFrequency \\(\\omega_0(t)\\) (frequency modulation, FM; the digital form is called frequency-shift keying, FSK)\nPhase \\(\\varphi(t)\\) (phase modulation, PM; the digital form is called phase-shift keying, PSK)\nAmplitude \\(A(t)\\) and phase \\(\\varphi(t)\\) (quadrature amplitude modulation, QAM)\n\nThe modulation formats FM and PM have the advantage that the carrier amplitude is constant, which makes them more robust against nonlinear distortion.\nQAM is widely used in modern communication systems, as it allows to transmit more bits per symbol by combining amplitude and phase modulation. The form with 4 different symbols is called QPSK. Higher-order modulation like 16-QAM, for example, uses 16 different symbols, which can encode 4 bits per symbol (as \\(2^4 = 16\\)). Even higher-order QAM formats like 64-QAM (6 bits per symbol), 256-QAM (8 bits per symbol), 1024-QAM (10 bits per symbol), or 4096-QAM (12 bits per symbol) are also used in modern systems like WiFi or LTE.\n\n\n\n\n\n\n\n\nFigure 13: 16-QAM constellation diagram with Gray code labeling of constellation points.\n\n\n\n\n\nShown in Figure 13 is the “constellation diagram” of a 16-QAM modulation format. The constellation points are arranged in a square grid, with each point representing a unique combination of amplitude and phase. The distance between the constellation points determines the robustness against noise and interference; larger distances result in better performance, but also require more bandwidth. The mapping of bits to constellation points is called “bit mapping” or “symbol mapping”. The example in Figure 13 uses a Gray code mapping, which minimizes the number of bit errors in case of a symbol error.\nThe constellation diagram can be imagined as a complex plane, where the x-axis represents the in-phase component (I) and the y-axis represents the quadrature component (Q) of the modulated signal. During transmission of a specific symbol, the RF carrier is modulated to the corresponding amplitude and phase, resulting in a specific point in the constellation diagram. In Figure 13, the amplitude and phase information for two consecutive symbols, \\(A_N\\)/\\(\\varphi_N\\) and \\(A_{N+1}\\)/\\(\\varphi_{N+1}\\), is shown.\nThe table below shows the SNR requirements for different modulation formats to achieve a bit error rate (BER) of \\(10^{-5}\\) in an additive white Gaussian noise (AWGN) channel. As we can see, higher-order modulation formats require higher SNR to achieve the same BER.\n\n\n\nTable 3: SNR requirements for different modulation schemes to achieve BER = \\(10^{-5}\\) in AWGN channel\n\n\n\n\n\nModulation\nBits/Symbol\nRequired SNR (dB)\n\n\n\n\nBPSK\n1\n9.6\n\n\nQPSK\n2\n12.6\n\n\n16-QAM\n4\n18.2\n\n\n64-QAM\n6\n24.4\n\n\n256-QAM\n8\n30.6\n\n\n1024-QAM\n10\n36.9\n\n\n4096-QAM\n12\n43.2"
  },
  {
    "objectID": "rfic.html#sec-fundamentals-pulse-shaping",
    "href": "rfic.html#sec-fundamentals-pulse-shaping",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.5 Pulse Shaping and Spectral Efficiency",
    "text": "2.5 Pulse Shaping and Spectral Efficiency\nWhen we modulate symbols onto a carrier, we usually do not transmit the symbols as pure sinusoids, but rather as pulses with a certain shape. The pulse shape determines the bandwidth of the transmitted signal and its spectral efficiency. A common pulse shape is the rectangular pulse, which has a sinc-shaped spectrum. However, the sinc function \\(\\sin(\\pi x)/ \\pi x\\) has side lobes that extend to infinity, which can cause interference with adjacent channels.\nFor reference, the spectrum of a random binary sequence with equal probability of 0s and 1s, using rectangular pulses with a duration of \\(T_\\mathrm{b}\\) is given by (\\(S(f)\\) is the two-sided power spectral density):\n\\[\nS(f) = \\frac{T_\\mathrm{b}}{4} \\text{sinc}^2(fT_\\mathrm{b}) + \\frac{1}{4} \\delta(f) = \\frac{T_\\mathrm{b}}{4} \\left( \\frac{\\sin(\\pi f T_\\mathrm{b})}{\\pi f T_\\mathrm{b}} \\right)^2 + \\frac{1}{4} \\delta(f)\n\\]\nTo avoid this, we can use pulse shapes that have better spectral properties, such as the raised cosine pulse or the root-raised cosine pulse. The raised-cosine pulse has a roll-off factor \\(\\alpha\\) that determines the excess bandwidth beyond the Nyquist bandwidth. The root-raised cosine (RRC) pulse is used in practical systems, as it can be implemented with a matched filter at the receiver.\nThe raised-cosine pulse \\(p(t)\\) (with a spectrum shaped like a raised cosine) is given by:\n\\[\np(t) = \\frac{\\sin(\\pi t / T_\\mathrm{b})}{\\pi t / T_\\mathrm{b}} \\cdot \\frac{\\cos(\\alpha \\pi t / T_\\mathrm{b})}{1 - (2 \\alpha t / T_\\mathrm{b})^2}\n\\]\nSetting \\(\\alpha = 0\\) results in a sinc pulse in the time domain (with a perfect bandwidth containment in the frequency domain), while \\(\\alpha = 1\\) results in a pulse with double the Nyquist bandwidth. The pulse shape for \\(\\alpha = 0\\) and \\(\\alpha = 0.22\\) (used in 3G) is shown in Figure 14.\n\n\n\n\n\n\n\n\nFigure 14: Raised cosine pulse shaping in time and frequency domain for different roll-off factors α.\n\n\n\n\n\nAnother often-used pulse shape is the Gaussian pulse, which is used in Gaussian minimum-shift keying (GMSK, used in 2G) modulation, or in Gaussian frequency-shift keying (GFSK, used in Bluetooth). The Gaussian pulse has a smooth shape and a narrow spectrum. The Gaussian pulse is given by:\n\\[\np(t) = \\frac{\\sqrt{\\pi}}{\\alpha} e^{-(\\pi t / \\alpha)^2} \\quad \\text{with} \\quad \\alpha = \\frac{\\sqrt{\\ln 2}}{\\sqrt{2}} \\cdot \\frac{T_\\mathrm{b}}{B T_\\mathrm{b}}\n\\]\nwhere \\(B T_\\mathrm{b}\\) controls the width of the pulse. The spectrum of the Gaussian pulse is also Gaussian-shaped, which helps to minimize inter-symbol interference (ISI).\nThe Gaussian pulse for \\(BT=0.5\\) as used in Bluetooth is shown in Figure 15.\n\n\n\n\n\n\n\n\nFigure 15: Gaussian pulse shaping in time and frequency domain for different bandwidth-time products BT.\n\n\n\n\n\nFor both the raised-cosine and Gaussian pulse, the trade-off between time- and frequency-domain containment is clearly visible. This is also captured in “Küpfmüller’s uncertainty principle”, which states that the product of the time duration and the bandwidth of a pulse is lower-bounded by a constant. In other words, if we want to have a pulse that is very short in time, it will have a wide bandwidth, and vice versa."
  },
  {
    "objectID": "rfic.html#sec-fundamentals-ofdm",
    "href": "rfic.html#sec-fundamentals-ofdm",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.6 Orthogonal Frequency-Division Multiplexing (OFDM)",
    "text": "2.6 Orthogonal Frequency-Division Multiplexing (OFDM)\nAs we have seen in the previous section, if we make the symbol rate high, we need to use pulses with a wide bandwidth. The problem with a wide bandwidth in wireless communication is multi-path propagation, which causes frequency-selective fading. This means that some frequencies are attenuated more than others, which can cause errors in the received signal. Equalizing such a frequency-selective channel can be very complex, especially if the channel changes rapidly (as in mobile communication). We now face a dilemma: How can we achieve high data rates (which require high symbol rates and thus wide bandwidth) while avoiding frequency-selective fading? The key idea, implemented in OFDM, is to split the wideband channel into multiple narrowband sub-channels (subcarriers), each with a low symbol rate. This way, each subcarrier experiences flat fading, which is much easier to equalize.\nThe key question is now how to implement this idea efficiently, as we now have to apply modulation to hundreds or thousands of individual subcarriers. The solution is to use the inverse fast Fourier transform (IFFT) at the transmitter to generate the time-domain OFDM signal from the frequency-domain symbols, and the fast Fourier transform (FFT) at the receiver to recover the frequency-domain symbols from the time-domain OFDM signal. This is illustrated in Figure 16.\n\n\n\n\n\n\n\n\nFigure 16: OFDM transmission system block diagram showing transmitter and receiver processing chains.\n\n\n\n\n\nThe OFDM transmitter takes a block of \\(N\\) symbols (e.g., 64-QAM symbols) and maps them onto \\(N\\) subcarriers, thereby reducing the symbol rate for each subcarrier to \\(T_\\mathrm{b} / N\\). The IFFT then generates the time-domain OFDM signal, which is transmitted over the wireless channel. Before transmission the cyclic prefix (CP) is added to each OFDM symbol.\nAt the receiver, first the CP is removed, and then the FFT recovers the frequency-domain symbols, which can then be equalized (fairly simply by multiplying each subcarrier with a complex factor to correct amplitude and phase) and demodulated.\nA key property of OFDM is that the subcarriers are orthogonal to each other, which means that they do not interfere with each other, even if they overlap in frequency. This is achieved by choosing the subcarrier spacing \\(\\Delta f\\) such that it is equal to the symbol rate \\(1/T_\\mathrm{b}\\), i.e., \\(\\Delta f = 1/T_\\mathrm{b}\\). This way, the integral of the product of two different subcarriers over one symbol period is zero, which means that they are orthogonal.\nTo further improve the robustness against multi-path propagation, a CP is added to each OFDM symbol. The CP is a copy of the last part of the OFDM symbol, which is added to the beginning of the symbol. This way, if there are delayed copies of the OFDM symbol due to multi-path propagation, they will still fall within the CP and will not cause inter-symbol interference (ISI). The length of the CP should be longer than the maximum delay spread of the channel.\n\n\n\n\n\n\nNote 6: OFDM in LTE\n\n\n\nIn LTE OFDM is used for the downlink (base station to user equipment) with the following parameters:\n\nSubcarrier spacing: 15 kHz\nCP length: 5.2 µs (normal), 4.7 µs (extended)\nNumber of subcarriers: 1200 (for 20 MHz bandwidth)\nModulation: QPSK, 16-QAM, 64-QAM, 256-QAM\n\nFrom the subcarrier spacing we can calculate the symbol duration as \\(T_\\mathrm{b} = 1 / \\Delta f = 1 / 15\\,\\text{kHz} \\approx 66.7\\,\\mu\\text{s}\\).\nWe can calculate the raw bitrate for a 20 MHz LTE channel as\n\\[\n\\text{Bitrate} = N_\\mathrm{sc} \\cdot N_\\mathrm{sym} \\cdot \\frac{1}{T_\\mathrm{b} + T_\\mathrm{CP}} = 1200 \\cdot 8 \\cdot \\frac{1}{66.7\\,\\mu\\text{s} + 5.2\\,\\mu\\text{s}} \\approx 133\\,\\text{Mbps}\n\\]\nWithout the overhead for control channels and error correction coding a user datarate of approximately 100 Mbps can be achieved in a 20 MHz LTE channel."
  },
  {
    "objectID": "rfic.html#sec-fundamentals-multiple-access",
    "href": "rfic.html#sec-fundamentals-multiple-access",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "2.7 Multiple Access Techniques",
    "text": "2.7 Multiple Access Techniques\nIn wireless communication systems, multiple users need to share the same frequency spectrum. This is achieved by using multiple access techniques, which allow multiple users to transmit and receive data simultaneously without interfering with each other. The most common multiple access techniques are:\n\nTime division multiple access (TDMA): Users are assigned specific time slots for transmission, allowing multiple users to share the same frequency channel by dividing the time into slots.\nFrequency division multiple access (FDMA): Users are assigned specific frequency bands within the overall frequency spectrum, allowing multiple users to transmit simultaneously on different frequencies.\nCode division multiple access (CDMA): Users are assigned unique spreading codes, allowing them to transmit simultaneously over the same frequency band. The receiver uses the code to extract the desired signal. A variant of CDMA is frequency-hopping spread spectrum (FHSS), where the carrier frequency is changed rapidly according to a pseudo-random sequence known to both the transmitter and receiver. This is used in Bluetooth.\nOrthogonal frequency division multiple access (OFDMA): A variant of OFDM, where multiple users are assigned different subcarriers for transmission, allowing for efficient use of the frequency spectrum. This is used in 4G LTE and 5G NR.\nSpatial division multiple access (SDMA): Uses multiple antennas to create spatially separated channels, allowing multiple users to transmit simultaneously in the same frequency band.\n\nIn addition, all of these techniques can be combined to create more efficient and flexible communication systems. For example, OFDMA can be used in conjunction with SDMA to allow multiple users to share the same frequency resources while also taking advantage of spatial diversity. Also, TDMA can be combined with FDMA to create a hybrid multiple access scheme (which has been used in 2G GSM)."
  },
  {
    "objectID": "rfic.html#sec-trx-direct-conversion",
    "href": "rfic.html#sec-trx-direct-conversion",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.1 Direct-Conversion Transceiver",
    "text": "3.1 Direct-Conversion Transceiver\nThe following typical functions have to be performed by a TRX:\n\nPulse-shaping filtering of the baseband signal (can be implemented analog or in most cases digital).\nModulating the baseband signal onto a carrier frequency (upconversion) in the TX or downconversion in the RX.\nContain the RF signal in a small bandwidth (TX), or single out the wanted signal in the RX.\nAdapt gain (and linearity) to the signal strength in the RX, and to the output power in the TX.\nGenerate the carrier frequency (local oscillator, LO) with low phase noise.\n\nThe dominant architecture for the TRX is the so-called direct-conversion (or Zero-IF) architecture, where the upconversion and downconversion is performed in a single step. This is in contrast to superheterodyne architectures, where the signal is first converted to an intermediate frequency (IF) before being converted to baseband. The direct-conversion architecture has the advantage of reduced complexity and cost, as it requires fewer components and less filtering. However, it also has some disadvantages, such as increased susceptibility to DC offsets and I/Q imbalance. A typical TRX block diagram is shown in Figure Figure 17.\n\n\n\n\n\n\n\n\nFigure 17: Block diagram of a typical transceiver (TRX) showing the main functional blocks of RX and TX. The modem provides the digital baseband processing and interfaces to the rest of the system.\n\n\n\n\n\nAs can be seen in Figure 17, this generic example can be adapted in various ways. Generally, the amplifier gains are adjustable to adapt to different signal levels. If various channel bandwidths are to be supported, the corner frequencies of the low-pass filters (LPF) can be adjusted, as well as (optionally) the sampling rate of the ADCs and DACs. The local oscillator (LO) frequency is generated by a phase-locked loop (PLL) synthesizer, which can be tuned to the desired carrier frequency. In case of frequency-division duplex (FDD) operation, two PLLs are used to generate the TX and RX LO frequencies, which are separated by the duplex distance. In time-division duplex (TDD) operation, a single PLL is sufficient, supplying the LO signal to both RX and TX.\nThe modem that is shown in Figure 17 is responsible for the digital baseband processing, including functions like channel coding/decoding, modulation/demodulation, equalization, and error correction. The modem is usually implemented as a digital System-on-Chip (SoC) consisting of (multiple) CPUS, DSPs, and fixed-function blocks for time-critical processing. For an in-depth discussion we recommend (Sklar and Harris 2020) or (Molisch 2022)."
  },
  {
    "objectID": "rfic.html#sec-trx-mod-demod",
    "href": "rfic.html#sec-trx-mod-demod",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.2 Modulation and Demodulation",
    "text": "3.2 Modulation and Demodulation\nModulation is the process of varying a carrier signal at frequency \\(f_\\mathrm{c}\\) in order to transmit information. The complex baseband signal (after converting the real-valued digital \\(s_\\mathrm{I}\\) and \\(s_\\mathrm{Q}\\) signals to analog and pulse-shaping filtering) is represented as\n\\[\ns_\\mathrm{BB}(t) = s_\\mathrm{I}(t) + j s_\\mathrm{Q}(t).\n\\]\nWe want to shift this signal to the carrier frequency \\(f_\\mathrm{c}\\), which can be done by multiplying with a complex exponential:\n\\[\ns_\\mathrm{RF,complex}(t) = s_\\mathrm{BB}(t) \\cdot e^{j \\omega_\\mathrm{c} t} = [s_\\mathrm{I}(t) + j s_\\mathrm{Q}(t)] \\cdot [\\cos(\\omega_\\mathrm{c} t) + j \\sin(\\omega_\\mathrm{c} t)].\n\\]\nThe real-valued RF signal is obtained by taking the real part of this expression:\n\\[\ns_\\mathrm{RF}(t) = \\Re \\{ s_\\mathrm{RF,complex}(t) \\} = s_\\mathrm{I}(t) \\cos(\\omega_\\mathrm{c} t) - s_\\mathrm{Q}(t) \\sin(\\omega_\\mathrm{c} t).\n\\tag{21}\\]\nThe process formulated in Equation 21 is done in the TX, as shown in Figure 18.\n\n\n\n\n\n\n\n\nFigure 18: TX modulator.\n\n\n\n\n\nThe RF signal generation according to Equation 21 is called quadrature modulation. This is the modulation used most often in modern communication systems, as it allows to transmit two independent signals (I and Q) in the same bandwidth. The I and Q signals are also called quadrature components, as they are 90° out of phase with each other.\nAlternatively, a modulation called polar modulation can be used, where the amplitude and phase of the carrier are varied according to the baseband signal. This is done by converting the I and Q signals to polar coordinates\n\\[\ns_\\mathrm{RF}(t) = \\Re \\{ A(t) \\cdot e^{j \\varphi(t)} \\cdot e^{j \\omega_\\mathrm{c} t} \\}\n\\]\nwith\n\\[\nA(t) = \\sqrt{s_\\mathrm{I}^2(t) + s_\\mathrm{Q}^2(t)}, \\quad \\varphi(t) = \\tan^{-1}\\left(\\frac{s_\\mathrm{I}(t)}{s_\\mathrm{Q}(t)}\\right).\n\\]\nAs the mathematical operations required for the cartesian to polar transformation are quite nonlinear, the \\(A(t)\\) and \\(\\phi(t)\\) signals are wideband. Some wireless standards allow efficient use of polar modulation, for example Bluetooth, where basically all TX are realized as polar modulators.\nIn the RX, the received RF signal is downconverted to baseband by a similar process, as shown in Figure 19.\n\n\n\n\n\n\n\n\nFigure 19: RX demodulator.\n\n\n\n\n\nFor demodulation we have to shift the RF signal down to baseband, which mathematically is done by multiplying with the complex conjugate of the carrier:\n\\[\ns_\\mathrm{BB,complex}(t) = s_\\mathrm{RF}(t) \\cdot e^{-j \\omega_\\mathrm{c} t} = s_\\mathrm{RF}(t) \\cdot [\\cos(\\omega_\\mathrm{c} t) - j \\sin(\\omega_\\mathrm{c} t)]\n\\tag{22}\\]"
  },
  {
    "objectID": "rfic.html#filtering",
    "href": "rfic.html#filtering",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.3 Filtering",
    "text": "3.3 Filtering\nFiltering is an essential function in both TX and RX. In the TX, filtering is used to limit the bandwidth of the transmitted signal to the allocated channel bandwidth, and to suppress out-of-band emissions. In the RX, filtering is used to select the wanted signal from a crowded spectrum, and to suppress unwanted signals (blockers) that can cause interference or desensitization of the RX. A typical example of filtering in the RX is shown in Figure 20, where a bandpass filter is used to attenuate strong unwanted blockers while only slightly attenuating the wanted signal.\n\n\n\n\n\n\n\n\nFigure 20: Filtering of wanted channel amid strong unwanted blockers. Exemplary shown in an RX scenario around 900 MHz. The strong blockers (top figure) are attenuated by an RF bandpass filter (bottom figure) with a bandwidth of 20 MHz, achieving more than 40 dB rejection of the blockers while only slightly attenuating the wanted signal.\n\n\n\n\n\nIn any filter there exists a fundamental trade-off between selectivity (steepness of the filter skirts), bandwidth, and insertion loss. A very selective filter with steep skirts and large BW will have a high insertion loss. Conversely, a filter with low insertion loss will have a gentle roll-off and may not sufficiently suppress unwanted signals. A useful metric to quantify the performance of a filter is the quality factor \\(Q\\), defined as\n\\[\nQ = \\frac{f_\\mathrm{c}}{\\Delta f}\n\\]\nwhere \\(f_\\mathrm{c}\\) is the center frequency and \\(\\Delta f\\) is the –3 dB bandwidth of the filter. A higher \\(Q\\) indicates a more selective filter.\nThe achievable \\(Q\\) depends on the filter technology used. For example, on-chip LC filters can achieve \\(Q\\) values of around 10-20, while off-chip SAW or BAW/FBAR filters can achieve \\(Q\\) values of several hundreds, and a crystal filter can achieve \\(Q\\) values of several thousands. The choice of filter technology depends on the application requirements, such as frequency range, bandwidth, insertion loss, and cost. Generally speaking, the required filtering to single out the wanted signal in the RX spectrum and decrease the power of strong blockers to a tolerable level is one of the most critical design choices, and is usually distributed at different locations in the RX chain:\n\nRF filters (between antenna and LNA) provide a first level of filtering, and are usually implemented as off-chip SAW or BAW/FBAR filters. They provide high \\(Q\\) and good selectivity, but have a fixed center frequency and bandwidth. They are used to pass the wanted band of interest, and to attenuate strong out-of-band blockers.\nIF filters (in case of a super-heterodyne receiver) provide additional filtering, and can be implemented as on-chip LC filters or off-chip SAW/BAW filters. They provide moderate \\(Q\\) and selectivity, and can be tuned to some extent.\nBB filters (after downconversion) provide the final level of filtering before entering the ADCs, and are usually implemented as on-chip active RC filters. They provide channel selection, and can be easily adjusted to different bandwidths.\nDigital filters (in the DSP block) provide the final level of filtering and signal processing, and can be implemented as FIR or IIR filters. They provide high flexibility and can be easily adapted to different standards and requirements. Digital filters show now variations, so they can be designed to be very selective.\n\nIt is important to note (because this dictates a lot of choices in RF design) that high-\\(Q\\) filters are usually fixed-frequency and fixed-bandwidth. Only baseband and digital filters can be easily adjusted to different bandwidths!\n\n\n\n\n\n\nImportantFilter Technologies\n\n\n\nBaseband filters (analog) are usually implemented as active \\(RC\\) filters on-chip. They are very flexible and can have adjustable bandwidth by either changing \\(R\\) and/or \\(C\\). For medium frequencies \\(g_\\mathrm{m}-C\\) filters can be used, which are also tunable by changing the transconductance \\(g_\\mathrm{m}\\) and/or \\(C\\). For even higher bandwidths, on-chip LC filters can be used, which have a limited \\(Q\\) of around 10-20.\nBaseband filters (digital) are implemented as FIR or IIR filters in the DSP block. They are very flexible and can be easily adapted to different standards and requirements. Digital filters show no variations, so they can be designed to be very selective.\nSurface acoustic wave (SAW) and bulk acoustic wave (BAW/FBAR) filters are off-chip components that can achieve high \\(Q\\) values of several hundreds. They have a fixed center frequency and bandwidth. Usually 1-2 such filters are required per supported band of interest.\nCrystal filters can achieve very high \\(Q\\) values of several thousands, but are usually bulky and expensive.\nLC filters can be either implemented off-chip (using discrete components) or on-chip. Off-chip LC filters can achieve higher \\(Q\\) values than on-chip LC filters, but are usually larger and more expensive. On-chip LC filters are limited in \\(Q\\) (around 10-20), but are very compact and can be integrated into the RFIC. Off-chip LC filters can achieve \\(Q\\) values of around 50-100, depending on the frequency and component quality.\nCeramic filters are another off-chip filter technology that can achieve moderate to high \\(Q\\) values (up to several hundreds). They are usually smaller and less expensive than SAW or BAW/FBAR filters, but also lower performance.\nWaveguide filters are used at very high frequencies (above 10 GHz) and can achieve very high \\(Q\\) values (up to several thousands). They are usually bulky and expensive, and are not commonly used in mobile applications, but rather in fixed installations like base stations or satellite communication.\n\n\nFundamentally, the choice of filter technology is a trade-off between performance, size, cost, and flexibility. In most cases, a combination of different filter technologies is used to achieve the desired performance."
  },
  {
    "objectID": "rfic.html#direct-conversion-architecture",
    "href": "rfic.html#direct-conversion-architecture",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.4 Direct-Conversion Architecture",
    "text": "3.4 Direct-Conversion Architecture\nThe transceiver architecture shown in Figure 17 is called direct-conversion or zero-IF architecture, as the downconversion in the RX and upconversion in the TX is done in a single step. This architecture has several advantages:\n\nPer RX and TX a single LO is required (which can even be shared between RX and TX in TDD operation).\nThere are a minimum number of RF blocks, which is good for cost and power consumption.\nThis architecture is very flexible and can be easily adapted to different standards and requirements, and generally shows very good performance if the disadvantages can be overcome by good design.\nThis architecture allows a high integration level, as basically all blocks can be implemented on-chip.\nDirect conversion is the de-facto standard architecture for cellular, WiFi, Bluetooth (with the exception of the TX), and GNSS.\n\nHowever, the direct-conversion architecture also has some disadvantages:\n\nLO-RF coupling can cause self-mixing and desensitization of the RX, as well as LO leakage in the TX. This is an issue because the LO frequency is the same as the RF frequency.\nEven-order distortion products (especially IIP2) cause sensitivity degradation due to strong amplitude-modulated blockers.\nLO pulling can occur in the TX (again, LO and RF are at the same frequency).\nIQ errors (gain and phase mismatch) of the \\(I\\) and \\(Q\\) paths can cause constellation distortion leading to increased error vector magnitude (EVM).\nDC offsets can occur due to self-mixing of LO leakage and even-order distortion products.\nFlicker noise (1/f noise) upconversion can cause increased phase noise close to the carrier, as well as increased RX noise figure.\n\nNowadays there exist good design techniques to mitigate these disadvantages. However, in some cases (for example very high linearity requirements, or very high frequencies) other architectures like low-IF or super-heterodyne may be preferred."
  },
  {
    "objectID": "rfic.html#duplexing",
    "href": "rfic.html#duplexing",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.5 Duplexing",
    "text": "3.5 Duplexing\nIn the block diagram of Figure 17, we have not yet considered how to share the antenna between RX and TX. Essentially, there are two main methods to achieve this: frequency-division duplex (FDD) and time-division duplex (TDD).\n\n3.5.1 Frequency-Division Duplex (FDD)\nIn FDD, the RX and TX operate at different frequencies, separated by a duplex distance. This allows simultaneous transmission and reception, which is beneficial for applications like voice communication where low latency is required. However, FDD requires two separate frequency bands, which can be a limitation in terms of spectrum availability. Additionally, FDD requires two PLLs to generate the RX and TX LO frequencies, which increases complexity and power consumption.\nThe RF RX and TX paths are connected to the antenna via a duplexer, which is a three-port device that allows signals to pass between the antenna and the RX or TX path, while isolating the RX and TX paths from each other. A typical FDD TRX block diagram is shown in Figure 21.\n\n\n\n\n\n\n\n\nFigure 21: Block diagram of an FDD RF front-end.\n\n\n\n\n\nAdvantages of FDD:\n\nRX and TX can operate simultaneously, which is beneficial for low-latency applications.\nThere is no need for fast switching between RX and TX, which simplifies the design.\nRelaxed synchronization requirements between RX and TX and different users.\n\nDisadvantages of FDD:\n\nDuplexers are costly components with significant insertion loss depending on filtering requirements.\nRequires two separate frequency bands, which can be a limitation in terms of spectrum availability, and MIMO channel estimation.\nThe strong TX causes severe desensitization of the RX, which requires high linearity and good filtering (50 dB to 60 dB).\n\n\n\n3.5.2 Time-Division Duplex (TDD)\nIn TDD, the RX and TX share the same frequency band but operate at different times. This allows for more efficient use of the available spectrum, as the same frequency can be used for both transmission and reception. TDD is particularly well-suited for applications with asymmetric traffic patterns, where the data rate in one direction is significantly higher than in the other. However, TDD requires precise timing control to avoid interference between RX and TX periods, which can increase complexity. In TDD, a single PLL can be used to generate the LO frequency for both RX and TX, which reduces complexity and power consumption. The RF RX and TX paths are connected to the antenna via a switch, which alternates between connecting the antenna to the RX path and the TX path. A typical TDD TRX block diagram is shown in Figure 22.\n\n\n\n\n\n\n\n\nFigure 22: Block diagram of a TDD RF front-end.\n\n\n\n\n\nAdvantages of TDD:\n\nMore efficient use of the available spectrum, as the same frequency can be used for both RX and TX.\nA single PLL can be used for both RX and TX, which reduces complexity and power consumption.\nNo duplexer is required (just a single band filter), which reduces cost and insertion loss.\nNo RX blocking by own TX, which relaxes linearity and filtering requirements.\nEasier to implement MIMO, as all antennas can operate in the same frequency band.\n\nDisadvantages of TDD:\n\nRX and TX cannot operate simultaneously, which can be a limitation for low-latency applications.\nRequires precise timing control to avoid interference between RX and TX periods, which can increase complexity.\nSynchronization between RX and TX and different users is required, which can be challenging in some scenarios.\n\n\n\n3.5.3 Comparison of FDD and TDD\nBelow is a summary of important wireless standards and their duplexing method as shown in Table 4:\n\n\n\nTable 4: Comparison of duplexing methods used by major wireless standards\n\n\n\n\n\n\n\n\n\n\nWireless Standard\nDuplexing Method\nComments\n\n\n\n\nGSM (2G)\nFDD & TDMA\nTX and RX operate at different frequencies (FDD) and different times (TDMA)\n\n\nUMTS (3G)\nFDD\nTraditional cellular standard using paired spectrum\n\n\nLTE (4G)\nFDD/TDD\nFDD is used mostly &lt;2.7 GHz, TDD is used &gt;2.3 GHz\n\n\n5G NR\nFDD/TDD\nFDD is used mostly &lt;2.7 GHz, TDD is used &gt;2.3 GHz\n\n\nWiFi (802.11)\nTDD\nUnlicensed spectrum operation\n\n\nBluetooth\nTDD\nShort-range personal area network\n\n\nZigbee\nTDD\nLow-power IoT applications\n\n\n\n\n\n\nAs you can see in Table 4, there is a tendency to use FDD for lower frequencies and long communication distances, while TDD is preferred for higher frequencies and shorter distances."
  },
  {
    "objectID": "rfic.html#specialty-architectures",
    "href": "rfic.html#specialty-architectures",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.6 Specialty Architectures",
    "text": "3.6 Specialty Architectures\nIn some cases, other architectures may be preferred over the direct-conversion architecture. During the evolution of wireless communication, many different architectures have been proposed and used. However, only a few of them are still relevant today. Some examples are shown next.\n\n3.6.1 Super-Heterodyne Architecture\nThe super-heterodyne architecture is a widely used approach in radio. It works by mixing the incoming/outgoing RF signal with an LO to produce an intermediate frequency (IF) signal. This IF signal is then amplified and processed, allowing for better selectivity and sensitivity compared to direct-conversion architectures. Super-heterodyne receivers/transmitters are known for their excellent performance in terms of image rejection and dynamic range, making them suitable for a variety of applications, including traditional analog TV and radio broadcasting. A simplified block diagram of a super-heterodyne transceiver is shown in Figure 23.\n\n\n\n\n\n\n\n\nFigure 23: Block diagram of a super-heterodyne transceiver (TRX) showing the main functional blocks of RX and TX.\n\n\n\n\n\nWhen you compare Figure 17 with Figure 23, you can immediately appreciate the increased complexity of the super-heterodyne architecture. It requires two PLLs to generate the RX and TX LO frequencies, as well as additional mixers and filters for the IF stage. This increases cost, power consumption, and size. However, the super-heterodyne architecture can provide better performance in terms of selectivity and sensitivity, especially in challenging RF environments with strong blockers, as it allows filtering at RF, IF, and baseband frequencies.\nOne important aspect of super-heterodyne receivers is the choice of the intermediate frequency (IF). The IF should be high enough to allow for effective filtering and image rejection, but low enough to avoid excessive complexity and power consumption. Common IF frequencies range from a few MHz to several hundred MHz, depending on the application and frequency band.\nAn important issue in super-heterodyne receivers is the image frequency. The image frequency is a spurious frequency that can interfere with the desired signal, and is located at \\(f_\\mathrm{image} = f_\\mathrm{RF} \\pm 2 f_\\mathrm{IF}\\) (the sign depends on the choice of high-side or low-side mixing). To suppress the image frequency, an image-reject filter is either placed before (RX) or after (TX) the mixer. The design of this filter is critical, as it must provide sufficient attenuation of the image frequency while maintaining low insertion loss for the desired signal.\nAn alternative to image filtering is the use of active image rejection techniques, such as the Hartley or Weaver architectures. These techniques use additional mixers and phase shifters to cancel out the image frequency, allowing for improved performance without the need for a dedicated image-reject filter.\n\n\n3.6.2 Low-IF Architecture\nTo avoid some of the issues of direct-conversion architectures (like dc offsets and flicker noise), a low-IF architecture can be used. In a low-IF architecture, the RX and TX signals are mixed to a low intermediate frequency (typically a few MHz to tens of MHz) instead of directly to baseband. This allows for easier filtering of DC offsets and flicker noise, while still maintaining the benefits of a single LO and reduced complexity compared to super-heterodyne architectures. A low-IF architecture is shown in Figure 24.\n\n\n\n\n\n\n\n\nFigure 24: Block diagram of a low-IF transceiver (TRX) showing the main functional blocks of RX and TX. Note the usage of complex analog and digital baseband filters. Otherwise, the structure is similar to a zero-IF TRX as shown in Figure 17.\n\n\n\n\n\nThe low-IF architecture is the de facto standard for Bluetooth receivers. Its advantage compared to direct-conversion vanishes for larger channel bandwidths, which is why it is not used for cellular or WiFi (GSM receivers might be an exception).\nOne noteworthy disadvantage of low-IF architectures is the required 2xBW compared to direct-conversion. This might cause increased power consumption in the analog baseband filters and ADCs/DACs. Additionally, the low-IF architecture still requires careful design to mitigate issues like IQ imbalance and LO leakage, although these issues are generally less severe than in direct-conversion architectures.\n\n\n3.6.3 Super Simple Architecture\nFor some applications with very low cost and low performance requirements, a super simple architecture can be used (think garage door opener). In this architecture, the RX and TX paths are stripped down to the bare minimum. A super simple receiver just uses a bandpass filter and an envelope detector, while a super simple transmitter uses an oscillator and power amplifier. These simplified architectures are shown in Figure 25.\n\n\n\n\n\n\n\n\nFigure 25: Block diagram of a super simple TX and RX.\n\n\n\n\n\nDespite the simple architecture, digital amplitude-shift-keying (ASK) or on-off-keying (OOK) can be used. If the receiver is able to discriminate between frequencies (e.g., by using two RF filters with an envelope detector each), also frequency-shift-keying (FSK) can be used."
  },
  {
    "objectID": "rfic.html#iq-imbalance",
    "href": "rfic.html#iq-imbalance",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "3.7 I/Q Imbalance",
    "text": "3.7 I/Q Imbalance\nIn direct-conversion and low-IF architectures, the I and Q paths are used to process the in-phase and quadrature components of the signal. Ideally, these paths should have identical gain and a 90° phase difference. However, in practice, there are always some mismatches between the I and Q paths, leading to I/Q imbalance. This imbalance can cause constellation distortion, leading to increased error vector magnitude (EVM) and degraded system performance.\nI/Q imbalance can be characterized by two parameters: gain mismatch (\\(\\Delta G\\)) and phase mismatch (\\(\\Delta \\varphi\\)). Gain mismatch refers to the difference in gain between the I and Q paths, while phase mismatch refers to the deviation from the ideal 90° phase difference. The impact of I/Q imbalance on system performance depends on the modulation scheme used, with higher-order modulations being more sensitive to these impairments.\nThere are two ways to quantify I/Q imbalance:\n\nImage rejection ratio (IRR): The IRR is a measure of how well the receiver can reject the image frequency caused by I/Q imbalance. It is defined as the ratio of the power of the desired signal to the power of the image (unwanted) signal, typically expressed in dB. A higher IRR indicates better performance, with values above 30 dB to 40 dB generally considered acceptable for most applications.\nError vector magnitude (EVM): The EVM is a measure of the difference between the ideal transmitted signal and the received signal, expressed as a percentage of the signal’s magnitude. It quantifies the overall distortion in the received signal, including the effects of I/Q imbalance. Lower EVM values indicate better performance, with typical requirements ranging from 1% to 10% depending on the modulation scheme and application.\n\nThe EVM (in rms) is defined as\n\\[\n\\text{EVM} = \\frac{\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} |s_\\mathrm{ideal}(i) - s_\\mathrm{meas}(i)|^2}}{\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} |s_\\mathrm{ideal}(i)|^2}}\n\\tag{23}\\]\nwhere \\(s_\\mathrm{ideal}(i)\\) is the ideal transmitted symbol, \\(s_\\mathrm{meas}(i)\\) is the measured received symbol, and \\(N\\) is the number of symbols. EVM is expressed either in percent or in dB using\n\\[\n\\text{EVM}|_\\mathrm{dB} = 20 \\cdot \\log_{10}(\\text{EVM}).\n\\]\nIn order to make the I/Q mismatch sufficiently small, among the possible techniques are:\n\nCareful layout and matching of the components in the I and Q paths to minimize gain and phase mismatches. This usually involves good layout techniques. Further, the LO I/Q generation should be done with high accuracy.\nCalibration techniques can be used to measure and compensate for I/Q imbalance. This can be done either in the analog domain (e.g., using variable gain amplifiers and phase shifters) or in the digital domain (e.g., using digital signal processing algorithms). Digital compensation is usually preferred, as it is more flexible and can adapt to changing conditions. A CORDIC can be readily used for this purpose."
  },
  {
    "objectID": "rfic.html#sec-lna-resistive-matching",
    "href": "rfic.html#sec-lna-resistive-matching",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "4.1 Resistively Matched Common-Source LNA",
    "text": "4.1 Resistively Matched Common-Source LNA\nThe key question is now how to design an LNA with low noise figure and an input impedance matched to 50 Ω? In order to appreciate this design challenge, we will first try a naive approach, using a common-source amplifier with resistive termination, as shown in Figure 28.\n\n\n\n\n\n\n\n\nFigure 28: A simple LNA with resistive input matching and a tank circuit as a load (biasing details are omitted). The LNA is driven by a 50 Ω source.\n\n\n\n\n\nIf we assume the gate capacitance of \\(M_1\\) is negligible, we can achieve good input impedance matching by choosing \\(R_\\mathrm{s} = R_\\mathrm{p} = 50\\,\\Omega\\). The voltage gain of this simple common-source LNA is given by \\(A_\\mathrm{v} = -g_\\mathrm{m}R_\\mathrm{D}\\), neglecting capacitances and \\(g_\\mathrm{ds}\\) of \\(M_1\\) (we assume that the load tank is tuned to the desired frequency with \\(\\omega_0 = 1 / \\sqrt{L C}\\)).\nHow can we calculate the noise figure of this simple LNA? We formulate\n\\[\nF = \\frac{\\text{total noise at output}}{\\text{noise at output due to source only}}.\n\\tag{24}\\]\nWe derive a small-signal equivalent circuit of Figure 28, which is shown in Figure 29, to calculate the total noise at the output of the LNA.\n\n\n\n\n\n\n\n\nFigure 29: Equivalent circuit of resistively matched common-source LNA.\n\n\n\n\n\nWith the help of Figure 29, we can calculate the total output noise power spectral density as\n\\[\n\\overline{V_\\mathrm{n,out,1}^2} = A_\\mathrm{v}^2 \\cdot 4 k T (R_\\mathrm{s} \\parallel R_\\mathrm{p}) = (g_\\mathrm{m}R_\\mathrm{D})^2 \\cdot 4 k T (R_\\mathrm{s} \\parallel R_\\mathrm{p})\n\\]\nand\n\\[\n\\overline{I_\\mathrm{n,out}^2} = 4 k T \\gamma g_\\mathrm{m}+ \\frac{4 k T}{R_\\mathrm{D}}\n\\] \\[\n\\overline{V_\\mathrm{n,out,2}^2} = R_\\mathrm{D}^2 \\cdot \\overline{I_\\mathrm{n,out}^2} = 4 k T \\gamma g_\\mathrm{m}R_\\mathrm{D}^2 + 4 k T R_\\mathrm{D}\n\\]\nso that in total\n\\[\n\\overline{V_\\mathrm{n,out}^2} = \\overline{V_\\mathrm{n,out,1}^2} + \\overline{V_\\mathrm{n,out,2}^2} = 4 k T \\left[ (g_\\mathrm{m}R_\\mathrm{D})^2 (R_\\mathrm{s} \\parallel R_\\mathrm{p}) + \\gamma g_\\mathrm{m}R_\\mathrm{D}^2 + R_\\mathrm{D} \\right].\n\\tag{25}\\]\nWe now need to find the output noise coming from the source only. For this we can use the equivalent circuit in Figure 30, to formulate the output noise due to the source only.\n\n\n\n\n\n\n\n\nFigure 30: Eqivalent circuit to calculate the output noise from the input.\n\n\n\n\n\nWe find that\n\\[\n\\overline{V_\\mathrm{n,out,s}^2} = A_\\mathrm{v}^2 \\cdot 4 k T R_\\mathrm{s} \\cdot \\left(\\frac{R_\\mathrm{p}}{R_\\mathrm{s} + R_\\mathrm{p}}{} \\right)^2.\n\\tag{26}\\]\nFinally, we can use Equation 25 and Equation 26 with Equation 24 to calculate the noise figure of the simple resistively matched common-source LNA as\n\\[\nF = \\frac{\\overline{V_\\mathrm{n,out}^2}}{\\overline{V_\\mathrm{n,out,s}^2}} = 1 + \\frac{R_\\mathrm{s}}{R_\\mathrm{p}} + \\frac{\\gamma R_\\mathrm{s}}{g_\\mathrm{m}(R_\\mathrm{s} \\parallel R_\\mathrm{p})^2} + \\frac{R_\\mathrm{s}}{g_\\mathrm{m}^2 (R_\\mathrm{s} \\parallel R_\\mathrm{p})^2 R_\\mathrm{D}}.\n\\tag{27}\\]\n\n\n\n\n\n\nNoteCommon-source LNA with Resistive Matching\n\n\n\nAs an exercise to calculate circuits with noise, re-confirm and derive yourself the result of Equation 27.\n\n\nHow can we interpret Equation 27? We see that we can minimize the noise factor by making \\(g_\\mathrm{m}\\) large. Then we have a noise factor of\n\\[\nF = 1 + \\frac{R_\\mathrm{s}}{R_\\mathrm{p}} = 2\n\\]\nso we see that we are limited to a minimum noise figure of 3 dB, even if we spend the bias current to make \\(g_\\mathrm{m}\\) very large. We can go below 3 dB noise figure only if we choose \\(R_\\mathrm{p} &gt; R_\\mathrm{s}\\), however, this means that the input is no longer matched to 50 Ω, which is usually not acceptable. Hence, this simple resistively matched common-source LNA is not a good choice for a low-noise amplifier, with one exception: For very wideband amplifiers, where a NF of larger than 3 dB is acceptable, this configuration might be a good choice.\nWe see that we are stuck at high noise figures if we realize the real part of the input impedance with a resistor. This leaves us with the question of how to realize a real part of the input impedance then. We will answer this question in the next section."
  },
  {
    "objectID": "rfic.html#sec-lna-common-gate",
    "href": "rfic.html#sec-lna-common-gate",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "4.2 Common-Gate LNA",
    "text": "4.2 Common-Gate LNA\nWe remember from our analog circuit design lecture that the common-gate configuration has an input impedance of \\(1/g_\\mathrm{m}\\), neglecting parasitic capacitances. Hence, if we choose \\(g_\\mathrm{m}= 1/50\\,\\Omega = 20\\,\\text{mS}\\), we can achieve input matching to 50 Ω without using a resistor at the input. This is the key idea of the common-gate LNA, which is shown in Figure 31.\n\n\n\n\n\n\n\n\nFigure 31: Circuit diagram of a common-gate LNA.\n\n\n\n\n\nBy inspecting Figure 31 and following the practice from Section 4.1, we can directly write down the output noise voltage as (with \\(1/g_\\mathrm{m}= R_\\mathrm{s}\\))\n\\[\n\\overline{V_\\mathrm{n,out}^2} = k T \\left[ (g_\\mathrm{m}R_\\mathrm{D})^2 R_\\mathrm{s} + \\gamma g_\\mathrm{m}R_\\mathrm{D}^2 + 4 R_\\mathrm{D} \\right] = k T \\left( \\frac{R_\\mathrm{D}^2}{R_\\mathrm{s}} + \\gamma \\frac{R_\\mathrm{D}^2}{R_\\mathrm{s}} + 4 R_\\mathrm{D} \\right).\n\\tag{28}\\]\nThe output noise due to the source only is given by\n\\[\n\\overline{V_\\mathrm{n,out,s}^2} = \\frac{R_\\mathrm{D}^2}{R_\\mathrm{s}}.\n\\tag{29}\\]\nFinally, we can use Equation 28 and Equation 29 with Equation 24 to calculate the noise figure of the common-gate LNA as\n\\[\nF = 1 + \\gamma + \\frac{4 R_\\mathrm{s}}{R_\\mathrm{D}}  \\xrightarrow{R_\\mathrm{D} \\gg R_\\mathrm{s}} F = 1 + \\gamma .\n\\tag{30}\\]\nWith a classical long-channel \\(\\gamma = 2/3\\), we can achieve a minimum noise figure of 2.2 dB, which is already better than the resistively matched common-source LNA. However, with modern short-channel devices, \\(\\gamma\\) is often larger than 1, so that the minimum noise figure of the common-gate LNA is often larger than 3 dB (Razavi 2011)."
  },
  {
    "objectID": "rfic.html#sec-lna-inductive-degeneration",
    "href": "rfic.html#sec-lna-inductive-degeneration",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "4.3 Inductively-Degenerated Common-Source LNA",
    "text": "4.3 Inductively-Degenerated Common-Source LNA\nAs we have seen in Section 4.2, using circuit techniques can realize a real part of an input impedance without the associated thermal noise of a resistor. We now try something different, in the hope that it will result in an even lower noise figure. We construct an LNA based on a common-source MOSFET amplifier, but we add an impedance \\(Z_\\mathrm{deg}\\) into the source line. This arrangement is shown in Figure 32.\n\n\n\n\n\n\n\n\nFigure 32: A common-source MOSFET stage with degeneration impedance.\n\n\n\n\n\nWe now extract the small-signal equivalent circuit of Figure 32, which is shown in Figure 33, to calculate the input impedance.\n\n\n\n\n\n\n\n\nFigure 33: Equivalent small-signal circuit of the input stage around \\(M_1\\).\n\n\n\n\n\nWe find that\n\\[\nv_\\mathrm{x} = v_\\mathrm{gs} + Z_\\mathrm{deg} (i_\\mathrm{x} + g_\\mathrm{m}v_\\mathrm{gs}), \\quad v_\\mathrm{gs} = \\frac{i_\\mathrm{x}}{s C_\\mathrm{gs}}\n\\]\nso that we can write the input impedance as\n\\[\nZ_\\mathrm{in} = \\frac{v_\\mathrm{x}}{i_\\mathrm{x}} = \\frac{1}{s C_\\mathrm{gs}} + Z_\\mathrm{deg} + \\frac{g_\\mathrm{m}Z_\\mathrm{deg}}{s C_\\mathrm{gs}}.\n\\tag{31}\\]\nThe final term in Equation 31 is the interesting one: By choosing \\(Z_\\mathrm{deg}\\) to be inductive (which we can do by either use an on-chip or off-chip inductor), we can realize a real part of the input impedance. If we choose \\(Z_\\mathrm{deg} = s L\\), we find that\n\\[\nZ_\\mathrm{in} = \\frac{1}{s C_\\mathrm{gs}} + s L + \\frac{g_\\mathrm{m}L}{C_\\mathrm{gs}}.\n\\]\nBy proper choice of \\(L\\) and \\(C_\\mathrm{gs}\\), we can achieve input matching to 50 Ω at the desired frequency \\(\\omega_0\\). We find that the real part of the input impedance is given by\n\\[\n\\Re \\{ Z_\\mathrm{in} \\} = \\frac{g_\\mathrm{m}L}{C_\\mathrm{gs}}\n\\]\nWithout proof (refer to (Razavi 2011) or (Darabi 2020) for a derivation) we find for the noise factor of this input stage (with some simplification) as\n\\[\nF = 1 + \\frac{\\gamma R_\\mathrm{s} \\omega_0^2 C_\\mathrm{gs}^2}{g_\\mathrm{m}}.\n\\tag{32}\\]\nFinally, we have an LNA input stage configuration that allows us to achieve a noise figure below 3 dB, even with \\(\\gamma &gt; 1\\), by proper choice of \\(g_\\mathrm{m}\\). Making \\(g_\\mathrm{m}\\) large (by spending more bias current) results in (to first order) arbitrarily low noise figure. The inductively-degenerated common-source LNA is a widely used LNA input stage configuration in modern RFICs. A somewhat detailed schematic is shown in Figure 34.\n\n\n\n\n\n\n\n\nFigure 34: An (almost complete) common-source MOSFET stage with degeneration impedance and cascode.\n\n\n\n\n\nThe inductor \\(L_\\mathrm{match}\\) is used to match the input impedance to 50 Ω at the desired frequency, \\(L_\\mathrm{deg}\\) is used to realize the real part of the input impedance, \\(R_\\mathrm{bias}\\) is used to set the bias current of \\(M_1\\), \\(M_2\\) is a cascode transistor which increases the output impedance and thus the gain of the stage (plus it improves the reverse isolation), and \\(R_\\mathrm{D}\\), \\(L_\\mathrm{D}\\), and \\(C_\\mathrm{D}\\) form a load tank which provides high gain at the desired frequency. A dc block is used at the input so that the bias point of \\(M_1\\) is not corrupted by the input signal source. The bias voltage \\(V_\\mathrm{bias2}\\) sets the operating point of the cascode transistor \\(M_2\\).\nWhat is missing in Figure 34 is any form of frequency tuning of the load to the frequency of interest, and the support of different gain modes. Apart from these details this LNA circuit is a good starting point for a practical LNA design."
  },
  {
    "objectID": "rfic.html#sec-lna-feedback",
    "href": "rfic.html#sec-lna-feedback",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "4.4 Feedback LNA",
    "text": "4.4 Feedback LNA\nOne drawback of the inductively-degenerated common-source LNA is the usage of at least one inductor. If the inductor is placed on-chip, it has a comparatively large size, and if it is implemented in the package (via a bondwire) or on the PCB, it adds to the bill-of-materials (BOM) cost.\nIf the CMOS technology is sufficiently fast, a shunt feedback LNA, as shown in Figure 35, might be a good choice.\n\n\n\n\n\n\n\n\nFigure 35: A shunt-feedback LNA.\n\n\n\n\n\nWithout proof, the input impedance of the shunt feedback LNA is given by\n\\[\nZ_\\mathrm{in} = \\frac{Z_\\mathrm{F} + Z_\\mathrm{L}}{1 + g_\\mathrm{m}Z_\\mathrm{L}}.\n\\tag{33}\\]\nThe noise factor of the shunt feedback LNA is given by\n\\[\nF = 1 + \\left| \\frac{Z_\\mathrm{F} + R_\\mathrm{s}}{g_\\mathrm{m}Z_\\mathrm{F} + 1} \\right|^2 \\cdot \\frac{\\gamma g_\\mathrm{m}+ \\Re \\{ Y_\\mathrm{L} \\} }{\\Re \\{ Z_\\mathrm{in} \\}}\n\\tag{34}\\]\nAs you can see from Equation 34, by making \\(g_\\mathrm{m}\\) large (by spending more bias current) the noise figure can be made arbitrarily small! Depending on the choice of \\(Z_\\mathrm{F}\\) and \\(Z_\\mathrm{L}\\), the input impedance of this LNA can be changed in interesting ways.\nBy setting \\(Z_\\mathrm{L} \\rightarrow \\infty\\) (e.g., by biasing with a current source and high-impedance loading), we find that\n\\[\nZ_\\mathrm{in} = \\frac{1}{g_\\mathrm{m}}\n\\]\nwhich is independent of \\(Z_\\mathrm{F}\\) and is a well-known result for a common-source stage. The disadvantage of this configuration is the noise factor, which (given that \\(Z_\\mathrm{F}\\) is sufficiently large) tends to \\(F = 1 + \\gamma\\), which is the same as for the common-gate LNA.\nA bit more interesting is the case when \\(g_\\mathrm{m}Z_\\mathrm{L} = A_0\\) and \\(Z_\\mathrm{L} \\gg Z_\\mathrm{F}\\), which results in\n\\[\nZ_\\mathrm{in} = \\frac{Z_\\mathrm{L}}{1 + A_0}\n\\]\nwhich is the well-known result that the input impedance of an amplifier with feedback is reduced by the factor \\(1 + A_0\\), where \\(A_0\\) is the open-loop gain of the amplifier. The noise factor can be made small by making \\(g_\\mathrm{m}\\) large, as we have already noted above.\nA very interesting case can be achieved by choosing \\(Z_\\mathrm{L} = 1 / s C_\\mathrm{L}\\) and \\(Z_\\mathrm{F} = 1 / s C_\\mathrm{F}\\), which results in\n\\[\nY_\\mathrm{in} = \\frac{1}{Z_\\mathrm{in}} = \\frac{g_\\mathrm{m}C_\\mathrm{F}}{C_\\mathrm{L} + C_\\mathrm{F}} + s \\frac{C_\\mathrm{L} C_\\mathrm{F}}{C_\\mathrm{L} + C_\\mathrm{F}}\n\\tag{35}\\]\nLooking at Equation 35, we see that the input admittance has a real part! By proper choice of components, we can achieve an input impedance matched to 50 Ω at the desired frequency. The noise factor can again be made small by making \\(g_\\mathrm{m}\\) large.\nThere is also an option, by proper choice of \\(Z_\\mathrm{F}\\) and \\(Z_\\mathrm{L}\\), to achieve an inductive input impedance component, which can be used to resonate out the input capacitance of the LNA, similar to the inductively-degenerated common-source LNA. However, in contrast to the inductively-degenerated common-source LNA, no inductor is required in this case. This configuration is called a reactance-canceling LNA."
  },
  {
    "objectID": "rfic.html#sec-mixer-nonlinear",
    "href": "rfic.html#sec-mixer-nonlinear",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "5.1 Non-Linear Mixer",
    "text": "5.1 Non-Linear Mixer\nGenerally speaking, we can use any non-linear device to implement a mixer (often, this generation of new frequency components in a nonlinear system is highly undesired; in a mixer, we want this effect). As a simple example we look at the case of a square function, shown in Figure 36.\n\n\n\n\n\n\n\n\nFigure 37: Mixer block diagram.\n\n\n\n\n\nWhen we apply the sum of the signals \\(s_\\mathrm{in}(t) = \\cos( \\omega_\\mathrm{in} t)\\) and \\(s_\\mathrm{LO}(t) = \\cos(\\omega_\\mathrm{LO} t)\\) to the input of a squarer, we get the output signal\n\\[\n\\begin{split}\ns_\\mathrm{out}(t) = [ s_\\mathrm{in}(t) + s_\\mathrm{LO}(t) ]^2 &= \\cos(\\omega_\\mathrm{in} t + \\omega_\\mathrm{LO} t) + \\cos(\\omega_\\mathrm{in} t - \\omega_\\mathrm{LO} t) \\\\\n&+ 1 + \\frac{1}{2} \\cos(2 \\omega_\\mathrm{in} t) + \\frac{1}{2} \\cos(2 \\omega_\\mathrm{LO} t).\n\\end{split}\n\\tag{36}\\]\nWe see that the output signal contains the desired frequency components at \\(\\omega_\\mathrm{in} \\pm \\omega_\\mathrm{LO}\\), but also additional components at dc (0 Hz), \\(2 \\omega_\\mathrm{in}\\), and \\(2 \\omega_\\mathrm{LO}\\). These additional components are usually unwanted and have to be filtered out in a subsequent filtering stage. As a side-note, in some circuits a frequency doubler is desired, which can be implemented by simply filtering out the other frequency components. In a doubler no LO signal is required, as the input signal is simply squared.\nA simple example circuit is a diode, which has a non-linear current-voltage characteristic. The block diagram of a simple diode mixer is shown in Figure 38.\n\n\n\n\n\n\n\n\nFigure 38: A diode mixer.\n\n\n\n\n\nThis structure is conceptionally simple, it just requires a (fast) diode, filters to couple the desired frequency components in and out, and an RF choke to provide a dc bias voltage for the diode. However, the performance of such a simple mixer is usually not very good, as the diode is a highly non-linear device, which generates many spurious frequency components. More advanced mixer circuits use more complex non-linear devices (for example, a ring of diodes) to improve the performance. The advantage of these mixers is that they can operate up to very high frequencies (in the mm-wave range and beyond). If you can make a nonlinear device, you can make a mixer (think also of nonlinear optics, for example)."
  },
  {
    "objectID": "rfic.html#sec-mixer-time-variant",
    "href": "rfic.html#sec-mixer-time-variant",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "5.2 Time-Variant Mixer",
    "text": "5.2 Time-Variant Mixer\nIn contrast to the non-linear mixer, a time-variant mixer uses an ideally linear device, but changes its properties over time. A simple example is a switch, which is opened and closed at the LO frequency. The block diagram of such a mixer is shown in Figure 39. This system is ideally linear from input to output, but very nonlinear when considering the LO input.\n\n\n\n\n\n\n\n\nFigure 39: A switch as a time-variant mixer.\n\n\n\n\n\nWhen the switch is closed (\\(s_\\mathrm{LO} \\ge 0\\)), the input signal is passed to the output, i.e., \\(s_\\mathrm{out}(t) = s_\\mathrm{in}(t)\\); when the switch is open (\\(s_\\mathrm{LO} &lt; 0\\)), no signal is passed, i.e., \\(s_\\mathrm{out}(t) = 0\\). The output signal can be expressed as\n\\[\ns_\\mathrm{out}(t) = s_\\mathrm{in}(t) \\cdot \\frac{1}{2} \\left\\{ 1 + \\mathrm{sgn}[ s_\\mathrm{LO}(t) ] \\right\\},\n\\]\nwhere \\(\\mathrm{sgn}(\\cdot)\\) is the sign function. The term in curly brackets is a square wave that switches between 0 and 1 at the LO frequency. This square wave can be expressed as a Fourier series, which contains the fundamental frequency at \\(\\omega_\\mathrm{LO}\\) and all odd harmonics \\(3 \\omega_\\mathrm{LO}\\), \\(5 \\omega_\\mathrm{LO}\\), and so on. In conclusion, if the input signal is expressed as \\(\\cos(\\omega_\\mathrm{in} t)\\), we get the output signal\n\\[\ns_\\mathrm{out}(t) = \\frac{1}{\\pi} \\cos(\\omega_\\mathrm{in} t \\pm \\omega_\\mathrm{LO} t) + \\ldots\n\\tag{37}\\]\nAgain, we see that the output signal contains the desired frequency components at \\(\\omega_\\mathrm{in} \\pm \\omega_\\mathrm{LO}\\), but also additional components at \\(3 \\omega_\\mathrm{LO}\\), \\(5 \\omega_\\mathrm{LO}\\), and so on. These additional components are usually unwanted and have to be filtered out in a subsequent filtering stage. The advantage of a time-variant mixer is that it can be implemented readily in CMOS, as shown in Figure 40.\n\n\n\n\n\n\n\n\nFigure 40: A MOSFET as a switch used as a mixer, with ac-coupled LO signal.\n\n\n\n\n\nThe implementation in Figure 40 uses a single NMOS transistor as a switch. The LO signal is ac-coupled to the gate of the transistor, so that the dc operating point is set by the bias voltage \\(V_\\mathrm{bias}\\). When the LO signal is high enough, the transistor is switched on and the input signal \\(v_\\mathrm{in}(t)\\) is passed to the output; when the LO signal is low, the transistor is switched off and no signal is passed. Note that with the MOSFET we can switch voltages as well as currents, so the mixer can work in both modes, voltage mode or current mode.\nA big disadvantage of this simple implementation is that the input signal is “lost” for half of the cycle when the MOSFET switch is open. A fully differential implementation (having differential ports at input, output and LO input) can alleviate this problem, as the input signal is always connected to one of the two output ports. This configuration is called a “double-balanced mixer” and is widely used in practice. It is shown in Figure 41.\n\n\n\n\n\n\n\n\nFigure 41: A fully-differential double-balanced MOSFET mixer.\n\n\n\n\n\nNote that with a double-balanced mixer, we have 6 dB more conversion gain compared to the single-balanced mixer (refer to Equation 37), as can be seen in Equation 38. Note that the factor of \\(2/\\pi\\) represents the conversion loss of an ideal double-balanced mixer of 3.9 dB.\n\\[\ns_\\mathrm{out}(t) = \\frac{2}{\\pi} \\cos(\\omega_\\mathrm{in} t \\pm \\omega_\\mathrm{LO} t) + \\ldots\n\\tag{38}\\]\nNote that no dc current needs to flow through the mixer structures shown in Figure 40 and Figure 41, which is a huge advantage when thinking of flicker noise. Flicker noise in a MOSFET is proportional to the dc current flowing through the device, so if no dc current flows, no flicker noise is generated!\nIn order to look at the full picture, we embed the mixer of Figure 41 in a complete RX front-end, as shown in Figure 42. An LNA (essentially a \\(g_\\mathrm{m}\\) cell) creates a current signal from the received voltage signal at the antenna. This current signal is then fed to the mixer in the current domain, and further sinked into a transimpedance amplifier (TIA), which also implements a lowpass pole. The simplified circuit is shown in Figure 42.\n\n\n\n\n\n\n\n\nFigure 42: An RX front-end using a current-mode (passive) mixer.\n\n\n\n\n\nThe capacitors connected directly to ground at the mixer outputs are good practice, as they shunt high-frequency switching noise to ground, and in this way help the performance of the TIA, which otherwise would have to sink these currents. Note that all blocker currents originating at the LNA output and passing through the mixer are shunt by the feedback capacitors to the output of the TIA, and need to be actively driven by the TIA’s output stage!"
  },
  {
    "objectID": "rfic.html#sec-mixer-gilbert",
    "href": "rfic.html#sec-mixer-gilbert",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "5.3 Gilbert Cell Mixer",
    "text": "5.3 Gilbert Cell Mixer\nAs we have seen in Section 5.2, in CMOS we have quite a few options to implement a mixer as the MOSFET is a good current and voltage switch. This is in stark contrast to the BJT, as the bipolar transistor can only be used as an (excellent) current switch in the differential pair configuration. Hence, we need to implement a current-mode mixer in bipolar technology. The most widely used structure is the so-called “Gilbert cell”, shown in Figure 43.\n\n\n\n\n\n\n\n\nFigure 43: A Gilbert mixer based on bipolar differential pairs.\n\n\n\n\n\nThe idea is that an input transconductor creates currents, which are switched in the double differential pair, and converts the mixed currents back to voltage in the load impedances. There are many known variations of this circuit, like skipping the current source at the bottom to increase linearity and headroom, or swap the input transconductor for another structure. It might also be useful to “bleed” some bias current from the LO switching stage to improve noise."
  },
  {
    "objectID": "rfic.html#sec-mixer-npath",
    "href": "rfic.html#sec-mixer-npath",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "5.4 N-Path Filter",
    "text": "5.4 N-Path Filter\nWithout much deliberation or diving into the background, it has to be stated that passive mixers (based on MOSFET switches) have a few very interesting properties. One of them is that they can be used to implement very high-quality bandpass filters, called “N-path filters” (Lepage, Cahn, and Brown 1953). The basic idea is shown in Figure 44. We use 4 phases of an LO signal to switch the 4 capacitors to ground in a round-robin fashion. The duty cycle of each LO phase is 25% to have a non-overlapping clock.\n\n\n\n\n\n\n\n\nFigure 44: A 4-phase N-path filter.\n\n\n\n\n\nThe key observation to make is that a switch that is opened and closed at a certain frequency (the LO frequency) can be seen as a time-variant resistor. This time-variant resistor converts impedance seen at one one to the other end, and also changes the frequency of this apparent impedance. In other words, if we connect grounded capacitors at one end of the mixer switches and look into the other end, we see a bandpass filter centered at the LO frequency! In this way we can build bandpass filters (and also bandstop filters (Vazny et al. 2010)) at very high frequencies which are precisely centered (without component variations) around \\(\\omega_\\mathrm{LO}\\).\nThe impedance characteristics of such a tank circuit exhibit first-order bandpass behavior, as shown in Figure 45. The peak impedance reaches 5.3 times the switch resistance (\\(R_\\mathrm{sw}\\)), and importantly, the bandwidth is inversely proportional to the capacitance value, i.e., \\(\\mathrm{BW} \\propto 1/C\\). This relationship allows for precise control of the filter bandwidth by adjusting the capacitor values.\n\n\n\n\n\n\n\n\nFigure 45: First-order bandpass behavior and impedance of an N-path filter."
  },
  {
    "objectID": "rfic.html#sec-mixer-lo",
    "href": "rfic.html#sec-mixer-lo",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "5.5 LO Generation",
    "text": "5.5 LO Generation\nAs you have seen in Section 3.2, for complex-valued modulation schemes (like QPSK, QAM, OFDM, and so on) we need to generate quadrature LO signals (i.e., two LO signals with a 90° phase shift). There are many ways to generate such signals, and we will now study a few of them.\n\n5.5.1 RC/CR Phase Shift Network\nThe probably simplest way to generate quadrature LO signals is to use a simple RC/CR phase shift network, as shown in Figure 46. The RC network (a first-order lowpass) generates a phase shift between 0° and -90°, while the CR network (a first-order highpass) generates a phase shift between 0° and +90°. By operating the network at \\(\\omega_0 = 1/RC\\), we can achieve a 90° phase shift between the two outputs.\n\n\n\n\n\n\n\n\nFigure 46: An RC/CR IQ generation network.\n\n\n\n\n\nThe advantage of this network is its simplicity, as it only requires a few passive components, and it can generate I and Q phases from an incoming signal at the target frequency. The disadvantage is that the phase shift is frequency-dependent, so the quadrature signals are only perfectly in phase at one frequency. Furthermore, the amplitude of the two outputs is not equal, which might require additional gain stages to equalize the amplitudes. Additionally, this passive network has a 3 dB loss, so we need additional gain stages to compensate for this loss.\n\n\n5.5.2 Polyphase Filter\nWe can create a more advanced phase shift network (following the idea of Section 5.5.1) by using a so-called “polyphase filter” (Kaukovuori et al. 2008). The idea is to use multiple RC sections to create a more ideal phase shift network. An example is shown in Figure 47.\n\n\n\n\n\n\n\n\nFigure 47: A two-stage polyphase network.\n\n\n\n\n\nAs shown in the figure above, we can use multiple stages (with \\(R_1 C_1 \\ne R_2 C_2\\)) in cascade to broaden the frequency range over which we have a good 90° phase shift between the four outputs. The more stages we use, the better the performance, but also the more components are required. Note that this network is still passive, so it has an inherent loss, which also increases with the number of stages. The idea behind this network is that the network is transparent for positive frequencies, and blocks negative frequencies (or vice versa). We enter the network with real signals (having positive and negative frequency components), and at the output we get complex signals (having only positive or negative frequency components). In this sense this network is a complex filter.\nNote that polyphase filters are popular when we have to create complex signals from real signals. We can use the polyphase filter in the LO path, or also in the signal path (e.g., in a receiver). The benefit is that we can work with a signal where input frequency is equal to the output frequency. This is in strong contrast to the approach we will discuss next.\n\n\n5.5.3 Flip-Flop Based Phase Generation\nThe most widely used approach to generate quadrature LO signals is to use digital circuits, as shown in Figure 48. The idea is to use a flip-flop (or a latch) to divide the frequency of an incoming clock signal by 2. If we drive the two flip-flops (which are connected as toggle flip-flops) by inverted clocks, then the resulting output signals are 90° phase-shifted, as shown in Figure 49.\n\n\n\n\n\n\n\n\nFigure 48: I/Q generation with a divide-by-2.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 49: Input and output waveforms of I/Q generation with a divide-by-2.\n\n\n\n\n\nIt is important to note that the circuit shown in Figure 48 has to be implemented in a way so that there is no phase ambiguity, i.e., the I-phase is lagging the Q-phase by exactly 90°. This can be achieved by using a reset signal to set the flip-flops to a known state at startup, or by implementing flip-flops using a differential clock input.\nIf the input clock is not 2x the target frequency but higher (e.g., 4x), then we can use a frequency divider approach to generate more than four phases. This could be useful in an N-path filter, where we could need more than four phases (see Section 5.4).\nOften, we need four-phase LO signals with 25% duty cycle (instead of the 50% duty cycle shown in Figure 49). This can be achieved by using additional logic gates to combine the outputs of the flip-flops, as shown in Figure 50. The resulting LO waveforms are shown in Figure 51.\n\n\n\n\n\n\n\n\nFigure 50: I/Q generation with a divide-by-2 and 25% duty cycle generation.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 51: Input and output waveforms of I/Q generation with a divide-by-2 and 25% duty cycle generation.\n\n\n\n\n\nThe advantage of using flip-flops to generate multi-phase LO signals is that very precise phase shifts can be achieved, which can be produced over a very wide frequency range. They can be implemented in different logic styles, like CMOS, ECL, CML, and so on. The disadvantage is that we need a high-frequency clock signal above the target frequency, which might be difficult to generate. Still, I/Q generation with flip-flops is the de-facto standard approach in modern RFICs.\n\n\n5.5.4 Delay-Based Phase Generation\nThe final approach we want to mention is to use a delay line (or multiple ones) to generate phase shifts. Using transmission lines, this approach is widely used at very high frequencies, where other approaches (like the ones shown in Section 5.5.2 or Section 5.5.3) are difficult to implement. One well-known approach is the 90° hybrid coupler, realized with \\(\\lambda/4\\) transmission lines (Pozar 2011). When the frequencies are high enough (and the resulting wavelengths short enough), this approach can even be implemented on-chip. The disadvantage is that the phase shift is frequency-dependent, so the quadrature signals are only perfectly in phase at one frequency. Furthermore, this passive network has a 3 dB loss, so we need additional gain stages to compensate for this loss. A branch-line hybrid coupler is shown in Figure 52.\n\n\n\n\n\n\n\n\nFigure 52: Branch-line hybrid coupler schematic showing the transmission line structure with characteristic impedances and λ/4 length sections.\n\n\n\n\n\nThe 3-port S-parameter matrix of an ideal branch-line coupler (assuming port 4 is poperly terminated with \\(Z_0\\)) is given by\n\\[\nS = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}\n0 & -j & -1 \\\\\n-j & 0 & 0 \\\\\n-1 & 0 & 0\n\\end{bmatrix}.\n\\tag{39}\\]\nA feature of the coupler in Figure 52 is that it is single-ended; a differential implementation needs either two couplers or a coupler with subsequent baluns.\nAnother approach, which is similar to the flip-flop based approach, is to use a delay line to generate the required phase shifts. This can be done with a single delay line and multiple taps, or with multiple delay lines. The idea is that we delay the input clock signal by a certain amount of time, which corresponds to a 90° phase shift at the target frequency. This approach is shown in Figure 53. Since the delay of a delay line is frequency dependent, and the delay will change with process, voltage, and temperature (PVT) variations, we have to implement a tuning mechanism to adjust the delay. This implementation is called a delay-locked loop (DLL), which is similar to a phase-locked loop (PLL, see Section 7).\n\n\n\n\n\n\n\n\nFigure 53: LO multiphase generation by delay-locked loop (DLL). An extension to more than four phases is straightforward.\n\n\n\n\n\nWith a phase detector (PD) we can compare the phase of the output signal with the input signal, and regulate the delay per stage so that after four delays the edges line up. Then we can tap the equally-spaced phases and use them as LO signals. The advantage of this approach is that we can flexibly create a required number of phases from an input clock. This feature is also used in wireline communication systems to generate multiple phases for the data sampling."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Radio-Frequency Integrated Circuits",
    "section": "",
    "text": "Radio-Frequency Integrated Circuits\n\n\n\nQuarto Publish\n\n\n(c) 2025 Harald Pretl and co-authors, Department for Integrated Circuits (ICD), Johannes Kepler University, Linz (JKU)\nThis is the material for a graduate-level radio-frequency integrated circuit course, held at JKU under course number 336.023 (“VO Integrierte Hochfrequenz-Schaltungstechnik”). Follow this link to access the material.\nAll course material is made publicly available and shared under the Apache-2.0 license.\nWe happily accept pull requests to fix typos or add content! If you want to discuss something that is not clear, please open an issue!"
  }
]